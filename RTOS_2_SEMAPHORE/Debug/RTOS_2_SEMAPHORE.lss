
RTOS_2_SEMAPHORE.elf:     file format elf32-avr

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .text         00002752  00000000  00000000  00000094  2**1
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  1 .data         0000000a  00800060  00002752  000027e6  2**0
                  CONTENTS, ALLOC, LOAD, DATA
  2 .bss          000003be  0080006a  0080006a  000027f0  2**0
                  ALLOC
  3 .stab         00000750  00000000  00000000  000027f0  2**2
                  CONTENTS, READONLY, DEBUGGING
  4 .stabstr      000000e7  00000000  00000000  00002f40  2**0
                  CONTENTS, READONLY, DEBUGGING
  5 .debug_aranges 00000140  00000000  00000000  00003028  2**3
                  CONTENTS, READONLY, DEBUGGING
  6 .debug_info   00003415  00000000  00000000  00003168  2**0
                  CONTENTS, READONLY, DEBUGGING
  7 .debug_abbrev 00000bdc  00000000  00000000  0000657d  2**0
                  CONTENTS, READONLY, DEBUGGING
  8 .debug_line   00001344  00000000  00000000  00007159  2**0
                  CONTENTS, READONLY, DEBUGGING
  9 .debug_frame  00000b28  00000000  00000000  000084a0  2**2
                  CONTENTS, READONLY, DEBUGGING
 10 .debug_str    000014a6  00000000  00000000  00008fc8  2**0
                  CONTENTS, READONLY, DEBUGGING
 11 .debug_loc    00003da7  00000000  00000000  0000a46e  2**0
                  CONTENTS, READONLY, DEBUGGING
 12 .debug_ranges 00000148  00000000  00000000  0000e215  2**0
                  CONTENTS, READONLY, DEBUGGING

Disassembly of section .text:

00000000 <__vectors>:
       0:	0c 94 2a 00 	jmp	0x54	; 0x54 <__ctors_end>
       4:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
       8:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
       c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      10:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      14:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      18:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      1c:	0c 94 d2 04 	jmp	0x9a4	; 0x9a4 <__vector_7>
      20:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      24:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      28:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      2c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      30:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      34:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      38:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      3c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      40:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      44:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      48:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      4c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      50:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>

00000054 <__ctors_end>:
      54:	11 24       	eor	r1, r1
      56:	1f be       	out	0x3f, r1	; 63
      58:	cf e5       	ldi	r28, 0x5F	; 95
      5a:	d8 e0       	ldi	r29, 0x08	; 8
      5c:	de bf       	out	0x3e, r29	; 62
      5e:	cd bf       	out	0x3d, r28	; 61

00000060 <__do_copy_data>:
      60:	10 e0       	ldi	r17, 0x00	; 0
      62:	a0 e6       	ldi	r26, 0x60	; 96
      64:	b0 e0       	ldi	r27, 0x00	; 0
      66:	e2 e5       	ldi	r30, 0x52	; 82
      68:	f7 e2       	ldi	r31, 0x27	; 39
      6a:	02 c0       	rjmp	.+4      	; 0x70 <__do_copy_data+0x10>
      6c:	05 90       	lpm	r0, Z+
      6e:	0d 92       	st	X+, r0
      70:	aa 36       	cpi	r26, 0x6A	; 106
      72:	b1 07       	cpc	r27, r17
      74:	d9 f7       	brne	.-10     	; 0x6c <__do_copy_data+0xc>

00000076 <__do_clear_bss>:
      76:	14 e0       	ldi	r17, 0x04	; 4
      78:	aa e6       	ldi	r26, 0x6A	; 106
      7a:	b0 e0       	ldi	r27, 0x00	; 0
      7c:	01 c0       	rjmp	.+2      	; 0x80 <.do_clear_bss_start>

0000007e <.do_clear_bss_loop>:
      7e:	1d 92       	st	X+, r1

00000080 <.do_clear_bss_start>:
      80:	a8 32       	cpi	r26, 0x28	; 40
      82:	b1 07       	cpc	r27, r17
      84:	e1 f7       	brne	.-8      	; 0x7e <.do_clear_bss_loop>
      86:	0e 94 5d 09 	call	0x12ba	; 0x12ba <main>
      8a:	0c 94 a7 13 	jmp	0x274e	; 0x274e <_exit>

0000008e <__bad_interrupt>:
      8e:	0c 94 00 00 	jmp	0	; 0x0 <__vectors>

00000092 <prvTestWaitCondition>:

static BaseType_t prvTestWaitCondition( const EventBits_t uxCurrentEventBits, const EventBits_t uxBitsToWaitFor, const BaseType_t xWaitForAllBits )
{
BaseType_t xWaitConditionMet = pdFALSE;

	if( xWaitForAllBits == pdFALSE )
      92:	44 23       	and	r20, r20
      94:	41 f4       	brne	.+16     	; 0xa6 <prvTestWaitCondition+0x14>
	{
		/* Task only has to wait for one bit within uxBitsToWaitFor to be
		set.  Is one already set? */
		if( ( uxCurrentEventBits & uxBitsToWaitFor ) != ( EventBits_t ) 0 )
      96:	68 23       	and	r22, r24
      98:	79 23       	and	r23, r25
		{
			xWaitConditionMet = pdTRUE;
      9a:	81 e0       	ldi	r24, 0x01	; 1
      9c:	61 15       	cp	r22, r1
      9e:	71 05       	cpc	r23, r1
      a0:	51 f4       	brne	.+20     	; 0xb6 <prvTestWaitCondition+0x24>
      a2:	80 e0       	ldi	r24, 0x00	; 0
      a4:	08 95       	ret
	}
	else
	{
		/* Task has to wait for all the bits in uxBitsToWaitFor to be set.
		Are they set already? */
		if( ( uxCurrentEventBits & uxBitsToWaitFor ) == uxBitsToWaitFor )
      a6:	9b 01       	movw	r18, r22
      a8:	28 23       	and	r18, r24
      aa:	39 23       	and	r19, r25
	{
		/* Task only has to wait for one bit within uxBitsToWaitFor to be
		set.  Is one already set? */
		if( ( uxCurrentEventBits & uxBitsToWaitFor ) != ( EventBits_t ) 0 )
		{
			xWaitConditionMet = pdTRUE;
      ac:	81 e0       	ldi	r24, 0x01	; 1
      ae:	62 17       	cp	r22, r18
      b0:	73 07       	cpc	r23, r19
      b2:	09 f0       	breq	.+2      	; 0xb6 <prvTestWaitCondition+0x24>
      b4:	80 e0       	ldi	r24, 0x00	; 0
			mtCOVERAGE_TEST_MARKER();
		}
	}

	return xWaitConditionMet;
}
      b6:	08 95       	ret

000000b8 <xEventGroupCreate>:
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	EventGroupHandle_t xEventGroupCreate( void )
	{
      b8:	cf 93       	push	r28
      ba:	df 93       	push	r29
	EventGroup_t *pxEventBits;

		/* Allocate the event group. */
		pxEventBits = ( EventGroup_t * ) pvPortMalloc( sizeof( EventGroup_t ) );
      bc:	8b e0       	ldi	r24, 0x0B	; 11
      be:	90 e0       	ldi	r25, 0x00	; 0
      c0:	0e 94 f2 01 	call	0x3e4	; 0x3e4 <pvPortMalloc>
      c4:	ec 01       	movw	r28, r24

		if( pxEventBits != NULL )
      c6:	00 97       	sbiw	r24, 0x00	; 0
      c8:	31 f0       	breq	.+12     	; 0xd6 <xEventGroupCreate+0x1e>
		{
			pxEventBits->uxEventBits = 0;
      ca:	fc 01       	movw	r30, r24
      cc:	11 92       	st	Z+, r1
      ce:	11 92       	st	Z+, r1
      d0:	cf 01       	movw	r24, r30
			vListInitialise( &( pxEventBits->xTasksWaitingForBits ) );
      d2:	0e 94 cb 02 	call	0x596	; 0x596 <vListInitialise>
		{
			traceEVENT_GROUP_CREATE_FAILED();
		}

		return ( EventGroupHandle_t ) pxEventBits;
	}
      d6:	8c 2f       	mov	r24, r28
      d8:	9d 2f       	mov	r25, r29
      da:	df 91       	pop	r29
      dc:	cf 91       	pop	r28
      de:	08 95       	ret

000000e0 <xEventGroupWaitBits>:
	return uxReturn;
}
/*-----------------------------------------------------------*/

EventBits_t xEventGroupWaitBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToWaitFor, const BaseType_t xClearOnExit, const BaseType_t xWaitForAllBits, TickType_t xTicksToWait )
{
      e0:	af 92       	push	r10
      e2:	bf 92       	push	r11
      e4:	cf 92       	push	r12
      e6:	df 92       	push	r13
      e8:	ef 92       	push	r14
      ea:	ff 92       	push	r15
      ec:	0f 93       	push	r16
      ee:	1f 93       	push	r17
      f0:	cf 93       	push	r28
      f2:	df 93       	push	r29
      f4:	5c 01       	movw	r10, r24
      f6:	6b 01       	movw	r12, r22
      f8:	e4 2e       	mov	r14, r20
      fa:	f2 2e       	mov	r15, r18
	{
		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );
	}
	#endif

	vTaskSuspendAll();
      fc:	0e 94 f3 0c 	call	0x19e6	; 0x19e6 <vTaskSuspendAll>
	{
		const EventBits_t uxCurrentEventBits = pxEventBits->uxEventBits;
     100:	f5 01       	movw	r30, r10
     102:	c0 81       	ld	r28, Z
     104:	d1 81       	ldd	r29, Z+1	; 0x01

		/* Check to see if the wait condition is already met or not. */
		xWaitConditionMet = prvTestWaitCondition( uxCurrentEventBits, uxBitsToWaitFor, xWaitForAllBits );
     106:	ce 01       	movw	r24, r28
     108:	b6 01       	movw	r22, r12
     10a:	4f 2d       	mov	r20, r15
     10c:	0e 94 49 00 	call	0x92	; 0x92 <prvTestWaitCondition>

		if( xWaitConditionMet != pdFALSE )
     110:	88 23       	and	r24, r24
     112:	51 f0       	breq	.+20     	; 0x128 <xEventGroupWaitBits+0x48>
			block. */
			uxReturn = uxCurrentEventBits;
			xTicksToWait = ( TickType_t ) 0;

			/* Clear the wait bits if requested to do so. */
			if( xClearOnExit != pdFALSE )
     114:	ee 20       	and	r14, r14
     116:	01 f1       	breq	.+64     	; 0x158 <xEventGroupWaitBits+0x78>
			{
				pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     118:	c0 94       	com	r12
     11a:	d0 94       	com	r13
     11c:	cc 22       	and	r12, r28
     11e:	dd 22       	and	r13, r29
     120:	f5 01       	movw	r30, r10
     122:	d1 82       	std	Z+1, r13	; 0x01
     124:	c0 82       	st	Z, r12
     126:	18 c0       	rjmp	.+48     	; 0x158 <xEventGroupWaitBits+0x78>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		else if( xTicksToWait == ( TickType_t ) 0 )
     128:	01 15       	cp	r16, r1
     12a:	11 05       	cpc	r17, r1
     12c:	a9 f0       	breq	.+42     	; 0x158 <xEventGroupWaitBits+0x78>
		{
			/* The task is going to block to wait for its required bits to be
			set.  uxControlBits are used to remember the specified behaviour of
			this call to xEventGroupWaitBits() - for use when the event bits
			unblock the task. */
			if( xClearOnExit != pdFALSE )
     12e:	ee 20       	and	r14, r14
     130:	19 f4       	brne	.+6      	; 0x138 <xEventGroupWaitBits+0x58>
/*-----------------------------------------------------------*/

EventBits_t xEventGroupWaitBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToWaitFor, const BaseType_t xClearOnExit, const BaseType_t xWaitForAllBits, TickType_t xTicksToWait )
{
EventGroup_t *pxEventBits = ( EventGroup_t * ) xEventGroup;
EventBits_t uxReturn, uxControlBits = 0;
     132:	60 e0       	ldi	r22, 0x00	; 0
     134:	70 e0       	ldi	r23, 0x00	; 0
     136:	02 c0       	rjmp	.+4      	; 0x13c <xEventGroupWaitBits+0x5c>
			set.  uxControlBits are used to remember the specified behaviour of
			this call to xEventGroupWaitBits() - for use when the event bits
			unblock the task. */
			if( xClearOnExit != pdFALSE )
			{
				uxControlBits |= eventCLEAR_EVENTS_ON_EXIT_BIT;
     138:	60 e0       	ldi	r22, 0x00	; 0
     13a:	71 e0       	ldi	r23, 0x01	; 1
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			if( xWaitForAllBits != pdFALSE )
     13c:	f1 10       	cpse	r15, r1
			{
				uxControlBits |= eventWAIT_FOR_ALL_BITS;
     13e:	74 60       	ori	r23, 0x04	; 4
			}

			/* Store the bits that the calling task is waiting for in the
			task's event list item so the kernel knows when a match is
			found.  Then enter the blocked state. */
			vTaskPlaceOnUnorderedEventList( &( pxEventBits->xTasksWaitingForBits ), ( uxBitsToWaitFor | uxControlBits ), xTicksToWait );
     140:	6c 29       	or	r22, r12
     142:	7d 29       	or	r23, r13
     144:	c5 01       	movw	r24, r10
     146:	02 96       	adiw	r24, 0x02	; 2
     148:	a8 01       	movw	r20, r16
     14a:	0e 94 99 0f 	call	0x1f32	; 0x1f32 <vTaskPlaceOnUnorderedEventList>
			uxReturn = 0;

			traceEVENT_GROUP_WAIT_BITS_BLOCK( xEventGroup, uxBitsToWaitFor );
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     14e:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
     152:	88 23       	and	r24, r24
     154:	39 f4       	brne	.+14     	; 0x164 <xEventGroupWaitBits+0x84>
     156:	04 c0       	rjmp	.+8      	; 0x160 <xEventGroupWaitBits+0x80>
			uxReturn = 0;

			traceEVENT_GROUP_WAIT_BITS_BLOCK( xEventGroup, uxBitsToWaitFor );
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     158:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>
     15c:	ce 01       	movw	r24, r28
     15e:	21 c0       	rjmp	.+66     	; 0x1a2 <xEventGroupWaitBits+0xc2>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
		{
			portYIELD_WITHIN_API();
     160:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>

		/* The task blocked to wait for its required bits to be set - at this
		point either the required bits were set or the block time expired.  If
		the required bits were set they will have been stored in the task's
		event list item, and they should now be retrieved then cleared. */
		uxReturn = uxTaskResetEventItemValue();
     164:	0e 94 1f 11 	call	0x223e	; 0x223e <uxTaskResetEventItemValue>
     168:	ec 01       	movw	r28, r24

		if( ( uxReturn & eventUNBLOCKED_DUE_TO_BIT_SET ) == ( EventBits_t ) 0 )
     16a:	91 fd       	sbrc	r25, 1
     16c:	18 c0       	rjmp	.+48     	; 0x19e <xEventGroupWaitBits+0xbe>
		{
			taskENTER_CRITICAL();
     16e:	0f b6       	in	r0, 0x3f	; 63
     170:	f8 94       	cli
     172:	0f 92       	push	r0
			{
				/* The task timed out, just return the current event bit value. */
				uxReturn = pxEventBits->uxEventBits;
     174:	f5 01       	movw	r30, r10
     176:	c0 81       	ld	r28, Z
     178:	d1 81       	ldd	r29, Z+1	; 0x01

				/* It is possible that the event bits were updated between this
				task leaving the Blocked state and running again. */
				if( prvTestWaitCondition( uxReturn, uxBitsToWaitFor, xWaitForAllBits ) != pdFALSE )
     17a:	ce 01       	movw	r24, r28
     17c:	b6 01       	movw	r22, r12
     17e:	4f 2d       	mov	r20, r15
     180:	0e 94 49 00 	call	0x92	; 0x92 <prvTestWaitCondition>
     184:	88 23       	and	r24, r24
     186:	49 f0       	breq	.+18     	; 0x19a <xEventGroupWaitBits+0xba>
				{
					if( xClearOnExit != pdFALSE )
     188:	ee 20       	and	r14, r14
     18a:	39 f0       	breq	.+14     	; 0x19a <xEventGroupWaitBits+0xba>
					{
						pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     18c:	c0 94       	com	r12
     18e:	d0 94       	com	r13
     190:	cc 22       	and	r12, r28
     192:	dd 22       	and	r13, r29
     194:	f5 01       	movw	r30, r10
     196:	d1 82       	std	Z+1, r13	; 0x01
     198:	c0 82       	st	Z, r12
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			taskEXIT_CRITICAL();
     19a:	0f 90       	pop	r0
     19c:	0f be       	out	0x3f, r0	; 63
		{
			/* The task unblocked because the bits were set. */
		}

		/* The task blocked so control bits may have been set. */
		uxReturn &= ~eventEVENT_BITS_CONTROL_BYTES;
     19e:	ce 01       	movw	r24, r28
     1a0:	90 70       	andi	r25, 0x00	; 0
	}
	traceEVENT_GROUP_WAIT_BITS_END( xEventGroup, uxBitsToWaitFor, xTimeoutOccurred );

	return uxReturn;
}
     1a2:	df 91       	pop	r29
     1a4:	cf 91       	pop	r28
     1a6:	1f 91       	pop	r17
     1a8:	0f 91       	pop	r16
     1aa:	ff 90       	pop	r15
     1ac:	ef 90       	pop	r14
     1ae:	df 90       	pop	r13
     1b0:	cf 90       	pop	r12
     1b2:	bf 90       	pop	r11
     1b4:	af 90       	pop	r10
     1b6:	08 95       	ret

000001b8 <xEventGroupClearBits>:
/*-----------------------------------------------------------*/

EventBits_t xEventGroupClearBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToClear )
{
     1b8:	fc 01       	movw	r30, r24
	/* Check the user is not attempting to clear the bits used by the kernel
	itself. */
	configASSERT( xEventGroup );
	configASSERT( ( uxBitsToClear & eventEVENT_BITS_CONTROL_BYTES ) == 0 );

	taskENTER_CRITICAL();
     1ba:	0f b6       	in	r0, 0x3f	; 63
     1bc:	f8 94       	cli
     1be:	0f 92       	push	r0
	{
		traceEVENT_GROUP_CLEAR_BITS( xEventGroup, uxBitsToClear );

		/* The value returned is the event group value prior to the bits being
		cleared. */
		uxReturn = pxEventBits->uxEventBits;
     1c0:	80 81       	ld	r24, Z
     1c2:	91 81       	ldd	r25, Z+1	; 0x01

		/* Clear the bits. */
		pxEventBits->uxEventBits &= ~uxBitsToClear;
     1c4:	60 95       	com	r22
     1c6:	70 95       	com	r23
     1c8:	68 23       	and	r22, r24
     1ca:	79 23       	and	r23, r25
     1cc:	71 83       	std	Z+1, r23	; 0x01
     1ce:	60 83       	st	Z, r22
	}
	taskEXIT_CRITICAL();
     1d0:	0f 90       	pop	r0
     1d2:	0f be       	out	0x3f, r0	; 63

	return uxReturn;
}
     1d4:	08 95       	ret

000001d6 <xEventGroupGetBitsFromISR>:

#endif
/*-----------------------------------------------------------*/

EventBits_t xEventGroupGetBitsFromISR( EventGroupHandle_t xEventGroup )
{
     1d6:	fc 01       	movw	r30, r24
		uxReturn = pxEventBits->uxEventBits;
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return uxReturn;
}
     1d8:	80 81       	ld	r24, Z
     1da:	91 81       	ldd	r25, Z+1	; 0x01
     1dc:	08 95       	ret

000001de <xEventGroupSetBits>:
/*-----------------------------------------------------------*/

EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet )
{
     1de:	af 92       	push	r10
     1e0:	bf 92       	push	r11
     1e2:	cf 92       	push	r12
     1e4:	df 92       	push	r13
     1e6:	ef 92       	push	r14
     1e8:	ff 92       	push	r15
     1ea:	0f 93       	push	r16
     1ec:	1f 93       	push	r17
     1ee:	cf 93       	push	r28
     1f0:	df 93       	push	r29
     1f2:	8c 01       	movw	r16, r24
     1f4:	eb 01       	movw	r28, r22
	itself. */
	configASSERT( xEventGroup );
	configASSERT( ( uxBitsToSet & eventEVENT_BITS_CONTROL_BYTES ) == 0 );

	pxList = &( pxEventBits->xTasksWaitingForBits );
	pxListEnd = listGET_END_MARKER( pxList ); /*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     1f6:	0f 2e       	mov	r0, r31
     1f8:	f5 e0       	ldi	r31, 0x05	; 5
     1fa:	cf 2e       	mov	r12, r31
     1fc:	dd 24       	eor	r13, r13
     1fe:	f0 2d       	mov	r31, r0
     200:	c8 0e       	add	r12, r24
     202:	d9 1e       	adc	r13, r25
	vTaskSuspendAll();
     204:	0e 94 f3 0c 	call	0x19e6	; 0x19e6 <vTaskSuspendAll>
	{
		traceEVENT_GROUP_SET_BITS( xEventGroup, uxBitsToSet );

		pxListItem = listGET_HEAD_ENTRY( pxList );
     208:	d8 01       	movw	r26, r16
     20a:	17 96       	adiw	r26, 0x07	; 7
     20c:	ed 91       	ld	r30, X+
     20e:	fc 91       	ld	r31, X
     210:	18 97       	sbiw	r26, 0x08	; 8

		/* Set the bits. */
		pxEventBits->uxEventBits |= uxBitsToSet;
     212:	8d 91       	ld	r24, X+
     214:	9c 91       	ld	r25, X
     216:	11 97       	sbiw	r26, 0x01	; 1
     218:	8c 2b       	or	r24, r28
     21a:	9d 2b       	or	r25, r29
     21c:	11 96       	adiw	r26, 0x01	; 1
     21e:	9c 93       	st	X, r25
     220:	8e 93       	st	-X, r24

		/* See if the new bit value should unblock any tasks. */
		while( pxListItem != pxListEnd )
     222:	ce 16       	cp	r12, r30
     224:	df 06       	cpc	r13, r31
     226:	c1 f1       	breq	.+112    	; 0x298 <xEventGroupSetBits+0xba>
EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet )
{
ListItem_t *pxListItem, *pxNext;
ListItem_t const *pxListEnd;
List_t *pxList;
EventBits_t uxBitsToClear = 0, uxBitsWaitedFor, uxControlBits;
     228:	aa 24       	eor	r10, r10
     22a:	bb 24       	eor	r11, r11
			if( ( uxControlBits & eventWAIT_FOR_ALL_BITS ) == ( EventBits_t ) 0 )
			{
				/* Just looking for single bit being set. */
				if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) != ( EventBits_t ) 0 )
				{
					xMatchFound = pdTRUE;
     22c:	ff 24       	eor	r15, r15
     22e:	f3 94       	inc	r15
     230:	ee 24       	eor	r14, r14
     232:	01 c0       	rjmp	.+2      	; 0x236 <xEventGroupSetBits+0x58>

		/* Set the bits. */
		pxEventBits->uxEventBits |= uxBitsToSet;

		/* See if the new bit value should unblock any tasks. */
		while( pxListItem != pxListEnd )
     234:	fe 01       	movw	r30, r28
		{
			pxNext = listGET_NEXT( pxListItem );
     236:	c2 81       	ldd	r28, Z+2	; 0x02
     238:	d3 81       	ldd	r29, Z+3	; 0x03
			uxBitsWaitedFor = listGET_LIST_ITEM_VALUE( pxListItem );
     23a:	80 81       	ld	r24, Z
     23c:	91 81       	ldd	r25, Z+1	; 0x01
			xMatchFound = pdFALSE;

			/* Split the bits waited for from the control bits. */
			uxControlBits = uxBitsWaitedFor & eventEVENT_BITS_CONTROL_BYTES;
     23e:	bc 01       	movw	r22, r24
     240:	60 70       	andi	r22, 0x00	; 0
			uxBitsWaitedFor &= ~eventEVENT_BITS_CONTROL_BYTES;
     242:	9c 01       	movw	r18, r24
     244:	30 70       	andi	r19, 0x00	; 0

			if( ( uxControlBits & eventWAIT_FOR_ALL_BITS ) == ( EventBits_t ) 0 )
     246:	92 fd       	sbrc	r25, 2
     248:	0b c0       	rjmp	.+22     	; 0x260 <xEventGroupSetBits+0x82>
			{
				/* Just looking for single bit being set. */
				if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) != ( EventBits_t ) 0 )
     24a:	d8 01       	movw	r26, r16
     24c:	8d 91       	ld	r24, X+
     24e:	9c 91       	ld	r25, X
     250:	11 97       	sbiw	r26, 0x01	; 1
     252:	82 23       	and	r24, r18
     254:	93 23       	and	r25, r19
				{
					xMatchFound = pdTRUE;
     256:	4f 2d       	mov	r20, r15
     258:	00 97       	sbiw	r24, 0x00	; 0
     25a:	69 f4       	brne	.+26     	; 0x276 <xEventGroupSetBits+0x98>
     25c:	4e 2d       	mov	r20, r14
     25e:	0b c0       	rjmp	.+22     	; 0x276 <xEventGroupSetBits+0x98>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			else if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) == uxBitsWaitedFor )
     260:	d8 01       	movw	r26, r16
     262:	8d 91       	ld	r24, X+
     264:	9c 91       	ld	r25, X
     266:	11 97       	sbiw	r26, 0x01	; 1
     268:	82 23       	and	r24, r18
     26a:	93 23       	and	r25, r19
			if( ( uxControlBits & eventWAIT_FOR_ALL_BITS ) == ( EventBits_t ) 0 )
			{
				/* Just looking for single bit being set. */
				if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) != ( EventBits_t ) 0 )
				{
					xMatchFound = pdTRUE;
     26c:	4f 2d       	mov	r20, r15
     26e:	28 17       	cp	r18, r24
     270:	39 07       	cpc	r19, r25
     272:	09 f0       	breq	.+2      	; 0x276 <xEventGroupSetBits+0x98>
     274:	4e 2d       	mov	r20, r14
			else
			{
				/* Need all bits to be set, but not all the bits were set. */
			}

			if( xMatchFound != pdFALSE )
     276:	44 23       	and	r20, r20
     278:	59 f0       	breq	.+22     	; 0x290 <xEventGroupSetBits+0xb2>
			{
				/* The bits match.  Should the bits be cleared on exit? */
				if( ( uxControlBits & eventCLEAR_EVENTS_ON_EXIT_BIT ) != ( EventBits_t ) 0 )
     27a:	70 ff       	sbrs	r23, 0
     27c:	02 c0       	rjmp	.+4      	; 0x282 <xEventGroupSetBits+0xa4>
				{
					uxBitsToClear |= uxBitsWaitedFor;
     27e:	a2 2a       	or	r10, r18
     280:	b3 2a       	or	r11, r19
				/* Store the actual event flag value in the task's event list
				item before removing the task from the event list.  The
				eventUNBLOCKED_DUE_TO_BIT_SET bit is set so the task knows
				that is was unblocked due to its required bits matching, rather
				than because it timed out. */
				( void ) xTaskRemoveFromUnorderedEventList( pxListItem, pxEventBits->uxEventBits | eventUNBLOCKED_DUE_TO_BIT_SET );
     282:	d8 01       	movw	r26, r16
     284:	6d 91       	ld	r22, X+
     286:	7c 91       	ld	r23, X
     288:	72 60       	ori	r23, 0x02	; 2
     28a:	cf 01       	movw	r24, r30
     28c:	0e 94 fd 0f 	call	0x1ffa	; 0x1ffa <xTaskRemoveFromUnorderedEventList>

		/* Set the bits. */
		pxEventBits->uxEventBits |= uxBitsToSet;

		/* See if the new bit value should unblock any tasks. */
		while( pxListItem != pxListEnd )
     290:	cc 16       	cp	r12, r28
     292:	dd 06       	cpc	r13, r29
     294:	79 f6       	brne	.-98     	; 0x234 <xEventGroupSetBits+0x56>
     296:	02 c0       	rjmp	.+4      	; 0x29c <xEventGroupSetBits+0xbe>
EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet )
{
ListItem_t *pxListItem, *pxNext;
ListItem_t const *pxListEnd;
List_t *pxList;
EventBits_t uxBitsToClear = 0, uxBitsWaitedFor, uxControlBits;
     298:	aa 24       	eor	r10, r10
     29a:	bb 24       	eor	r11, r11
			pxListItem = pxNext;
		}

		/* Clear any bits that matched when the eventCLEAR_EVENTS_ON_EXIT_BIT
		bit was set in the control word. */
		pxEventBits->uxEventBits &= ~uxBitsToClear;
     29c:	c5 01       	movw	r24, r10
     29e:	80 95       	com	r24
     2a0:	90 95       	com	r25
     2a2:	f8 01       	movw	r30, r16
     2a4:	a0 80       	ld	r10, Z
     2a6:	b1 80       	ldd	r11, Z+1	; 0x01
     2a8:	a8 22       	and	r10, r24
     2aa:	b9 22       	and	r11, r25
     2ac:	b1 82       	std	Z+1, r11	; 0x01
     2ae:	a0 82       	st	Z, r10
	}
	( void ) xTaskResumeAll();
     2b0:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>

	return pxEventBits->uxEventBits;
}
     2b4:	d8 01       	movw	r26, r16
     2b6:	8c 91       	ld	r24, X
     2b8:	11 96       	adiw	r26, 0x01	; 1
     2ba:	9c 91       	ld	r25, X
     2bc:	11 97       	sbiw	r26, 0x01	; 1
     2be:	df 91       	pop	r29
     2c0:	cf 91       	pop	r28
     2c2:	1f 91       	pop	r17
     2c4:	0f 91       	pop	r16
     2c6:	ff 90       	pop	r15
     2c8:	ef 90       	pop	r14
     2ca:	df 90       	pop	r13
     2cc:	cf 90       	pop	r12
     2ce:	bf 90       	pop	r11
     2d0:	af 90       	pop	r10
     2d2:	08 95       	ret

000002d4 <xEventGroupSync>:

#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
/*-----------------------------------------------------------*/

EventBits_t xEventGroupSync( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet, const EventBits_t uxBitsToWaitFor, TickType_t xTicksToWait )
{
     2d4:	af 92       	push	r10
     2d6:	bf 92       	push	r11
     2d8:	cf 92       	push	r12
     2da:	df 92       	push	r13
     2dc:	ef 92       	push	r14
     2de:	ff 92       	push	r15
     2e0:	0f 93       	push	r16
     2e2:	1f 93       	push	r17
     2e4:	cf 93       	push	r28
     2e6:	df 93       	push	r29
     2e8:	6c 01       	movw	r12, r24
     2ea:	eb 01       	movw	r28, r22
     2ec:	7a 01       	movw	r14, r20
     2ee:	59 01       	movw	r10, r18
	{
		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );
	}
	#endif

	vTaskSuspendAll();
     2f0:	0e 94 f3 0c 	call	0x19e6	; 0x19e6 <vTaskSuspendAll>
	{
		uxOriginalBitValue = pxEventBits->uxEventBits;
     2f4:	f6 01       	movw	r30, r12
     2f6:	00 81       	ld	r16, Z
     2f8:	11 81       	ldd	r17, Z+1	; 0x01

		( void ) xEventGroupSetBits( xEventGroup, uxBitsToSet );
     2fa:	c6 01       	movw	r24, r12
     2fc:	be 01       	movw	r22, r28
     2fe:	0e 94 ef 00 	call	0x1de	; 0x1de <xEventGroupSetBits>

		if( ( ( uxOriginalBitValue | uxBitsToSet ) & uxBitsToWaitFor ) == uxBitsToWaitFor )
     302:	c0 2b       	or	r28, r16
     304:	d1 2b       	or	r29, r17
     306:	c7 01       	movw	r24, r14
     308:	8c 23       	and	r24, r28
     30a:	9d 23       	and	r25, r29
     30c:	8e 15       	cp	r24, r14
     30e:	9f 05       	cpc	r25, r15
     310:	51 f4       	brne	.+20     	; 0x326 <xEventGroupSync+0x52>
			/* All the rendezvous bits are now set - no need to block. */
			uxReturn = ( uxOriginalBitValue | uxBitsToSet );

			/* Rendezvous always clear the bits.  They will have been cleared
			already unless this is the only task in the rendezvous. */
			pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     312:	80 95       	com	r24
     314:	90 95       	com	r25
     316:	f6 01       	movw	r30, r12
     318:	20 81       	ld	r18, Z
     31a:	31 81       	ldd	r19, Z+1	; 0x01
     31c:	82 23       	and	r24, r18
     31e:	93 23       	and	r25, r19
     320:	91 83       	std	Z+1, r25	; 0x01
     322:	80 83       	st	Z, r24
     324:	12 c0       	rjmp	.+36     	; 0x34a <xEventGroupSync+0x76>

			xTicksToWait = 0;
		}
		else
		{
			if( xTicksToWait != ( TickType_t ) 0 )
     326:	a1 14       	cp	r10, r1
     328:	b1 04       	cpc	r11, r1
     32a:	61 f0       	breq	.+24     	; 0x344 <xEventGroupSync+0x70>
				traceEVENT_GROUP_SYNC_BLOCK( xEventGroup, uxBitsToSet, uxBitsToWaitFor );

				/* Store the bits that the calling task is waiting for in the
				task's event list item so the kernel knows when a match is
				found.  Then enter the blocked state. */
				vTaskPlaceOnUnorderedEventList( &( pxEventBits->xTasksWaitingForBits ), ( uxBitsToWaitFor | eventCLEAR_EVENTS_ON_EXIT_BIT | eventWAIT_FOR_ALL_BITS ), xTicksToWait );
     32c:	b7 01       	movw	r22, r14
     32e:	75 60       	ori	r23, 0x05	; 5
     330:	c6 01       	movw	r24, r12
     332:	02 96       	adiw	r24, 0x02	; 2
     334:	a5 01       	movw	r20, r10
     336:	0e 94 99 0f 	call	0x1f32	; 0x1f32 <vTaskPlaceOnUnorderedEventList>
				specified - just return the current event bit value. */
				uxReturn = pxEventBits->uxEventBits;
			}
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     33a:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
     33e:	88 23       	and	r24, r24
     340:	49 f4       	brne	.+18     	; 0x354 <xEventGroupSync+0x80>
     342:	06 c0       	rjmp	.+12     	; 0x350 <xEventGroupSync+0x7c>
			}
			else
			{
				/* The rendezvous bits were not set, but no block time was
				specified - just return the current event bit value. */
				uxReturn = pxEventBits->uxEventBits;
     344:	f6 01       	movw	r30, r12
     346:	c0 81       	ld	r28, Z
     348:	d1 81       	ldd	r29, Z+1	; 0x01
			}
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     34a:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>
     34e:	1c c0       	rjmp	.+56     	; 0x388 <xEventGroupSync+0xb4>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
		{
			portYIELD_WITHIN_API();
     350:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>

		/* The task blocked to wait for its required bits to be set - at this
		point either the required bits were set or the block time expired.  If
		the required bits were set they will have been stored in the task's
		event list item, and they should now be retrieved then cleared. */
		uxReturn = uxTaskResetEventItemValue();
     354:	0e 94 1f 11 	call	0x223e	; 0x223e <uxTaskResetEventItemValue>

		if( ( uxReturn & eventUNBLOCKED_DUE_TO_BIT_SET ) == ( EventBits_t ) 0 )
     358:	91 fd       	sbrc	r25, 1
     35a:	14 c0       	rjmp	.+40     	; 0x384 <xEventGroupSync+0xb0>
		{
			/* The task timed out, just return the current event bit value. */
			taskENTER_CRITICAL();
     35c:	0f b6       	in	r0, 0x3f	; 63
     35e:	f8 94       	cli
     360:	0f 92       	push	r0
			{
				uxReturn = pxEventBits->uxEventBits;
     362:	f6 01       	movw	r30, r12
     364:	80 81       	ld	r24, Z
     366:	91 81       	ldd	r25, Z+1	; 0x01

				/* Although the task got here because it timed out before the
				bits it was waiting for were set, it is possible that since it
				unblocked another task has set the bits.  If this is the case
				then it needs to clear the bits before exiting. */
				if( ( uxReturn & uxBitsToWaitFor ) == uxBitsToWaitFor )
     368:	97 01       	movw	r18, r14
     36a:	28 23       	and	r18, r24
     36c:	39 23       	and	r19, r25
     36e:	2e 15       	cp	r18, r14
     370:	3f 05       	cpc	r19, r15
     372:	31 f4       	brne	.+12     	; 0x380 <xEventGroupSync+0xac>
				{
					pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     374:	20 95       	com	r18
     376:	30 95       	com	r19
     378:	28 23       	and	r18, r24
     37a:	39 23       	and	r19, r25
     37c:	31 83       	std	Z+1, r19	; 0x01
     37e:	20 83       	st	Z, r18
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			taskEXIT_CRITICAL();
     380:	0f 90       	pop	r0
     382:	0f be       	out	0x3f, r0	; 63
			/* The task unblocked because the bits were set. */
		}

		/* Control bits might be set as the task had blocked should not be
		returned. */
		uxReturn &= ~eventEVENT_BITS_CONTROL_BYTES;
     384:	ec 01       	movw	r28, r24
     386:	d0 70       	andi	r29, 0x00	; 0
	}

	traceEVENT_GROUP_SYNC_END( xEventGroup, uxBitsToSet, uxBitsToWaitFor, xTimeoutOccurred );

	return uxReturn;
}
     388:	8c 2f       	mov	r24, r28
     38a:	9d 2f       	mov	r25, r29
     38c:	df 91       	pop	r29
     38e:	cf 91       	pop	r28
     390:	1f 91       	pop	r17
     392:	0f 91       	pop	r16
     394:	ff 90       	pop	r15
     396:	ef 90       	pop	r14
     398:	df 90       	pop	r13
     39a:	cf 90       	pop	r12
     39c:	bf 90       	pop	r11
     39e:	af 90       	pop	r10
     3a0:	08 95       	ret

000003a2 <vEventGroupDelete>:
	return pxEventBits->uxEventBits;
}
/*-----------------------------------------------------------*/

void vEventGroupDelete( EventGroupHandle_t xEventGroup )
{
     3a2:	cf 93       	push	r28
     3a4:	df 93       	push	r29
     3a6:	ec 01       	movw	r28, r24
EventGroup_t *pxEventBits = ( EventGroup_t * ) xEventGroup;
const List_t *pxTasksWaitingForBits = &( pxEventBits->xTasksWaitingForBits );

	vTaskSuspendAll();
     3a8:	0e 94 f3 0c 	call	0x19e6	; 0x19e6 <vTaskSuspendAll>
	{
		traceEVENT_GROUP_DELETE( xEventGroup );

		while( listCURRENT_LIST_LENGTH( pxTasksWaitingForBits ) > ( UBaseType_t ) 0 )
     3ac:	8a 81       	ldd	r24, Y+2	; 0x02
     3ae:	88 23       	and	r24, r24
     3b0:	49 f0       	breq	.+18     	; 0x3c4 <vEventGroupDelete+0x22>
		{
			/* Unblock the task, returning 0 as the event list is being deleted
			and	cannot therefore have any bits set. */
			configASSERT( pxTasksWaitingForBits->xListEnd.pxNext != ( ListItem_t * ) &( pxTasksWaitingForBits->xListEnd ) );
			( void ) xTaskRemoveFromUnorderedEventList( pxTasksWaitingForBits->xListEnd.pxNext, eventUNBLOCKED_DUE_TO_BIT_SET );
     3b2:	8f 81       	ldd	r24, Y+7	; 0x07
     3b4:	98 85       	ldd	r25, Y+8	; 0x08
     3b6:	60 e0       	ldi	r22, 0x00	; 0
     3b8:	72 e0       	ldi	r23, 0x02	; 2
     3ba:	0e 94 fd 0f 	call	0x1ffa	; 0x1ffa <xTaskRemoveFromUnorderedEventList>

	vTaskSuspendAll();
	{
		traceEVENT_GROUP_DELETE( xEventGroup );

		while( listCURRENT_LIST_LENGTH( pxTasksWaitingForBits ) > ( UBaseType_t ) 0 )
     3be:	8a 81       	ldd	r24, Y+2	; 0x02
     3c0:	88 23       	and	r24, r24
     3c2:	b9 f7       	brne	.-18     	; 0x3b2 <vEventGroupDelete+0x10>

		#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
		{
			/* The event group can only have been allocated dynamically - free
			it again. */
			vPortFree( pxEventBits );
     3c4:	ce 01       	movw	r24, r28
     3c6:	0e 94 92 02 	call	0x524	; 0x524 <vPortFree>
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
	}
	( void ) xTaskResumeAll();
     3ca:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>
}
     3ce:	df 91       	pop	r29
     3d0:	cf 91       	pop	r28
     3d2:	08 95       	ret

000003d4 <vEventGroupSetBitsCallback>:

/* For internal use only - execute a 'set bits' command that was pended from
an interrupt. */
void vEventGroupSetBitsCallback( void *pvEventGroup, const uint32_t ulBitsToSet )
{
	( void ) xEventGroupSetBits( pvEventGroup, ( EventBits_t ) ulBitsToSet );
     3d4:	ba 01       	movw	r22, r20
     3d6:	0e 94 ef 00 	call	0x1de	; 0x1de <xEventGroupSetBits>
}
     3da:	08 95       	ret

000003dc <vEventGroupClearBitsCallback>:

/* For internal use only - execute a 'clear bits' command that was pended from
an interrupt. */
void vEventGroupClearBitsCallback( void *pvEventGroup, const uint32_t ulBitsToClear )
{
	( void ) xEventGroupClearBits( pvEventGroup, ( EventBits_t ) ulBitsToClear );
     3dc:	ba 01       	movw	r22, r20
     3de:	0e 94 dc 00 	call	0x1b8	; 0x1b8 <xEventGroupClearBits>
}
     3e2:	08 95       	ret

000003e4 <pvPortMalloc>:
	pxIterator->pxNextFreeBlock = pxBlockToInsert;									\
}
/*-----------------------------------------------------------*/

void *pvPortMalloc( size_t xWantedSize )
{
     3e4:	0f 93       	push	r16
     3e6:	1f 93       	push	r17
     3e8:	cf 93       	push	r28
     3ea:	df 93       	push	r29
     3ec:	ec 01       	movw	r28, r24
BlockLink_t *pxBlock, *pxPreviousBlock, *pxNewBlockLink;
static BaseType_t xHeapHasBeenInitialised = pdFALSE;
void *pvReturn = NULL;

	vTaskSuspendAll();
     3ee:	0e 94 f3 0c 	call	0x19e6	; 0x19e6 <vTaskSuspendAll>
	{
		/* If this is the first call to malloc then the heap will require
		initialisation to setup the list of free blocks. */
		if( xHeapHasBeenInitialised == pdFALSE )
     3f2:	80 91 6a 00 	lds	r24, 0x006A
     3f6:	88 23       	and	r24, r24
     3f8:	f9 f4       	brne	.+62     	; 0x438 <pvPortMalloc+0x54>
	/* Ensure the heap starts on a correctly aligned boundary. */
	pucAlignedHeap = ( uint8_t * ) ( ( ( portPOINTER_SIZE_TYPE ) &ucHeap[ portBYTE_ALIGNMENT ] ) & ( ~( ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) ) );

	/* xStart is used to hold a pointer to the first item in the list of free
	blocks.  The void cast is used to prevent compiler warnings. */
	xStart.pxNextFreeBlock = ( void * ) pucAlignedHeap;
     3fa:	84 e7       	ldi	r24, 0x74	; 116
     3fc:	90 e0       	ldi	r25, 0x00	; 0
     3fe:	90 93 6c 00 	sts	0x006C, r25
     402:	80 93 6b 00 	sts	0x006B, r24
	xStart.xBlockSize = ( size_t ) 0;
     406:	10 92 6e 00 	sts	0x006E, r1
     40a:	10 92 6d 00 	sts	0x006D, r1

	/* xEnd is used to mark the end of the list of free blocks. */
	xEnd.xBlockSize = configADJUSTED_HEAP_SIZE;
     40e:	8f e1       	ldi	r24, 0x1F	; 31
     410:	93 e0       	ldi	r25, 0x03	; 3
     412:	90 93 72 00 	sts	0x0072, r25
     416:	80 93 71 00 	sts	0x0071, r24
	xEnd.pxNextFreeBlock = NULL;
     41a:	e1 e7       	ldi	r30, 0x71	; 113
     41c:	f0 e0       	ldi	r31, 0x00	; 0
     41e:	12 92       	st	-Z, r1
     420:	12 92       	st	-Z, r1

	/* To start with there is a single free block that is sized to take up the
	entire heap space. */
	pxFirstFreeBlock = ( void * ) pucAlignedHeap;
	pxFirstFreeBlock->xBlockSize = configADJUSTED_HEAP_SIZE;
     422:	90 93 77 00 	sts	0x0077, r25
     426:	80 93 76 00 	sts	0x0076, r24
	pxFirstFreeBlock->pxNextFreeBlock = &xEnd;
     42a:	f0 93 75 00 	sts	0x0075, r31
     42e:	e0 93 74 00 	sts	0x0074, r30
		/* If this is the first call to malloc then the heap will require
		initialisation to setup the list of free blocks. */
		if( xHeapHasBeenInitialised == pdFALSE )
		{
			prvHeapInit();
			xHeapHasBeenInitialised = pdTRUE;
     432:	81 e0       	ldi	r24, 0x01	; 1
     434:	80 93 6a 00 	sts	0x006A, r24
		}

		/* The wanted size is increased so it can contain a BlockLink_t
		structure in addition to the requested amount of bytes. */
		if( xWantedSize > 0 )
     438:	20 97       	sbiw	r28, 0x00	; 0
     43a:	09 f4       	brne	.+2      	; 0x43e <pvPortMalloc+0x5a>
     43c:	62 c0       	rjmp	.+196    	; 0x502 <pvPortMalloc+0x11e>
		{
			xWantedSize += heapSTRUCT_SIZE;
     43e:	9e 01       	movw	r18, r28
     440:	2c 5f       	subi	r18, 0xFC	; 252
     442:	3f 4f       	sbci	r19, 0xFF	; 255
				/* Byte alignment required. */
				xWantedSize += ( portBYTE_ALIGNMENT - ( xWantedSize & portBYTE_ALIGNMENT_MASK ) );
			}
		}

		if( ( xWantedSize > 0 ) && ( xWantedSize < configADJUSTED_HEAP_SIZE ) )
     444:	23 96       	adiw	r28, 0x03	; 3
     446:	83 e0       	ldi	r24, 0x03	; 3
     448:	ce 31       	cpi	r28, 0x1E	; 30
     44a:	d8 07       	cpc	r29, r24
     44c:	08 f0       	brcs	.+2      	; 0x450 <pvPortMalloc+0x6c>
     44e:	5c c0       	rjmp	.+184    	; 0x508 <pvPortMalloc+0x124>
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
			pxBlock = xStart.pxNextFreeBlock;
     450:	e0 91 6b 00 	lds	r30, 0x006B
     454:	f0 91 6c 00 	lds	r31, 0x006C

		if( ( xWantedSize > 0 ) && ( xWantedSize < configADJUSTED_HEAP_SIZE ) )
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
     458:	ab e6       	ldi	r26, 0x6B	; 107
     45a:	b0 e0       	ldi	r27, 0x00	; 0
			pxBlock = xStart.pxNextFreeBlock;
			while( ( pxBlock->xBlockSize < xWantedSize ) && ( pxBlock->pxNextFreeBlock != NULL ) )
     45c:	02 c0       	rjmp	.+4      	; 0x462 <pvPortMalloc+0x7e>
     45e:	df 01       	movw	r26, r30
			{
				pxPreviousBlock = pxBlock;
				pxBlock = pxBlock->pxNextFreeBlock;
     460:	fc 01       	movw	r30, r24
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
			pxBlock = xStart.pxNextFreeBlock;
			while( ( pxBlock->xBlockSize < xWantedSize ) && ( pxBlock->pxNextFreeBlock != NULL ) )
     462:	82 81       	ldd	r24, Z+2	; 0x02
     464:	93 81       	ldd	r25, Z+3	; 0x03
     466:	82 17       	cp	r24, r18
     468:	93 07       	cpc	r25, r19
     46a:	20 f4       	brcc	.+8      	; 0x474 <pvPortMalloc+0x90>
     46c:	80 81       	ld	r24, Z
     46e:	91 81       	ldd	r25, Z+1	; 0x01
     470:	00 97       	sbiw	r24, 0x00	; 0
     472:	a9 f7       	brne	.-22     	; 0x45e <pvPortMalloc+0x7a>
				pxPreviousBlock = pxBlock;
				pxBlock = pxBlock->pxNextFreeBlock;
			}

			/* If we found the end marker then a block of adequate size was not found. */
			if( pxBlock != &xEnd )
     474:	c0 e0       	ldi	r28, 0x00	; 0
     476:	ef 36       	cpi	r30, 0x6F	; 111
     478:	fc 07       	cpc	r31, r28
     47a:	09 f4       	brne	.+2      	; 0x47e <pvPortMalloc+0x9a>
     47c:	48 c0       	rjmp	.+144    	; 0x50e <pvPortMalloc+0x12a>
			{
				/* Return the memory space - jumping over the BlockLink_t structure
				at its start. */
				pvReturn = ( void * ) ( ( ( uint8_t * ) pxPreviousBlock->pxNextFreeBlock ) + heapSTRUCT_SIZE );
     47e:	8d 91       	ld	r24, X+
     480:	9c 91       	ld	r25, X
     482:	11 97       	sbiw	r26, 0x01	; 1
     484:	8c 01       	movw	r16, r24
     486:	0c 5f       	subi	r16, 0xFC	; 252
     488:	1f 4f       	sbci	r17, 0xFF	; 255

				/* This block is being returned for use so must be taken out of the
				list of free blocks. */
				pxPreviousBlock->pxNextFreeBlock = pxBlock->pxNextFreeBlock;
     48a:	80 81       	ld	r24, Z
     48c:	91 81       	ldd	r25, Z+1	; 0x01
     48e:	11 96       	adiw	r26, 0x01	; 1
     490:	9c 93       	st	X, r25
     492:	8e 93       	st	-X, r24

				/* If the block is larger than required it can be split into two. */
				if( ( pxBlock->xBlockSize - xWantedSize ) > heapMINIMUM_BLOCK_SIZE )
     494:	82 81       	ldd	r24, Z+2	; 0x02
     496:	93 81       	ldd	r25, Z+3	; 0x03
     498:	82 1b       	sub	r24, r18
     49a:	93 0b       	sbc	r25, r19
     49c:	89 30       	cpi	r24, 0x09	; 9
     49e:	91 05       	cpc	r25, r1
     4a0:	18 f1       	brcs	.+70     	; 0x4e8 <pvPortMalloc+0x104>
				{
					/* This block is to be split into two.  Create a new block
					following the number of bytes requested. The void cast is
					used to prevent byte alignment warnings from the compiler. */
					pxNewBlockLink = ( void * ) ( ( ( uint8_t * ) pxBlock ) + xWantedSize );
     4a2:	af 01       	movw	r20, r30
     4a4:	42 0f       	add	r20, r18
     4a6:	53 1f       	adc	r21, r19

					/* Calculate the sizes of two blocks split from the single
					block. */
					pxNewBlockLink->xBlockSize = pxBlock->xBlockSize - xWantedSize;
     4a8:	da 01       	movw	r26, r20
     4aa:	13 96       	adiw	r26, 0x03	; 3
     4ac:	9c 93       	st	X, r25
     4ae:	8e 93       	st	-X, r24
     4b0:	12 97       	sbiw	r26, 0x02	; 2
					pxBlock->xBlockSize = xWantedSize;
     4b2:	33 83       	std	Z+3, r19	; 0x03
     4b4:	22 83       	std	Z+2, r18	; 0x02

					/* Insert the new block into the list of free blocks. */
					prvInsertBlockIntoFreeList( ( pxNewBlockLink ) );
     4b6:	12 96       	adiw	r26, 0x02	; 2
     4b8:	2d 91       	ld	r18, X+
     4ba:	3c 91       	ld	r19, X
     4bc:	13 97       	sbiw	r26, 0x03	; 3
     4be:	6b e6       	ldi	r22, 0x6B	; 107
     4c0:	70 e0       	ldi	r23, 0x00	; 0
     4c2:	01 c0       	rjmp	.+2      	; 0x4c6 <pvPortMalloc+0xe2>
     4c4:	bd 01       	movw	r22, r26
     4c6:	eb 01       	movw	r28, r22
     4c8:	a8 81       	ld	r26, Y
     4ca:	b9 81       	ldd	r27, Y+1	; 0x01
     4cc:	12 96       	adiw	r26, 0x02	; 2
     4ce:	8d 91       	ld	r24, X+
     4d0:	9c 91       	ld	r25, X
     4d2:	13 97       	sbiw	r26, 0x03	; 3
     4d4:	82 17       	cp	r24, r18
     4d6:	93 07       	cpc	r25, r19
     4d8:	a8 f3       	brcs	.-22     	; 0x4c4 <pvPortMalloc+0xe0>
     4da:	ea 01       	movw	r28, r20
     4dc:	b9 83       	std	Y+1, r27	; 0x01
     4de:	a8 83       	st	Y, r26
     4e0:	db 01       	movw	r26, r22
     4e2:	11 96       	adiw	r26, 0x01	; 1
     4e4:	5c 93       	st	X, r21
     4e6:	4e 93       	st	-X, r20
				}

				xFreeBytesRemaining -= pxBlock->xBlockSize;
     4e8:	80 91 60 00 	lds	r24, 0x0060
     4ec:	90 91 61 00 	lds	r25, 0x0061
     4f0:	22 81       	ldd	r18, Z+2	; 0x02
     4f2:	33 81       	ldd	r19, Z+3	; 0x03
     4f4:	82 1b       	sub	r24, r18
     4f6:	93 0b       	sbc	r25, r19
     4f8:	90 93 61 00 	sts	0x0061, r25
     4fc:	80 93 60 00 	sts	0x0060, r24
     500:	08 c0       	rjmp	.+16     	; 0x512 <pvPortMalloc+0x12e>

void *pvPortMalloc( size_t xWantedSize )
{
BlockLink_t *pxBlock, *pxPreviousBlock, *pxNewBlockLink;
static BaseType_t xHeapHasBeenInitialised = pdFALSE;
void *pvReturn = NULL;
     502:	00 e0       	ldi	r16, 0x00	; 0
     504:	10 e0       	ldi	r17, 0x00	; 0
     506:	05 c0       	rjmp	.+10     	; 0x512 <pvPortMalloc+0x12e>
     508:	00 e0       	ldi	r16, 0x00	; 0
     50a:	10 e0       	ldi	r17, 0x00	; 0
     50c:	02 c0       	rjmp	.+4      	; 0x512 <pvPortMalloc+0x12e>
     50e:	00 e0       	ldi	r16, 0x00	; 0
     510:	10 e0       	ldi	r17, 0x00	; 0
			}
		}

		traceMALLOC( pvReturn, xWantedSize );
	}
	( void ) xTaskResumeAll();
     512:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>
		}
	}
	#endif

	return pvReturn;
}
     516:	80 2f       	mov	r24, r16
     518:	91 2f       	mov	r25, r17
     51a:	df 91       	pop	r29
     51c:	cf 91       	pop	r28
     51e:	1f 91       	pop	r17
     520:	0f 91       	pop	r16
     522:	08 95       	ret

00000524 <vPortFree>:
/*-----------------------------------------------------------*/

void vPortFree( void *pv )
{
     524:	0f 93       	push	r16
     526:	1f 93       	push	r17
     528:	cf 93       	push	r28
     52a:	df 93       	push	r29
     52c:	ec 01       	movw	r28, r24
uint8_t *puc = ( uint8_t * ) pv;
BlockLink_t *pxLink;

	if( pv != NULL )
     52e:	00 97       	sbiw	r24, 0x00	; 0
     530:	39 f1       	breq	.+78     	; 0x580 <vPortFree+0x5c>
		before it. */
		puc -= heapSTRUCT_SIZE;

		/* This unexpected casting is to keep some compilers from issuing
		byte alignment warnings. */
		pxLink = ( void * ) puc;
     532:	8c 01       	movw	r16, r24
     534:	04 50       	subi	r16, 0x04	; 4
     536:	10 40       	sbci	r17, 0x00	; 0

		vTaskSuspendAll();
     538:	0e 94 f3 0c 	call	0x19e6	; 0x19e6 <vTaskSuspendAll>
		{
			/* Add this block to the list of free blocks. */
			prvInsertBlockIntoFreeList( ( ( BlockLink_t * ) pxLink ) );
     53c:	f8 01       	movw	r30, r16
     53e:	22 81       	ldd	r18, Z+2	; 0x02
     540:	33 81       	ldd	r19, Z+3	; 0x03
     542:	ab e6       	ldi	r26, 0x6B	; 107
     544:	b0 e0       	ldi	r27, 0x00	; 0
     546:	01 c0       	rjmp	.+2      	; 0x54a <vPortFree+0x26>
     548:	df 01       	movw	r26, r30
     54a:	ed 91       	ld	r30, X+
     54c:	fc 91       	ld	r31, X
     54e:	11 97       	sbiw	r26, 0x01	; 1
     550:	82 81       	ldd	r24, Z+2	; 0x02
     552:	93 81       	ldd	r25, Z+3	; 0x03
     554:	82 17       	cp	r24, r18
     556:	93 07       	cpc	r25, r19
     558:	b8 f3       	brcs	.-18     	; 0x548 <vPortFree+0x24>
     55a:	24 97       	sbiw	r28, 0x04	; 4
     55c:	f9 83       	std	Y+1, r31	; 0x01
     55e:	e8 83       	st	Y, r30
     560:	0d 93       	st	X+, r16
     562:	1c 93       	st	X, r17
			xFreeBytesRemaining += pxLink->xBlockSize;
     564:	80 91 60 00 	lds	r24, 0x0060
     568:	90 91 61 00 	lds	r25, 0x0061
     56c:	2a 81       	ldd	r18, Y+2	; 0x02
     56e:	3b 81       	ldd	r19, Y+3	; 0x03
     570:	82 0f       	add	r24, r18
     572:	93 1f       	adc	r25, r19
     574:	90 93 61 00 	sts	0x0061, r25
     578:	80 93 60 00 	sts	0x0060, r24
			traceFREE( pv, pxLink->xBlockSize );
		}
		( void ) xTaskResumeAll();
     57c:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>
	}
}
     580:	df 91       	pop	r29
     582:	cf 91       	pop	r28
     584:	1f 91       	pop	r17
     586:	0f 91       	pop	r16
     588:	08 95       	ret

0000058a <xPortGetFreeHeapSize>:
/*-----------------------------------------------------------*/

size_t xPortGetFreeHeapSize( void )
{
	return xFreeBytesRemaining;
}
     58a:	80 91 60 00 	lds	r24, 0x0060
     58e:	90 91 61 00 	lds	r25, 0x0061
     592:	08 95       	ret

00000594 <vPortInitialiseBlocks>:
/*-----------------------------------------------------------*/

void vPortInitialiseBlocks( void )
{
	/* This just exists to keep the linker quiet. */
}
     594:	08 95       	ret

00000596 <vListInitialise>:
/*-----------------------------------------------------------
 * PUBLIC LIST API documented in list.h
 *----------------------------------------------------------*/

void vListInitialise( List_t * const pxList )
{
     596:	fc 01       	movw	r30, r24
	/* The list structure contains a list item which is used to mark the
	end of the list.  To initialise the list the list end is inserted
	as the only list entry. */
	pxList->pxIndex = ( ListItem_t * ) &( pxList->xListEnd );			/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     598:	03 96       	adiw	r24, 0x03	; 3
     59a:	92 83       	std	Z+2, r25	; 0x02
     59c:	81 83       	std	Z+1, r24	; 0x01

	/* The list end value is the highest possible value in the list to
	ensure it remains at the end of the list. */
	pxList->xListEnd.xItemValue = portMAX_DELAY;
     59e:	2f ef       	ldi	r18, 0xFF	; 255
     5a0:	3f ef       	ldi	r19, 0xFF	; 255
     5a2:	34 83       	std	Z+4, r19	; 0x04
     5a4:	23 83       	std	Z+3, r18	; 0x03

	/* The list end next and previous pointers point to itself so we know
	when the list is empty. */
	pxList->xListEnd.pxNext = ( ListItem_t * ) &( pxList->xListEnd );	/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     5a6:	96 83       	std	Z+6, r25	; 0x06
     5a8:	85 83       	std	Z+5, r24	; 0x05
	pxList->xListEnd.pxPrevious = ( ListItem_t * ) &( pxList->xListEnd );/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     5aa:	90 87       	std	Z+8, r25	; 0x08
     5ac:	87 83       	std	Z+7, r24	; 0x07

	pxList->uxNumberOfItems = ( UBaseType_t ) 0U;
     5ae:	10 82       	st	Z, r1

	/* Write known values into the list if
	configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
	listSET_LIST_INTEGRITY_CHECK_1_VALUE( pxList );
	listSET_LIST_INTEGRITY_CHECK_2_VALUE( pxList );
}
     5b0:	08 95       	ret

000005b2 <vListInitialiseItem>:
/*-----------------------------------------------------------*/

void vListInitialiseItem( ListItem_t * const pxItem )
{
	/* Make sure the list item is not recorded as being on a list. */
	pxItem->pvContainer = NULL;
     5b2:	fc 01       	movw	r30, r24
     5b4:	11 86       	std	Z+9, r1	; 0x09
     5b6:	10 86       	std	Z+8, r1	; 0x08

	/* Write known values into the list item if
	configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
	listSET_FIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem );
	listSET_SECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem );
}
     5b8:	08 95       	ret

000005ba <vListInsertEnd>:
/*-----------------------------------------------------------*/

void vListInsertEnd( List_t * const pxList, ListItem_t * const pxNewListItem )
{
     5ba:	cf 93       	push	r28
     5bc:	df 93       	push	r29
     5be:	fb 01       	movw	r30, r22
ListItem_t * const pxIndex = pxList->pxIndex;
     5c0:	dc 01       	movw	r26, r24
     5c2:	11 96       	adiw	r26, 0x01	; 1
     5c4:	cd 91       	ld	r28, X+
     5c6:	dc 91       	ld	r29, X
     5c8:	12 97       	sbiw	r26, 0x02	; 2
	listTEST_LIST_ITEM_INTEGRITY( pxNewListItem );

	/* Insert a new list item into pxList, but rather than sort the list,
	makes the new list item the last item to be removed by a call to
	listGET_OWNER_OF_NEXT_ENTRY(). */
	pxNewListItem->pxNext = pxIndex;
     5ca:	d3 83       	std	Z+3, r29	; 0x03
     5cc:	c2 83       	std	Z+2, r28	; 0x02
	pxNewListItem->pxPrevious = pxIndex->pxPrevious;
     5ce:	2c 81       	ldd	r18, Y+4	; 0x04
     5d0:	3d 81       	ldd	r19, Y+5	; 0x05
     5d2:	35 83       	std	Z+5, r19	; 0x05
     5d4:	24 83       	std	Z+4, r18	; 0x04

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	pxIndex->pxPrevious->pxNext = pxNewListItem;
     5d6:	ac 81       	ldd	r26, Y+4	; 0x04
     5d8:	bd 81       	ldd	r27, Y+5	; 0x05
     5da:	13 96       	adiw	r26, 0x03	; 3
     5dc:	7c 93       	st	X, r23
     5de:	6e 93       	st	-X, r22
     5e0:	12 97       	sbiw	r26, 0x02	; 2
	pxIndex->pxPrevious = pxNewListItem;
     5e2:	7d 83       	std	Y+5, r23	; 0x05
     5e4:	6c 83       	std	Y+4, r22	; 0x04

	/* Remember which list the item is in. */
	pxNewListItem->pvContainer = ( void * ) pxList;
     5e6:	91 87       	std	Z+9, r25	; 0x09
     5e8:	80 87       	std	Z+8, r24	; 0x08

	( pxList->uxNumberOfItems )++;
     5ea:	fc 01       	movw	r30, r24
     5ec:	20 81       	ld	r18, Z
     5ee:	2f 5f       	subi	r18, 0xFF	; 255
     5f0:	20 83       	st	Z, r18
}
     5f2:	df 91       	pop	r29
     5f4:	cf 91       	pop	r28
     5f6:	08 95       	ret

000005f8 <vListInsert>:
/*-----------------------------------------------------------*/

void vListInsert( List_t * const pxList, ListItem_t * const pxNewListItem )
{
     5f8:	cf 93       	push	r28
     5fa:	df 93       	push	r29
     5fc:	ac 01       	movw	r20, r24
     5fe:	eb 01       	movw	r28, r22
ListItem_t *pxIterator;
const TickType_t xValueOfInsertion = pxNewListItem->xItemValue;
     600:	28 81       	ld	r18, Y
     602:	39 81       	ldd	r19, Y+1	; 0x01
	new list item should be placed after it.  This ensures that TCB's which are
	stored in ready lists (all of which have the same xItemValue value) get a
	share of the CPU.  However, if the xItemValue is the same as the back marker
	the iteration loop below will not end.  Therefore the value is checked
	first, and the algorithm slightly modified if necessary. */
	if( xValueOfInsertion == portMAX_DELAY )
     604:	8f ef       	ldi	r24, 0xFF	; 255
     606:	2f 3f       	cpi	r18, 0xFF	; 255
     608:	38 07       	cpc	r19, r24
     60a:	21 f4       	brne	.+8      	; 0x614 <vListInsert+0x1c>
	{
		pxIterator = pxList->xListEnd.pxPrevious;
     60c:	fa 01       	movw	r30, r20
     60e:	a7 81       	ldd	r26, Z+7	; 0x07
     610:	b0 85       	ldd	r27, Z+8	; 0x08
     612:	0d c0       	rjmp	.+26     	; 0x62e <vListInsert+0x36>
			4) Using a queue or semaphore before it has been initialised or
			   before the scheduler has been started (are interrupts firing
			   before vTaskStartScheduler() has been called?).
		**********************************************************************/

		for( pxIterator = ( ListItem_t * ) &( pxList->xListEnd ); pxIterator->pxNext->xItemValue <= xValueOfInsertion; pxIterator = pxIterator->pxNext ) /*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     614:	da 01       	movw	r26, r20
     616:	13 96       	adiw	r26, 0x03	; 3
     618:	01 c0       	rjmp	.+2      	; 0x61c <vListInsert+0x24>
     61a:	df 01       	movw	r26, r30
     61c:	12 96       	adiw	r26, 0x02	; 2
     61e:	ed 91       	ld	r30, X+
     620:	fc 91       	ld	r31, X
     622:	13 97       	sbiw	r26, 0x03	; 3
     624:	80 81       	ld	r24, Z
     626:	91 81       	ldd	r25, Z+1	; 0x01
     628:	28 17       	cp	r18, r24
     62a:	39 07       	cpc	r19, r25
     62c:	b0 f7       	brcc	.-20     	; 0x61a <vListInsert+0x22>
			/* There is nothing to do here, just iterating to the wanted
			insertion position. */
		}
	}

	pxNewListItem->pxNext = pxIterator->pxNext;
     62e:	12 96       	adiw	r26, 0x02	; 2
     630:	ed 91       	ld	r30, X+
     632:	fc 91       	ld	r31, X
     634:	13 97       	sbiw	r26, 0x03	; 3
     636:	fb 83       	std	Y+3, r31	; 0x03
     638:	ea 83       	std	Y+2, r30	; 0x02
	pxNewListItem->pxNext->pxPrevious = pxNewListItem;
     63a:	d5 83       	std	Z+5, r29	; 0x05
     63c:	c4 83       	std	Z+4, r28	; 0x04
	pxNewListItem->pxPrevious = pxIterator;
     63e:	bd 83       	std	Y+5, r27	; 0x05
     640:	ac 83       	std	Y+4, r26	; 0x04
	pxIterator->pxNext = pxNewListItem;
     642:	13 96       	adiw	r26, 0x03	; 3
     644:	dc 93       	st	X, r29
     646:	ce 93       	st	-X, r28
     648:	12 97       	sbiw	r26, 0x02	; 2

	/* Remember which list the item is in.  This allows fast removal of the
	item later. */
	pxNewListItem->pvContainer = ( void * ) pxList;
     64a:	59 87       	std	Y+9, r21	; 0x09
     64c:	48 87       	std	Y+8, r20	; 0x08

	( pxList->uxNumberOfItems )++;
     64e:	fa 01       	movw	r30, r20
     650:	80 81       	ld	r24, Z
     652:	8f 5f       	subi	r24, 0xFF	; 255
     654:	80 83       	st	Z, r24
}
     656:	df 91       	pop	r29
     658:	cf 91       	pop	r28
     65a:	08 95       	ret

0000065c <uxListRemove>:
/*-----------------------------------------------------------*/

UBaseType_t uxListRemove( ListItem_t * const pxItemToRemove )
{
     65c:	cf 93       	push	r28
     65e:	df 93       	push	r29
     660:	fc 01       	movw	r30, r24
/* The list item knows which list it is in.  Obtain the list from the list
item. */
List_t * const pxList = ( List_t * ) pxItemToRemove->pvContainer;
     662:	c0 85       	ldd	r28, Z+8	; 0x08
     664:	d1 85       	ldd	r29, Z+9	; 0x09

	pxItemToRemove->pxNext->pxPrevious = pxItemToRemove->pxPrevious;
     666:	a2 81       	ldd	r26, Z+2	; 0x02
     668:	b3 81       	ldd	r27, Z+3	; 0x03
     66a:	84 81       	ldd	r24, Z+4	; 0x04
     66c:	95 81       	ldd	r25, Z+5	; 0x05
     66e:	15 96       	adiw	r26, 0x05	; 5
     670:	9c 93       	st	X, r25
     672:	8e 93       	st	-X, r24
     674:	14 97       	sbiw	r26, 0x04	; 4
	pxItemToRemove->pxPrevious->pxNext = pxItemToRemove->pxNext;
     676:	a4 81       	ldd	r26, Z+4	; 0x04
     678:	b5 81       	ldd	r27, Z+5	; 0x05
     67a:	82 81       	ldd	r24, Z+2	; 0x02
     67c:	93 81       	ldd	r25, Z+3	; 0x03
     67e:	13 96       	adiw	r26, 0x03	; 3
     680:	9c 93       	st	X, r25
     682:	8e 93       	st	-X, r24
     684:	12 97       	sbiw	r26, 0x02	; 2

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	/* Make sure the index is left pointing to a valid item. */
	if( pxList->pxIndex == pxItemToRemove )
     686:	a9 81       	ldd	r26, Y+1	; 0x01
     688:	ba 81       	ldd	r27, Y+2	; 0x02
     68a:	ae 17       	cp	r26, r30
     68c:	bf 07       	cpc	r27, r31
     68e:	31 f4       	brne	.+12     	; 0x69c <uxListRemove+0x40>
	{
		pxList->pxIndex = pxItemToRemove->pxPrevious;
     690:	14 96       	adiw	r26, 0x04	; 4
     692:	8d 91       	ld	r24, X+
     694:	9c 91       	ld	r25, X
     696:	15 97       	sbiw	r26, 0x05	; 5
     698:	9a 83       	std	Y+2, r25	; 0x02
     69a:	89 83       	std	Y+1, r24	; 0x01
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxItemToRemove->pvContainer = NULL;
     69c:	11 86       	std	Z+9, r1	; 0x09
     69e:	10 86       	std	Z+8, r1	; 0x08
	( pxList->uxNumberOfItems )--;
     6a0:	88 81       	ld	r24, Y
     6a2:	81 50       	subi	r24, 0x01	; 1
     6a4:	88 83       	st	Y, r24

	return pxList->uxNumberOfItems;
}
     6a6:	df 91       	pop	r29
     6a8:	cf 91       	pop	r28
     6aa:	08 95       	ret

000006ac <pxPortInitialiseStack>:
uint16_t usAddress;

	/* Place a few bytes of known values on the bottom of the stack. 
	This is just useful for debugging. */

	*pxTopOfStack = 0x11;
     6ac:	21 e1       	ldi	r18, 0x11	; 17
     6ae:	fc 01       	movw	r30, r24
     6b0:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = 0x22;
     6b2:	31 97       	sbiw	r30, 0x01	; 1
     6b4:	32 e2       	ldi	r19, 0x22	; 34
     6b6:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = 0x33;
     6b8:	fc 01       	movw	r30, r24
     6ba:	32 97       	sbiw	r30, 0x02	; 2
     6bc:	a3 e3       	ldi	r26, 0x33	; 51
     6be:	a0 83       	st	Z, r26
	/*lint -e950 -e611 -e923 Lint doesn't like this much - but nothing I can do about it. */

	/* The start of the task code will be popped off the stack last, so place
	it on first. */
	usAddress = ( uint16_t ) pxCode;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     6c0:	fc 01       	movw	r30, r24
     6c2:	33 97       	sbiw	r30, 0x03	; 3
     6c4:	60 83       	st	Z, r22
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     6c6:	fc 01       	movw	r30, r24
     6c8:	34 97       	sbiw	r30, 0x04	; 4
     6ca:	70 83       	st	Z, r23

	/* Next simulate the stack as if after a call to portSAVE_CONTEXT().  
	portSAVE_CONTEXT places the flags on the stack immediately after r0
	to ensure the interrupts get disabled as soon as possible, and so ensuring
	the stack use is minimal should a context switch interrupt occur. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R0 */
     6cc:	fc 01       	movw	r30, r24
     6ce:	35 97       	sbiw	r30, 0x05	; 5
     6d0:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = portFLAGS_INT_ENABLED;
     6d2:	fc 01       	movw	r30, r24
     6d4:	36 97       	sbiw	r30, 0x06	; 6
     6d6:	60 e8       	ldi	r22, 0x80	; 128
     6d8:	60 83       	st	Z, r22
	pxTopOfStack--;


	/* Now the remaining registers.   The compiler expects R1 to be 0. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R1 */
     6da:	fc 01       	movw	r30, r24
     6dc:	37 97       	sbiw	r30, 0x07	; 7
     6de:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x02;	/* R2 */
     6e0:	fc 01       	movw	r30, r24
     6e2:	38 97       	sbiw	r30, 0x08	; 8
     6e4:	62 e0       	ldi	r22, 0x02	; 2
     6e6:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x03;	/* R3 */
     6e8:	fc 01       	movw	r30, r24
     6ea:	39 97       	sbiw	r30, 0x09	; 9
     6ec:	63 e0       	ldi	r22, 0x03	; 3
     6ee:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x04;	/* R4 */
     6f0:	fc 01       	movw	r30, r24
     6f2:	3a 97       	sbiw	r30, 0x0a	; 10
     6f4:	64 e0       	ldi	r22, 0x04	; 4
     6f6:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x05;	/* R5 */
     6f8:	fc 01       	movw	r30, r24
     6fa:	3b 97       	sbiw	r30, 0x0b	; 11
     6fc:	65 e0       	ldi	r22, 0x05	; 5
     6fe:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x06;	/* R6 */
     700:	fc 01       	movw	r30, r24
     702:	3c 97       	sbiw	r30, 0x0c	; 12
     704:	66 e0       	ldi	r22, 0x06	; 6
     706:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x07;	/* R7 */
     708:	fc 01       	movw	r30, r24
     70a:	3d 97       	sbiw	r30, 0x0d	; 13
     70c:	67 e0       	ldi	r22, 0x07	; 7
     70e:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x08;	/* R8 */
     710:	fc 01       	movw	r30, r24
     712:	3e 97       	sbiw	r30, 0x0e	; 14
     714:	68 e0       	ldi	r22, 0x08	; 8
     716:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x09;	/* R9 */
     718:	fc 01       	movw	r30, r24
     71a:	3f 97       	sbiw	r30, 0x0f	; 15
     71c:	69 e0       	ldi	r22, 0x09	; 9
     71e:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x10;	/* R10 */
     720:	fc 01       	movw	r30, r24
     722:	70 97       	sbiw	r30, 0x10	; 16
     724:	60 e1       	ldi	r22, 0x10	; 16
     726:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x11;	/* R11 */
     728:	fc 01       	movw	r30, r24
     72a:	71 97       	sbiw	r30, 0x11	; 17
     72c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x12;	/* R12 */
     72e:	fc 01       	movw	r30, r24
     730:	72 97       	sbiw	r30, 0x12	; 18
     732:	22 e1       	ldi	r18, 0x12	; 18
     734:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x13;	/* R13 */
     736:	fc 01       	movw	r30, r24
     738:	73 97       	sbiw	r30, 0x13	; 19
     73a:	23 e1       	ldi	r18, 0x13	; 19
     73c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x14;	/* R14 */
     73e:	fc 01       	movw	r30, r24
     740:	74 97       	sbiw	r30, 0x14	; 20
     742:	24 e1       	ldi	r18, 0x14	; 20
     744:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x15;	/* R15 */
     746:	fc 01       	movw	r30, r24
     748:	75 97       	sbiw	r30, 0x15	; 21
     74a:	25 e1       	ldi	r18, 0x15	; 21
     74c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x16;	/* R16 */
     74e:	fc 01       	movw	r30, r24
     750:	76 97       	sbiw	r30, 0x16	; 22
     752:	26 e1       	ldi	r18, 0x16	; 22
     754:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x17;	/* R17 */
     756:	fc 01       	movw	r30, r24
     758:	77 97       	sbiw	r30, 0x17	; 23
     75a:	27 e1       	ldi	r18, 0x17	; 23
     75c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x18;	/* R18 */
     75e:	fc 01       	movw	r30, r24
     760:	78 97       	sbiw	r30, 0x18	; 24
     762:	28 e1       	ldi	r18, 0x18	; 24
     764:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x19;	/* R19 */
     766:	fc 01       	movw	r30, r24
     768:	79 97       	sbiw	r30, 0x19	; 25
     76a:	29 e1       	ldi	r18, 0x19	; 25
     76c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x20;	/* R20 */
     76e:	fc 01       	movw	r30, r24
     770:	7a 97       	sbiw	r30, 0x1a	; 26
     772:	20 e2       	ldi	r18, 0x20	; 32
     774:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x21;	/* R21 */
     776:	fc 01       	movw	r30, r24
     778:	7b 97       	sbiw	r30, 0x1b	; 27
     77a:	21 e2       	ldi	r18, 0x21	; 33
     77c:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x22;	/* R22 */
     77e:	fc 01       	movw	r30, r24
     780:	7c 97       	sbiw	r30, 0x1c	; 28
     782:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x23;	/* R23 */
     784:	fc 01       	movw	r30, r24
     786:	7d 97       	sbiw	r30, 0x1d	; 29
     788:	23 e2       	ldi	r18, 0x23	; 35
     78a:	20 83       	st	Z, r18
	pxTopOfStack--;

	/* Place the parameter on the stack in the expected location. */
	usAddress = ( uint16_t ) pvParameters;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     78c:	fc 01       	movw	r30, r24
     78e:	7e 97       	sbiw	r30, 0x1e	; 30
     790:	40 83       	st	Z, r20
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     792:	fc 01       	movw	r30, r24
     794:	7f 97       	sbiw	r30, 0x1f	; 31
     796:	50 83       	st	Z, r21
	pxTopOfStack--;

	*pxTopOfStack = ( StackType_t ) 0x26;	/* R26 X */
     798:	fc 01       	movw	r30, r24
     79a:	b0 97       	sbiw	r30, 0x20	; 32
     79c:	26 e2       	ldi	r18, 0x26	; 38
     79e:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x27;	/* R27 */
     7a0:	fc 01       	movw	r30, r24
     7a2:	b1 97       	sbiw	r30, 0x21	; 33
     7a4:	27 e2       	ldi	r18, 0x27	; 39
     7a6:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x28;	/* R28 Y */
     7a8:	fc 01       	movw	r30, r24
     7aa:	b2 97       	sbiw	r30, 0x22	; 34
     7ac:	28 e2       	ldi	r18, 0x28	; 40
     7ae:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x29;	/* R29 */
     7b0:	fc 01       	movw	r30, r24
     7b2:	b3 97       	sbiw	r30, 0x23	; 35
     7b4:	29 e2       	ldi	r18, 0x29	; 41
     7b6:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x30;	/* R30 Z */
     7b8:	fc 01       	movw	r30, r24
     7ba:	b4 97       	sbiw	r30, 0x24	; 36
     7bc:	20 e3       	ldi	r18, 0x30	; 48
     7be:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x031;	/* R31 */
     7c0:	fc 01       	movw	r30, r24
     7c2:	b5 97       	sbiw	r30, 0x25	; 37
     7c4:	21 e3       	ldi	r18, 0x31	; 49
     7c6:	20 83       	st	Z, r18
	pxTopOfStack--;

	/*lint +e950 +e611 +e923 */

	return pxTopOfStack;
     7c8:	86 97       	sbiw	r24, 0x26	; 38
}
     7ca:	08 95       	ret

000007cc <xPortStartScheduler>:
	/* Setup compare match value for compare match A.  Interrupts are disabled 
	before this is called so we need not worry here. */
	ucLowByte = ( uint8_t ) ( ulCompareMatch & ( uint32_t ) 0xff );
	ulCompareMatch >>= 8;
	ucHighByte = ( uint8_t ) ( ulCompareMatch & ( uint32_t ) 0xff );
	OCR1AH = ucHighByte;
     7cc:	1b bc       	out	0x2b, r1	; 43
	OCR1AL = ucLowByte;
     7ce:	8c e7       	ldi	r24, 0x7C	; 124
     7d0:	8a bd       	out	0x2a, r24	; 42

	/* Setup clock source and compare match behaviour. */
	ucLowByte = portCLEAR_COUNTER_ON_MATCH | portPRESCALE_64;
	TCCR1B = ucLowByte;
     7d2:	8b e0       	ldi	r24, 0x0B	; 11
     7d4:	8e bd       	out	0x2e, r24	; 46

	/* Enable the interrupt - this is okay as interrupt are currently globally
	disabled. */
	ucLowByte = TIMSK;
     7d6:	89 b7       	in	r24, 0x39	; 57
	ucLowByte |= portCOMPARE_MATCH_A_INTERRUPT_ENABLE;
     7d8:	80 61       	ori	r24, 0x10	; 16
	TIMSK = ucLowByte;
     7da:	89 bf       	out	0x39, r24	; 57
{
	/* Setup the hardware to generate the tick. */
	prvSetupTimerInterrupt();

	/* Restore the context of the first task that is going to run. */
	portRESTORE_CONTEXT();
     7dc:	a0 91 97 03 	lds	r26, 0x0397
     7e0:	b0 91 98 03 	lds	r27, 0x0398
     7e4:	cd 91       	ld	r28, X+
     7e6:	cd bf       	out	0x3d, r28	; 61
     7e8:	dd 91       	ld	r29, X+
     7ea:	de bf       	out	0x3e, r29	; 62
     7ec:	ff 91       	pop	r31
     7ee:	ef 91       	pop	r30
     7f0:	df 91       	pop	r29
     7f2:	cf 91       	pop	r28
     7f4:	bf 91       	pop	r27
     7f6:	af 91       	pop	r26
     7f8:	9f 91       	pop	r25
     7fa:	8f 91       	pop	r24
     7fc:	7f 91       	pop	r23
     7fe:	6f 91       	pop	r22
     800:	5f 91       	pop	r21
     802:	4f 91       	pop	r20
     804:	3f 91       	pop	r19
     806:	2f 91       	pop	r18
     808:	1f 91       	pop	r17
     80a:	0f 91       	pop	r16
     80c:	ff 90       	pop	r15
     80e:	ef 90       	pop	r14
     810:	df 90       	pop	r13
     812:	cf 90       	pop	r12
     814:	bf 90       	pop	r11
     816:	af 90       	pop	r10
     818:	9f 90       	pop	r9
     81a:	8f 90       	pop	r8
     81c:	7f 90       	pop	r7
     81e:	6f 90       	pop	r6
     820:	5f 90       	pop	r5
     822:	4f 90       	pop	r4
     824:	3f 90       	pop	r3
     826:	2f 90       	pop	r2
     828:	1f 90       	pop	r1
     82a:	0f 90       	pop	r0
     82c:	0f be       	out	0x3f, r0	; 63
     82e:	0f 90       	pop	r0

	/* Simulate a function call end as generated by the compiler.  We will now
	jump to the start of the task the context of which we have just restored. */
	asm volatile ( "ret" );
     830:	08 95       	ret

	/* Should not get here. */
	return pdTRUE;
}
     832:	81 e0       	ldi	r24, 0x01	; 1
     834:	08 95       	ret

00000836 <vPortEndScheduler>:

void vPortEndScheduler( void )
{
	/* It is unlikely that the AVR port will get stopped.  If required simply
	disable the tick interrupt here. */
}
     836:	08 95       	ret

00000838 <vPortYield>:
 * can use a naked attribute.
 */
void vPortYield( void ) __attribute__ ( ( naked ) );
void vPortYield( void )
{
	portSAVE_CONTEXT();
     838:	0f 92       	push	r0
     83a:	0f b6       	in	r0, 0x3f	; 63
     83c:	f8 94       	cli
     83e:	0f 92       	push	r0
     840:	1f 92       	push	r1
     842:	11 24       	eor	r1, r1
     844:	2f 92       	push	r2
     846:	3f 92       	push	r3
     848:	4f 92       	push	r4
     84a:	5f 92       	push	r5
     84c:	6f 92       	push	r6
     84e:	7f 92       	push	r7
     850:	8f 92       	push	r8
     852:	9f 92       	push	r9
     854:	af 92       	push	r10
     856:	bf 92       	push	r11
     858:	cf 92       	push	r12
     85a:	df 92       	push	r13
     85c:	ef 92       	push	r14
     85e:	ff 92       	push	r15
     860:	0f 93       	push	r16
     862:	1f 93       	push	r17
     864:	2f 93       	push	r18
     866:	3f 93       	push	r19
     868:	4f 93       	push	r20
     86a:	5f 93       	push	r21
     86c:	6f 93       	push	r22
     86e:	7f 93       	push	r23
     870:	8f 93       	push	r24
     872:	9f 93       	push	r25
     874:	af 93       	push	r26
     876:	bf 93       	push	r27
     878:	cf 93       	push	r28
     87a:	df 93       	push	r29
     87c:	ef 93       	push	r30
     87e:	ff 93       	push	r31
     880:	a0 91 97 03 	lds	r26, 0x0397
     884:	b0 91 98 03 	lds	r27, 0x0398
     888:	0d b6       	in	r0, 0x3d	; 61
     88a:	0d 92       	st	X+, r0
     88c:	0e b6       	in	r0, 0x3e	; 62
     88e:	0d 92       	st	X+, r0
	vTaskSwitchContext();
     890:	0e 94 dc 0e 	call	0x1db8	; 0x1db8 <vTaskSwitchContext>
	portRESTORE_CONTEXT();
     894:	a0 91 97 03 	lds	r26, 0x0397
     898:	b0 91 98 03 	lds	r27, 0x0398
     89c:	cd 91       	ld	r28, X+
     89e:	cd bf       	out	0x3d, r28	; 61
     8a0:	dd 91       	ld	r29, X+
     8a2:	de bf       	out	0x3e, r29	; 62
     8a4:	ff 91       	pop	r31
     8a6:	ef 91       	pop	r30
     8a8:	df 91       	pop	r29
     8aa:	cf 91       	pop	r28
     8ac:	bf 91       	pop	r27
     8ae:	af 91       	pop	r26
     8b0:	9f 91       	pop	r25
     8b2:	8f 91       	pop	r24
     8b4:	7f 91       	pop	r23
     8b6:	6f 91       	pop	r22
     8b8:	5f 91       	pop	r21
     8ba:	4f 91       	pop	r20
     8bc:	3f 91       	pop	r19
     8be:	2f 91       	pop	r18
     8c0:	1f 91       	pop	r17
     8c2:	0f 91       	pop	r16
     8c4:	ff 90       	pop	r15
     8c6:	ef 90       	pop	r14
     8c8:	df 90       	pop	r13
     8ca:	cf 90       	pop	r12
     8cc:	bf 90       	pop	r11
     8ce:	af 90       	pop	r10
     8d0:	9f 90       	pop	r9
     8d2:	8f 90       	pop	r8
     8d4:	7f 90       	pop	r7
     8d6:	6f 90       	pop	r6
     8d8:	5f 90       	pop	r5
     8da:	4f 90       	pop	r4
     8dc:	3f 90       	pop	r3
     8de:	2f 90       	pop	r2
     8e0:	1f 90       	pop	r1
     8e2:	0f 90       	pop	r0
     8e4:	0f be       	out	0x3f, r0	; 63
     8e6:	0f 90       	pop	r0

	asm volatile ( "ret" );
     8e8:	08 95       	ret

000008ea <vPortYieldFromTick>:
 * call comes from the tick ISR.
 */
void vPortYieldFromTick( void ) __attribute__ ( ( naked ) );
void vPortYieldFromTick( void )
{
	portSAVE_CONTEXT();
     8ea:	0f 92       	push	r0
     8ec:	0f b6       	in	r0, 0x3f	; 63
     8ee:	f8 94       	cli
     8f0:	0f 92       	push	r0
     8f2:	1f 92       	push	r1
     8f4:	11 24       	eor	r1, r1
     8f6:	2f 92       	push	r2
     8f8:	3f 92       	push	r3
     8fa:	4f 92       	push	r4
     8fc:	5f 92       	push	r5
     8fe:	6f 92       	push	r6
     900:	7f 92       	push	r7
     902:	8f 92       	push	r8
     904:	9f 92       	push	r9
     906:	af 92       	push	r10
     908:	bf 92       	push	r11
     90a:	cf 92       	push	r12
     90c:	df 92       	push	r13
     90e:	ef 92       	push	r14
     910:	ff 92       	push	r15
     912:	0f 93       	push	r16
     914:	1f 93       	push	r17
     916:	2f 93       	push	r18
     918:	3f 93       	push	r19
     91a:	4f 93       	push	r20
     91c:	5f 93       	push	r21
     91e:	6f 93       	push	r22
     920:	7f 93       	push	r23
     922:	8f 93       	push	r24
     924:	9f 93       	push	r25
     926:	af 93       	push	r26
     928:	bf 93       	push	r27
     92a:	cf 93       	push	r28
     92c:	df 93       	push	r29
     92e:	ef 93       	push	r30
     930:	ff 93       	push	r31
     932:	a0 91 97 03 	lds	r26, 0x0397
     936:	b0 91 98 03 	lds	r27, 0x0398
     93a:	0d b6       	in	r0, 0x3d	; 61
     93c:	0d 92       	st	X+, r0
     93e:	0e b6       	in	r0, 0x3e	; 62
     940:	0d 92       	st	X+, r0
	if( xTaskIncrementTick() != pdFALSE )
     942:	0e 94 13 0d 	call	0x1a26	; 0x1a26 <xTaskIncrementTick>
     946:	88 23       	and	r24, r24
     948:	11 f0       	breq	.+4      	; 0x94e <vPortYieldFromTick+0x64>
	{
		vTaskSwitchContext();
     94a:	0e 94 dc 0e 	call	0x1db8	; 0x1db8 <vTaskSwitchContext>
	}
	portRESTORE_CONTEXT();
     94e:	a0 91 97 03 	lds	r26, 0x0397
     952:	b0 91 98 03 	lds	r27, 0x0398
     956:	cd 91       	ld	r28, X+
     958:	cd bf       	out	0x3d, r28	; 61
     95a:	dd 91       	ld	r29, X+
     95c:	de bf       	out	0x3e, r29	; 62
     95e:	ff 91       	pop	r31
     960:	ef 91       	pop	r30
     962:	df 91       	pop	r29
     964:	cf 91       	pop	r28
     966:	bf 91       	pop	r27
     968:	af 91       	pop	r26
     96a:	9f 91       	pop	r25
     96c:	8f 91       	pop	r24
     96e:	7f 91       	pop	r23
     970:	6f 91       	pop	r22
     972:	5f 91       	pop	r21
     974:	4f 91       	pop	r20
     976:	3f 91       	pop	r19
     978:	2f 91       	pop	r18
     97a:	1f 91       	pop	r17
     97c:	0f 91       	pop	r16
     97e:	ff 90       	pop	r15
     980:	ef 90       	pop	r14
     982:	df 90       	pop	r13
     984:	cf 90       	pop	r12
     986:	bf 90       	pop	r11
     988:	af 90       	pop	r10
     98a:	9f 90       	pop	r9
     98c:	8f 90       	pop	r8
     98e:	7f 90       	pop	r7
     990:	6f 90       	pop	r6
     992:	5f 90       	pop	r5
     994:	4f 90       	pop	r4
     996:	3f 90       	pop	r3
     998:	2f 90       	pop	r2
     99a:	1f 90       	pop	r1
     99c:	0f 90       	pop	r0
     99e:	0f be       	out	0x3f, r0	; 63
     9a0:	0f 90       	pop	r0

	asm volatile ( "ret" );
     9a2:	08 95       	ret

000009a4 <__vector_7>:
	 * count is incremented after the context is saved.
	 */
	void TIMER1_COMPA_vect( void ) __attribute__ ( ( signal, naked ) );
	void TIMER1_COMPA_vect( void )
	{
		vPortYieldFromTick();
     9a4:	0e 94 75 04 	call	0x8ea	; 0x8ea <vPortYieldFromTick>
		asm volatile ( "reti" );
     9a8:	18 95       	reti

000009aa <prvIsQueueEmpty>:

static BaseType_t prvIsQueueEmpty( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
     9aa:	0f b6       	in	r0, 0x3f	; 63
     9ac:	f8 94       	cli
     9ae:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == ( UBaseType_t )  0 )
     9b0:	fc 01       	movw	r30, r24
     9b2:	92 8d       	ldd	r25, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
     9b4:	0f 90       	pop	r0
     9b6:	0f be       	out	0x3f, r0	; 63

	taskENTER_CRITICAL();
	{
		if( pxQueue->uxMessagesWaiting == ( UBaseType_t )  0 )
		{
			xReturn = pdTRUE;
     9b8:	81 e0       	ldi	r24, 0x01	; 1
     9ba:	91 11       	cpse	r25, r1
     9bc:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	taskEXIT_CRITICAL();

	return xReturn;
}
     9be:	08 95       	ret

000009c0 <prvCopyDataFromQueue>:
	return xReturn;
}
/*-----------------------------------------------------------*/

static void prvCopyDataFromQueue( Queue_t * const pxQueue, void * const pvBuffer )
{
     9c0:	fc 01       	movw	r30, r24
	if( pxQueue->uxItemSize != ( UBaseType_t ) 0 )
     9c2:	44 8d       	ldd	r20, Z+28	; 0x1c
     9c4:	44 23       	and	r20, r20
     9c6:	c1 f0       	breq	.+48     	; 0x9f8 <prvCopyDataFromQueue+0x38>
	{
		pxQueue->u.pcReadFrom += pxQueue->uxItemSize;
     9c8:	26 81       	ldd	r18, Z+6	; 0x06
     9ca:	37 81       	ldd	r19, Z+7	; 0x07
     9cc:	24 0f       	add	r18, r20
     9ce:	31 1d       	adc	r19, r1
     9d0:	37 83       	std	Z+7, r19	; 0x07
     9d2:	26 83       	std	Z+6, r18	; 0x06
		if( pxQueue->u.pcReadFrom >= pxQueue->pcTail ) /*lint !e946 MISRA exception justified as use of the relational operator is the cleanest solutions. */
     9d4:	a2 81       	ldd	r26, Z+2	; 0x02
     9d6:	b3 81       	ldd	r27, Z+3	; 0x03
     9d8:	2a 17       	cp	r18, r26
     9da:	3b 07       	cpc	r19, r27
     9dc:	20 f0       	brcs	.+8      	; 0x9e6 <prvCopyDataFromQueue+0x26>
		{
			pxQueue->u.pcReadFrom = pxQueue->pcHead;
     9de:	20 81       	ld	r18, Z
     9e0:	31 81       	ldd	r19, Z+1	; 0x01
     9e2:	37 83       	std	Z+7, r19	; 0x07
     9e4:	26 83       	std	Z+6, r18	; 0x06
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
		( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.pcReadFrom, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports.  Also previous logic ensures a null pointer can only be passed to memcpy() when the count is 0. */
     9e6:	36 81       	ldd	r19, Z+6	; 0x06
     9e8:	27 81       	ldd	r18, Z+7	; 0x07
     9ea:	86 2f       	mov	r24, r22
     9ec:	97 2f       	mov	r25, r23
     9ee:	63 2f       	mov	r22, r19
     9f0:	72 2f       	mov	r23, r18
     9f2:	50 e0       	ldi	r21, 0x00	; 0
     9f4:	0e 94 9e 13 	call	0x273c	; 0x273c <memcpy>
     9f8:	08 95       	ret

000009fa <prvUnlockQueue>:
	}
}
/*-----------------------------------------------------------*/

static void prvUnlockQueue( Queue_t * const pxQueue )
{
     9fa:	ef 92       	push	r14
     9fc:	ff 92       	push	r15
     9fe:	0f 93       	push	r16
     a00:	1f 93       	push	r17
     a02:	cf 93       	push	r28
     a04:	8c 01       	movw	r16, r24

	/* The lock counts contains the number of extra data items placed or
	removed from the queue while the queue was locked.  When a queue is
	locked items can be added or removed, but the event lists cannot be
	updated. */
	taskENTER_CRITICAL();
     a06:	0f b6       	in	r0, 0x3f	; 63
     a08:	f8 94       	cli
     a0a:	0f 92       	push	r0
	{
		int8_t cTxLock = pxQueue->cTxLock;
     a0c:	fc 01       	movw	r30, r24
     a0e:	c6 8d       	ldd	r28, Z+30	; 0x1e

		/* See if data was added to the queue while it was locked. */
		while( cTxLock > queueLOCKED_UNMODIFIED )
     a10:	1c 16       	cp	r1, r28
     a12:	cc f4       	brge	.+50     	; 0xa46 <prvUnlockQueue+0x4c>
			}
			#else /* configUSE_QUEUE_SETS */
			{
				/* Tasks that are removed from the event list will get added to
				the pending ready list as the scheduler is still suspended. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     a14:	81 89       	ldd	r24, Z+17	; 0x11
     a16:	88 23       	and	r24, r24
     a18:	31 f4       	brne	.+12     	; 0xa26 <prvUnlockQueue+0x2c>
     a1a:	15 c0       	rjmp	.+42     	; 0xa46 <prvUnlockQueue+0x4c>
     a1c:	f8 01       	movw	r30, r16
     a1e:	81 89       	ldd	r24, Z+17	; 0x11
     a20:	88 23       	and	r24, r24
     a22:	41 f4       	brne	.+16     	; 0xa34 <prvUnlockQueue+0x3a>
     a24:	10 c0       	rjmp	.+32     	; 0xa46 <prvUnlockQueue+0x4c>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     a26:	0f 2e       	mov	r0, r31
     a28:	f1 e1       	ldi	r31, 0x11	; 17
     a2a:	ef 2e       	mov	r14, r31
     a2c:	ff 24       	eor	r15, r15
     a2e:	f0 2d       	mov	r31, r0
     a30:	e0 0e       	add	r14, r16
     a32:	f1 1e       	adc	r15, r17
     a34:	c7 01       	movw	r24, r14
     a36:	0e 94 b2 0f 	call	0x1f64	; 0x1f64 <xTaskRemoveFromEventList>
     a3a:	88 23       	and	r24, r24
     a3c:	11 f0       	breq	.+4      	; 0xa42 <prvUnlockQueue+0x48>
					{
						/* The task waiting has a higher priority so record that
						a context switch is required. */
						vTaskMissedYield();
     a3e:	0e 94 77 10 	call	0x20ee	; 0x20ee <vTaskMissedYield>
					break;
				}
			}
			#endif /* configUSE_QUEUE_SETS */

			--cTxLock;
     a42:	c1 50       	subi	r28, 0x01	; 1
	taskENTER_CRITICAL();
	{
		int8_t cTxLock = pxQueue->cTxLock;

		/* See if data was added to the queue while it was locked. */
		while( cTxLock > queueLOCKED_UNMODIFIED )
     a44:	59 f7       	brne	.-42     	; 0xa1c <prvUnlockQueue+0x22>
			#endif /* configUSE_QUEUE_SETS */

			--cTxLock;
		}

		pxQueue->cTxLock = queueUNLOCKED;
     a46:	8f ef       	ldi	r24, 0xFF	; 255
     a48:	f8 01       	movw	r30, r16
     a4a:	86 8f       	std	Z+30, r24	; 0x1e
	}
	taskEXIT_CRITICAL();
     a4c:	0f 90       	pop	r0
     a4e:	0f be       	out	0x3f, r0	; 63

	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
     a50:	0f b6       	in	r0, 0x3f	; 63
     a52:	f8 94       	cli
     a54:	0f 92       	push	r0
	{
		int8_t cRxLock = pxQueue->cRxLock;
     a56:	f8 01       	movw	r30, r16
     a58:	c5 8d       	ldd	r28, Z+29	; 0x1d

		while( cRxLock > queueLOCKED_UNMODIFIED )
     a5a:	1c 16       	cp	r1, r28
     a5c:	c4 f4       	brge	.+48     	; 0xa8e <prvUnlockQueue+0x94>
		{
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     a5e:	80 85       	ldd	r24, Z+8	; 0x08
     a60:	88 23       	and	r24, r24
     a62:	31 f4       	brne	.+12     	; 0xa70 <prvUnlockQueue+0x76>
     a64:	14 c0       	rjmp	.+40     	; 0xa8e <prvUnlockQueue+0x94>
     a66:	f8 01       	movw	r30, r16
     a68:	80 85       	ldd	r24, Z+8	; 0x08
     a6a:	88 23       	and	r24, r24
     a6c:	39 f4       	brne	.+14     	; 0xa7c <prvUnlockQueue+0x82>
     a6e:	0f c0       	rjmp	.+30     	; 0xa8e <prvUnlockQueue+0x94>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
     a70:	ee 24       	eor	r14, r14
     a72:	ff 24       	eor	r15, r15
     a74:	68 94       	set
     a76:	e3 f8       	bld	r14, 3
     a78:	e0 0e       	add	r14, r16
     a7a:	f1 1e       	adc	r15, r17
     a7c:	c7 01       	movw	r24, r14
     a7e:	0e 94 b2 0f 	call	0x1f64	; 0x1f64 <xTaskRemoveFromEventList>
     a82:	88 23       	and	r24, r24
     a84:	11 f0       	breq	.+4      	; 0xa8a <prvUnlockQueue+0x90>
				{
					vTaskMissedYield();
     a86:	0e 94 77 10 	call	0x20ee	; 0x20ee <vTaskMissedYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				--cRxLock;
     a8a:	c1 50       	subi	r28, 0x01	; 1
	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
	{
		int8_t cRxLock = pxQueue->cRxLock;

		while( cRxLock > queueLOCKED_UNMODIFIED )
     a8c:	61 f7       	brne	.-40     	; 0xa66 <prvUnlockQueue+0x6c>
			{
				break;
			}
		}

		pxQueue->cRxLock = queueUNLOCKED;
     a8e:	8f ef       	ldi	r24, 0xFF	; 255
     a90:	f8 01       	movw	r30, r16
     a92:	85 8f       	std	Z+29, r24	; 0x1d
	}
	taskEXIT_CRITICAL();
     a94:	0f 90       	pop	r0
     a96:	0f be       	out	0x3f, r0	; 63
}
     a98:	cf 91       	pop	r28
     a9a:	1f 91       	pop	r17
     a9c:	0f 91       	pop	r16
     a9e:	ff 90       	pop	r15
     aa0:	ef 90       	pop	r14
     aa2:	08 95       	ret

00000aa4 <prvCopyDataToQueue>:

#endif /* configUSE_TRACE_FACILITY */
/*-----------------------------------------------------------*/

static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
{
     aa4:	0f 93       	push	r16
     aa6:	1f 93       	push	r17
     aa8:	cf 93       	push	r28
     aaa:	df 93       	push	r29
     aac:	ec 01       	movw	r28, r24
     aae:	14 2f       	mov	r17, r20
BaseType_t xReturn = pdFALSE;
UBaseType_t uxMessagesWaiting;

	/* This function is called from a critical section. */

	uxMessagesWaiting = pxQueue->uxMessagesWaiting;
     ab0:	0a 8d       	ldd	r16, Y+26	; 0x1a

	if( pxQueue->uxItemSize == ( UBaseType_t ) 0 )
     ab2:	4c 8d       	ldd	r20, Y+28	; 0x1c
     ab4:	44 23       	and	r20, r20
     ab6:	61 f4       	brne	.+24     	; 0xad0 <prvCopyDataToQueue+0x2c>
	{
		#if ( configUSE_MUTEXES == 1 )
		{
			if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
     ab8:	88 81       	ld	r24, Y
     aba:	99 81       	ldd	r25, Y+1	; 0x01
     abc:	00 97       	sbiw	r24, 0x00	; 0
     abe:	09 f0       	breq	.+2      	; 0xac2 <prvCopyDataToQueue+0x1e>
     ac0:	42 c0       	rjmp	.+132    	; 0xb46 <prvCopyDataToQueue+0xa2>
			{
				/* The mutex is no longer being held. */
				xReturn = xTaskPriorityDisinherit( ( void * ) pxQueue->pxMutexHolder );
     ac2:	8a 81       	ldd	r24, Y+2	; 0x02
     ac4:	9b 81       	ldd	r25, Y+3	; 0x03
     ac6:	0e 94 de 10 	call	0x21bc	; 0x21bc <xTaskPriorityDisinherit>
				pxQueue->pxMutexHolder = NULL;
     aca:	1b 82       	std	Y+3, r1	; 0x03
     acc:	1a 82       	std	Y+2, r1	; 0x02
     ace:	42 c0       	rjmp	.+132    	; 0xb54 <prvCopyDataToQueue+0xb0>
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configUSE_MUTEXES */
	}
	else if( xPosition == queueSEND_TO_BACK )
     ad0:	11 23       	and	r17, r17
     ad2:	b9 f4       	brne	.+46     	; 0xb02 <prvCopyDataToQueue+0x5e>
	{
		( void ) memcpy( ( void * ) pxQueue->pcWriteTo, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports, plus previous logic ensures a null pointer can only be passed to memcpy() if the copy size is 0. */
     ad4:	8c 81       	ldd	r24, Y+4	; 0x04
     ad6:	9d 81       	ldd	r25, Y+5	; 0x05
     ad8:	50 e0       	ldi	r21, 0x00	; 0
     ada:	0e 94 9e 13 	call	0x273c	; 0x273c <memcpy>
		pxQueue->pcWriteTo += pxQueue->uxItemSize;
     ade:	2c 8d       	ldd	r18, Y+28	; 0x1c
     ae0:	8c 81       	ldd	r24, Y+4	; 0x04
     ae2:	9d 81       	ldd	r25, Y+5	; 0x05
     ae4:	82 0f       	add	r24, r18
     ae6:	91 1d       	adc	r25, r1
     ae8:	9d 83       	std	Y+5, r25	; 0x05
     aea:	8c 83       	std	Y+4, r24	; 0x04
		if( pxQueue->pcWriteTo >= pxQueue->pcTail ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
     aec:	2a 81       	ldd	r18, Y+2	; 0x02
     aee:	3b 81       	ldd	r19, Y+3	; 0x03
     af0:	82 17       	cp	r24, r18
     af2:	93 07       	cpc	r25, r19
     af4:	50 f1       	brcs	.+84     	; 0xb4a <prvCopyDataToQueue+0xa6>
		{
			pxQueue->pcWriteTo = pxQueue->pcHead;
     af6:	88 81       	ld	r24, Y
     af8:	99 81       	ldd	r25, Y+1	; 0x01
     afa:	9d 83       	std	Y+5, r25	; 0x05
     afc:	8c 83       	std	Y+4, r24	; 0x04
#endif /* configUSE_TRACE_FACILITY */
/*-----------------------------------------------------------*/

static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
{
BaseType_t xReturn = pdFALSE;
     afe:	80 e0       	ldi	r24, 0x00	; 0
     b00:	29 c0       	rjmp	.+82     	; 0xb54 <prvCopyDataToQueue+0xb0>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	else
	{
		( void ) memcpy( ( void * ) pxQueue->u.pcReadFrom, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     b02:	8e 81       	ldd	r24, Y+6	; 0x06
     b04:	9f 81       	ldd	r25, Y+7	; 0x07
     b06:	50 e0       	ldi	r21, 0x00	; 0
     b08:	0e 94 9e 13 	call	0x273c	; 0x273c <memcpy>
		pxQueue->u.pcReadFrom -= pxQueue->uxItemSize;
     b0c:	4c 8d       	ldd	r20, Y+28	; 0x1c
     b0e:	50 e0       	ldi	r21, 0x00	; 0
     b10:	50 95       	com	r21
     b12:	41 95       	neg	r20
     b14:	5f 4f       	sbci	r21, 0xFF	; 255
     b16:	8e 81       	ldd	r24, Y+6	; 0x06
     b18:	9f 81       	ldd	r25, Y+7	; 0x07
     b1a:	84 0f       	add	r24, r20
     b1c:	95 1f       	adc	r25, r21
     b1e:	9f 83       	std	Y+7, r25	; 0x07
     b20:	8e 83       	std	Y+6, r24	; 0x06
		if( pxQueue->u.pcReadFrom < pxQueue->pcHead ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
     b22:	28 81       	ld	r18, Y
     b24:	39 81       	ldd	r19, Y+1	; 0x01
     b26:	82 17       	cp	r24, r18
     b28:	93 07       	cpc	r25, r19
     b2a:	30 f4       	brcc	.+12     	; 0xb38 <prvCopyDataToQueue+0x94>
		{
			pxQueue->u.pcReadFrom = ( pxQueue->pcTail - pxQueue->uxItemSize );
     b2c:	8a 81       	ldd	r24, Y+2	; 0x02
     b2e:	9b 81       	ldd	r25, Y+3	; 0x03
     b30:	84 0f       	add	r24, r20
     b32:	95 1f       	adc	r25, r21
     b34:	9f 83       	std	Y+7, r25	; 0x07
     b36:	8e 83       	std	Y+6, r24	; 0x06
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		if( xPosition == queueOVERWRITE )
     b38:	12 30       	cpi	r17, 0x02	; 2
     b3a:	49 f4       	brne	.+18     	; 0xb4e <prvCopyDataToQueue+0xaa>
		{
			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
     b3c:	00 23       	and	r16, r16
     b3e:	49 f0       	breq	.+18     	; 0xb52 <prvCopyDataToQueue+0xae>
			{
				/* An item is not being added but overwritten, so subtract
				one from the recorded number of items in the queue so when
				one is added again below the number of recorded items remains
				correct. */
				--uxMessagesWaiting;
     b40:	01 50       	subi	r16, 0x01	; 1
#endif /* configUSE_TRACE_FACILITY */
/*-----------------------------------------------------------*/

static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
{
BaseType_t xReturn = pdFALSE;
     b42:	80 e0       	ldi	r24, 0x00	; 0
     b44:	07 c0       	rjmp	.+14     	; 0xb54 <prvCopyDataToQueue+0xb0>
     b46:	80 e0       	ldi	r24, 0x00	; 0
     b48:	05 c0       	rjmp	.+10     	; 0xb54 <prvCopyDataToQueue+0xb0>
     b4a:	80 e0       	ldi	r24, 0x00	; 0
     b4c:	03 c0       	rjmp	.+6      	; 0xb54 <prvCopyDataToQueue+0xb0>
     b4e:	80 e0       	ldi	r24, 0x00	; 0
     b50:	01 c0       	rjmp	.+2      	; 0xb54 <prvCopyDataToQueue+0xb0>
     b52:	80 e0       	ldi	r24, 0x00	; 0
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}

	pxQueue->uxMessagesWaiting = uxMessagesWaiting + 1;
     b54:	0f 5f       	subi	r16, 0xFF	; 255
     b56:	0a 8f       	std	Y+26, r16	; 0x1a

	return xReturn;
}
     b58:	df 91       	pop	r29
     b5a:	cf 91       	pop	r28
     b5c:	1f 91       	pop	r17
     b5e:	0f 91       	pop	r16
     b60:	08 95       	ret

00000b62 <xQueueGenericReset>:
	}														\
	taskEXIT_CRITICAL()
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue )
{
     b62:	cf 93       	push	r28
     b64:	df 93       	push	r29
     b66:	ec 01       	movw	r28, r24
Queue_t * const pxQueue = ( Queue_t * ) xQueue;

	configASSERT( pxQueue );

	taskENTER_CRITICAL();
     b68:	0f b6       	in	r0, 0x3f	; 63
     b6a:	f8 94       	cli
     b6c:	0f 92       	push	r0
	{
		pxQueue->pcTail = pxQueue->pcHead + ( pxQueue->uxLength * pxQueue->uxItemSize );
     b6e:	48 81       	ld	r20, Y
     b70:	59 81       	ldd	r21, Y+1	; 0x01
     b72:	2b 8d       	ldd	r18, Y+27	; 0x1b
     b74:	30 e0       	ldi	r19, 0x00	; 0
     b76:	ec 8d       	ldd	r30, Y+28	; 0x1c
     b78:	f0 e0       	ldi	r31, 0x00	; 0
     b7a:	2e 9f       	mul	r18, r30
     b7c:	c0 01       	movw	r24, r0
     b7e:	2f 9f       	mul	r18, r31
     b80:	90 0d       	add	r25, r0
     b82:	3e 9f       	mul	r19, r30
     b84:	90 0d       	add	r25, r0
     b86:	11 24       	eor	r1, r1
     b88:	84 0f       	add	r24, r20
     b8a:	95 1f       	adc	r25, r21
     b8c:	9b 83       	std	Y+3, r25	; 0x03
     b8e:	8a 83       	std	Y+2, r24	; 0x02
		pxQueue->uxMessagesWaiting = ( UBaseType_t ) 0U;
     b90:	1a 8e       	std	Y+26, r1	; 0x1a
		pxQueue->pcWriteTo = pxQueue->pcHead;
     b92:	5d 83       	std	Y+5, r21	; 0x05
     b94:	4c 83       	std	Y+4, r20	; 0x04
		pxQueue->u.pcReadFrom = pxQueue->pcHead + ( ( pxQueue->uxLength - ( UBaseType_t ) 1U ) * pxQueue->uxItemSize );
     b96:	c9 01       	movw	r24, r18
     b98:	01 97       	sbiw	r24, 0x01	; 1
     b9a:	e8 9f       	mul	r30, r24
     b9c:	90 01       	movw	r18, r0
     b9e:	e9 9f       	mul	r30, r25
     ba0:	30 0d       	add	r19, r0
     ba2:	f8 9f       	mul	r31, r24
     ba4:	30 0d       	add	r19, r0
     ba6:	11 24       	eor	r1, r1
     ba8:	24 0f       	add	r18, r20
     baa:	35 1f       	adc	r19, r21
     bac:	3f 83       	std	Y+7, r19	; 0x07
     bae:	2e 83       	std	Y+6, r18	; 0x06
		pxQueue->cRxLock = queueUNLOCKED;
     bb0:	8f ef       	ldi	r24, 0xFF	; 255
     bb2:	8d 8f       	std	Y+29, r24	; 0x1d
		pxQueue->cTxLock = queueUNLOCKED;
     bb4:	8e 8f       	std	Y+30, r24	; 0x1e

		if( xNewQueue == pdFALSE )
     bb6:	66 23       	and	r22, r22
     bb8:	61 f4       	brne	.+24     	; 0xbd2 <xQueueGenericReset+0x70>
			/* If there are tasks blocked waiting to read from the queue, then
			the tasks will remain blocked as after this function exits the queue
			will still be empty.  If there are tasks blocked waiting to write to
			the queue, then one should be unblocked as after this function exits
			it will be possible to write to it. */
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     bba:	88 85       	ldd	r24, Y+8	; 0x08
     bbc:	88 23       	and	r24, r24
     bbe:	89 f0       	breq	.+34     	; 0xbe2 <xQueueGenericReset+0x80>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
     bc0:	ce 01       	movw	r24, r28
     bc2:	08 96       	adiw	r24, 0x08	; 8
     bc4:	0e 94 b2 0f 	call	0x1f64	; 0x1f64 <xTaskRemoveFromEventList>
     bc8:	88 23       	and	r24, r24
     bca:	59 f0       	breq	.+22     	; 0xbe2 <xQueueGenericReset+0x80>
				{
					queueYIELD_IF_USING_PREEMPTION();
     bcc:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
     bd0:	08 c0       	rjmp	.+16     	; 0xbe2 <xQueueGenericReset+0x80>
			}
		}
		else
		{
			/* Ensure the event queues start in the correct state. */
			vListInitialise( &( pxQueue->xTasksWaitingToSend ) );
     bd2:	ce 01       	movw	r24, r28
     bd4:	08 96       	adiw	r24, 0x08	; 8
     bd6:	0e 94 cb 02 	call	0x596	; 0x596 <vListInitialise>
			vListInitialise( &( pxQueue->xTasksWaitingToReceive ) );
     bda:	ce 01       	movw	r24, r28
     bdc:	41 96       	adiw	r24, 0x11	; 17
     bde:	0e 94 cb 02 	call	0x596	; 0x596 <vListInitialise>
		}
	}
	taskEXIT_CRITICAL();
     be2:	0f 90       	pop	r0
     be4:	0f be       	out	0x3f, r0	; 63

	/* A value is returned for calling semantic consistency with previous
	versions. */
	return pdPASS;
}
     be6:	81 e0       	ldi	r24, 0x01	; 1
     be8:	df 91       	pop	r29
     bea:	cf 91       	pop	r28
     bec:	08 95       	ret

00000bee <xQueueGenericCreate>:
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType )
	{
     bee:	0f 93       	push	r16
     bf0:	1f 93       	push	r17
     bf2:	cf 93       	push	r28
     bf4:	df 93       	push	r29
     bf6:	08 2f       	mov	r16, r24
     bf8:	16 2f       	mov	r17, r22
	size_t xQueueSizeInBytes;
	uint8_t *pucQueueStorage;

		configASSERT( uxQueueLength > ( UBaseType_t ) 0 );

		if( uxItemSize == ( UBaseType_t ) 0 )
     bfa:	66 23       	and	r22, r22
     bfc:	21 f0       	breq	.+8      	; 0xc06 <xQueueGenericCreate+0x18>
		}
		else
		{
			/* Allocate enough space to hold the maximum number of items that
			can be in the queue at any time. */
			xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     bfe:	68 9f       	mul	r22, r24
     c00:	c0 01       	movw	r24, r0
     c02:	11 24       	eor	r1, r1
     c04:	02 c0       	rjmp	.+4      	; 0xc0a <xQueueGenericCreate+0x1c>
		configASSERT( uxQueueLength > ( UBaseType_t ) 0 );

		if( uxItemSize == ( UBaseType_t ) 0 )
		{
			/* There is not going to be a queue storage area. */
			xQueueSizeInBytes = ( size_t ) 0;
     c06:	80 e0       	ldi	r24, 0x00	; 0
     c08:	90 e0       	ldi	r25, 0x00	; 0
			/* Allocate enough space to hold the maximum number of items that
			can be in the queue at any time. */
			xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
		}

		pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes );
     c0a:	4f 96       	adiw	r24, 0x1f	; 31
     c0c:	0e 94 f2 01 	call	0x3e4	; 0x3e4 <pvPortMalloc>
     c10:	ec 01       	movw	r28, r24

		if( pxNewQueue != NULL )
     c12:	00 97       	sbiw	r24, 0x00	; 0
     c14:	71 f0       	breq	.+28     	; 0xc32 <xQueueGenericCreate+0x44>
{
	/* Remove compiler warnings about unused parameters should
	configUSE_TRACE_FACILITY not be set to 1. */
	( void ) ucQueueType;

	if( uxItemSize == ( UBaseType_t ) 0 )
     c16:	11 23       	and	r17, r17
     c18:	19 f4       	brne	.+6      	; 0xc20 <xQueueGenericCreate+0x32>
	{
		/* No RAM was allocated for the queue storage area, but PC head cannot
		be set to NULL because NULL is used as a key to say the queue is used as
		a mutex.  Therefore just set pcHead to point to the queue as a benign
		value that is known to be within the memory map. */
		pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;
     c1a:	99 83       	std	Y+1, r25	; 0x01
     c1c:	88 83       	st	Y, r24
     c1e:	03 c0       	rjmp	.+6      	; 0xc26 <xQueueGenericCreate+0x38>

		if( pxNewQueue != NULL )
		{
			/* Jump past the queue structure to find the location of the queue
			storage area. */
			pucQueueStorage = ( ( uint8_t * ) pxNewQueue ) + sizeof( Queue_t );
     c20:	4f 96       	adiw	r24, 0x1f	; 31
		pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;
	}
	else
	{
		/* Set the head to the start of the queue storage area. */
		pxNewQueue->pcHead = ( int8_t * ) pucQueueStorage;
     c22:	99 83       	std	Y+1, r25	; 0x01
     c24:	88 83       	st	Y, r24
	}

	/* Initialise the queue members as described where the queue type is
	defined. */
	pxNewQueue->uxLength = uxQueueLength;
     c26:	0b 8f       	std	Y+27, r16	; 0x1b
	pxNewQueue->uxItemSize = uxItemSize;
     c28:	1c 8f       	std	Y+28, r17	; 0x1c
	( void ) xQueueGenericReset( pxNewQueue, pdTRUE );
     c2a:	ce 01       	movw	r24, r28
     c2c:	61 e0       	ldi	r22, 0x01	; 1
     c2e:	0e 94 b1 05 	call	0xb62	; 0xb62 <xQueueGenericReset>

			prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );
		}

		return pxNewQueue;
	}
     c32:	8c 2f       	mov	r24, r28
     c34:	9d 2f       	mov	r25, r29
     c36:	df 91       	pop	r29
     c38:	cf 91       	pop	r28
     c3a:	1f 91       	pop	r17
     c3c:	0f 91       	pop	r16
     c3e:	08 95       	ret

00000c40 <xQueueGenericSend>:

#endif /* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition )
{
     c40:	8f 92       	push	r8
     c42:	9f 92       	push	r9
     c44:	bf 92       	push	r11
     c46:	cf 92       	push	r12
     c48:	df 92       	push	r13
     c4a:	ef 92       	push	r14
     c4c:	ff 92       	push	r15
     c4e:	0f 93       	push	r16
     c50:	1f 93       	push	r17
     c52:	cf 93       	push	r28
     c54:	df 93       	push	r29
     c56:	00 d0       	rcall	.+0      	; 0xc58 <xQueueGenericSend+0x18>
     c58:	00 d0       	rcall	.+0      	; 0xc5a <xQueueGenericSend+0x1a>
     c5a:	0f 92       	push	r0
     c5c:	cd b7       	in	r28, 0x3d	; 61
     c5e:	de b7       	in	r29, 0x3e	; 62
     c60:	8c 01       	movw	r16, r24
     c62:	4b 01       	movw	r8, r22
     c64:	5d 83       	std	Y+5, r21	; 0x05
     c66:	4c 83       	std	Y+4, r20	; 0x04
     c68:	e2 2e       	mov	r14, r18
BaseType_t xEntryTimeSet = pdFALSE, xYieldRequired;
     c6a:	ff 24       	eor	r15, r15
				else if( xEntryTimeSet == pdFALSE )
				{
					/* The queue was full and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
     c6c:	bb 24       	eor	r11, r11
     c6e:	b3 94       	inc	r11
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
     c70:	cc 24       	eor	r12, r12
     c72:	dd 24       	eor	r13, r13
     c74:	68 94       	set
     c76:	c3 f8       	bld	r12, 3
     c78:	c8 0e       	add	r12, r24
     c7a:	d9 1e       	adc	r13, r25
	/* This function relaxes the coding standard somewhat to allow return
	statements within the function itself.  This is done in the interest
	of execution time efficiency. */
	for( ;; )
	{
		taskENTER_CRITICAL();
     c7c:	0f b6       	in	r0, 0x3f	; 63
     c7e:	f8 94       	cli
     c80:	0f 92       	push	r0
		{
			/* Is there room on the queue now?  The running task must be the
			highest priority task wanting to access the queue.  If the head item
			in the queue is to be overwritten then it does not matter if the
			queue is full. */
			if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
     c82:	f8 01       	movw	r30, r16
     c84:	92 8d       	ldd	r25, Z+26	; 0x1a
     c86:	83 8d       	ldd	r24, Z+27	; 0x1b
     c88:	98 17       	cp	r25, r24
     c8a:	18 f0       	brcs	.+6      	; 0xc92 <xQueueGenericSend+0x52>
     c8c:	f2 e0       	ldi	r31, 0x02	; 2
     c8e:	ef 16       	cp	r14, r31
     c90:	d1 f4       	brne	.+52     	; 0xcc6 <xQueueGenericSend+0x86>
			{
				traceQUEUE_SEND( pxQueue );
				xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
     c92:	c8 01       	movw	r24, r16
     c94:	b4 01       	movw	r22, r8
     c96:	4e 2d       	mov	r20, r14
     c98:	0e 94 52 05 	call	0xaa4	; 0xaa4 <prvCopyDataToQueue>
				}
				#else /* configUSE_QUEUE_SETS */
				{
					/* If there was a task waiting for data to arrive on the
					queue then unblock it now. */
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     c9c:	f8 01       	movw	r30, r16
     c9e:	91 89       	ldd	r25, Z+17	; 0x11
     ca0:	99 23       	and	r25, r25
     ca2:	49 f0       	breq	.+18     	; 0xcb6 <xQueueGenericSend+0x76>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     ca4:	c8 01       	movw	r24, r16
     ca6:	41 96       	adiw	r24, 0x11	; 17
     ca8:	0e 94 b2 0f 	call	0x1f64	; 0x1f64 <xTaskRemoveFromEventList>
     cac:	88 23       	and	r24, r24
     cae:	39 f0       	breq	.+14     	; 0xcbe <xQueueGenericSend+0x7e>
						{
							/* The unblocked task has a priority higher than
							our own so yield immediately.  Yes it is ok to do
							this from within the critical section - the kernel
							takes care of that. */
							queueYIELD_IF_USING_PREEMPTION();
     cb0:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
     cb4:	04 c0       	rjmp	.+8      	; 0xcbe <xQueueGenericSend+0x7e>
						else
						{
							mtCOVERAGE_TEST_MARKER();
						}
					}
					else if( xYieldRequired != pdFALSE )
     cb6:	88 23       	and	r24, r24
     cb8:	11 f0       	breq	.+4      	; 0xcbe <xQueueGenericSend+0x7e>
					{
						/* This path is a special case that will only get
						executed if the task was holding multiple mutexes and
						the mutexes were given back in an order that is
						different to that in which they were taken. */
						queueYIELD_IF_USING_PREEMPTION();
     cba:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif /* configUSE_QUEUE_SETS */

				taskEXIT_CRITICAL();
     cbe:	0f 90       	pop	r0
     cc0:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
     cc2:	81 e0       	ldi	r24, 0x01	; 1
     cc4:	52 c0       	rjmp	.+164    	; 0xd6a <xQueueGenericSend+0x12a>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
     cc6:	8c 81       	ldd	r24, Y+4	; 0x04
     cc8:	9d 81       	ldd	r25, Y+5	; 0x05
     cca:	00 97       	sbiw	r24, 0x00	; 0
     ccc:	21 f4       	brne	.+8      	; 0xcd6 <xQueueGenericSend+0x96>
				{
					/* The queue was full and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
     cce:	0f 90       	pop	r0
     cd0:	0f be       	out	0x3f, r0	; 63

					/* Return to the original privilege level before exiting
					the function. */
					traceQUEUE_SEND_FAILED( pxQueue );
					return errQUEUE_FULL;
     cd2:	80 e0       	ldi	r24, 0x00	; 0
     cd4:	4a c0       	rjmp	.+148    	; 0xd6a <xQueueGenericSend+0x12a>
				}
				else if( xEntryTimeSet == pdFALSE )
     cd6:	ff 20       	and	r15, r15
     cd8:	29 f4       	brne	.+10     	; 0xce4 <xQueueGenericSend+0xa4>
				{
					/* The queue was full and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
     cda:	ce 01       	movw	r24, r28
     cdc:	01 96       	adiw	r24, 0x01	; 1
     cde:	0e 94 37 10 	call	0x206e	; 0x206e <vTaskSetTimeOutState>
					xEntryTimeSet = pdTRUE;
     ce2:	fb 2c       	mov	r15, r11
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
     ce4:	0f 90       	pop	r0
     ce6:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
     ce8:	0e 94 f3 0c 	call	0x19e6	; 0x19e6 <vTaskSuspendAll>
		prvLockQueue( pxQueue );
     cec:	0f b6       	in	r0, 0x3f	; 63
     cee:	f8 94       	cli
     cf0:	0f 92       	push	r0
     cf2:	f8 01       	movw	r30, r16
     cf4:	85 8d       	ldd	r24, Z+29	; 0x1d
     cf6:	8f 3f       	cpi	r24, 0xFF	; 255
     cf8:	09 f4       	brne	.+2      	; 0xcfc <xQueueGenericSend+0xbc>
     cfa:	15 8e       	std	Z+29, r1	; 0x1d
     cfc:	f8 01       	movw	r30, r16
     cfe:	86 8d       	ldd	r24, Z+30	; 0x1e
     d00:	8f 3f       	cpi	r24, 0xFF	; 255
     d02:	09 f4       	brne	.+2      	; 0xd06 <xQueueGenericSend+0xc6>
     d04:	16 8e       	std	Z+30, r1	; 0x1e
     d06:	0f 90       	pop	r0
     d08:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
     d0a:	ce 01       	movw	r24, r28
     d0c:	01 96       	adiw	r24, 0x01	; 1
     d0e:	be 01       	movw	r22, r28
     d10:	6c 5f       	subi	r22, 0xFC	; 252
     d12:	7f 4f       	sbci	r23, 0xFF	; 255
     d14:	0e 94 42 10 	call	0x2084	; 0x2084 <xTaskCheckForTimeOut>
     d18:	88 23       	and	r24, r24
     d1a:	09 f5       	brne	.+66     	; 0xd5e <xQueueGenericSend+0x11e>

static BaseType_t prvIsQueueFull( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
     d1c:	0f b6       	in	r0, 0x3f	; 63
     d1e:	f8 94       	cli
     d20:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
     d22:	f8 01       	movw	r30, r16
     d24:	92 8d       	ldd	r25, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
     d26:	0f 90       	pop	r0
     d28:	0f be       	out	0x3f, r0	; 63
		prvLockQueue( pxQueue );

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
     d2a:	f8 01       	movw	r30, r16
     d2c:	83 8d       	ldd	r24, Z+27	; 0x1b
     d2e:	98 17       	cp	r25, r24
     d30:	81 f4       	brne	.+32     	; 0xd52 <xQueueGenericSend+0x112>
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
     d32:	6c 81       	ldd	r22, Y+4	; 0x04
     d34:	7d 81       	ldd	r23, Y+5	; 0x05
     d36:	c6 01       	movw	r24, r12
     d38:	0e 94 87 0f 	call	0x1f0e	; 0x1f0e <vTaskPlaceOnEventList>
				/* Unlocking the queue means queue events can effect the
				event list.  It is possible	that interrupts occurring now
				remove this task from the event	list again - but as the
				scheduler is suspended the task will go onto the pending
				ready last instead of the actual ready list. */
				prvUnlockQueue( pxQueue );
     d3c:	c8 01       	movw	r24, r16
     d3e:	0e 94 fd 04 	call	0x9fa	; 0x9fa <prvUnlockQueue>
				/* Resuming the scheduler will move tasks from the pending
				ready list into the ready list - so it is feasible that this
				task is already in a ready list before it yields - in which
				case the yield will not cause a context switch unless there
				is also a higher priority task in the pending ready list. */
				if( xTaskResumeAll() == pdFALSE )
     d42:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>
     d46:	88 23       	and	r24, r24
     d48:	09 f0       	breq	.+2      	; 0xd4c <xQueueGenericSend+0x10c>
     d4a:	98 cf       	rjmp	.-208    	; 0xc7c <xQueueGenericSend+0x3c>
				{
					portYIELD_WITHIN_API();
     d4c:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
     d50:	95 cf       	rjmp	.-214    	; 0xc7c <xQueueGenericSend+0x3c>
				}
			}
			else
			{
				/* Try again. */
				prvUnlockQueue( pxQueue );
     d52:	c8 01       	movw	r24, r16
     d54:	0e 94 fd 04 	call	0x9fa	; 0x9fa <prvUnlockQueue>
				( void ) xTaskResumeAll();
     d58:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>
     d5c:	8f cf       	rjmp	.-226    	; 0xc7c <xQueueGenericSend+0x3c>
			}
		}
		else
		{
			/* The timeout has expired. */
			prvUnlockQueue( pxQueue );
     d5e:	c8 01       	movw	r24, r16
     d60:	0e 94 fd 04 	call	0x9fa	; 0x9fa <prvUnlockQueue>
			( void ) xTaskResumeAll();
     d64:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>

			traceQUEUE_SEND_FAILED( pxQueue );
			return errQUEUE_FULL;
     d68:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
}
     d6a:	0f 90       	pop	r0
     d6c:	0f 90       	pop	r0
     d6e:	0f 90       	pop	r0
     d70:	0f 90       	pop	r0
     d72:	0f 90       	pop	r0
     d74:	df 91       	pop	r29
     d76:	cf 91       	pop	r28
     d78:	1f 91       	pop	r17
     d7a:	0f 91       	pop	r16
     d7c:	ff 90       	pop	r15
     d7e:	ef 90       	pop	r14
     d80:	df 90       	pop	r13
     d82:	cf 90       	pop	r12
     d84:	bf 90       	pop	r11
     d86:	9f 90       	pop	r9
     d88:	8f 90       	pop	r8
     d8a:	08 95       	ret

00000d8c <xQueueCreateMutex>:
/*-----------------------------------------------------------*/

#if( ( configUSE_MUTEXES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )

	QueueHandle_t xQueueCreateMutex( const uint8_t ucQueueType )
	{
     d8c:	cf 93       	push	r28
     d8e:	df 93       	push	r29
     d90:	48 2f       	mov	r20, r24
	Queue_t *pxNewQueue;
	const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;

		pxNewQueue = ( Queue_t * ) xQueueGenericCreate( uxMutexLength, uxMutexSize, ucQueueType );
     d92:	81 e0       	ldi	r24, 0x01	; 1
     d94:	60 e0       	ldi	r22, 0x00	; 0
     d96:	0e 94 f7 05 	call	0xbee	; 0xbee <xQueueGenericCreate>
     d9a:	ec 01       	movw	r28, r24

#if( configUSE_MUTEXES == 1 )

	static void prvInitialiseMutex( Queue_t *pxNewQueue )
	{
		if( pxNewQueue != NULL )
     d9c:	00 97       	sbiw	r24, 0x00	; 0
     d9e:	61 f0       	breq	.+24     	; 0xdb8 <xQueueCreateMutex+0x2c>
		{
			/* The queue create function will set all the queue structure members
			correctly for a generic queue, but this function is creating a
			mutex.  Overwrite those members that need to be set differently -
			in particular the information required for priority inheritance. */
			pxNewQueue->pxMutexHolder = NULL;
     da0:	1b 82       	std	Y+3, r1	; 0x03
     da2:	1a 82       	std	Y+2, r1	; 0x02
			pxNewQueue->uxQueueType = queueQUEUE_IS_MUTEX;
     da4:	19 82       	std	Y+1, r1	; 0x01
     da6:	18 82       	st	Y, r1

			/* In case this is a recursive mutex. */
			pxNewQueue->u.uxRecursiveCallCount = 0;
     da8:	1e 82       	std	Y+6, r1	; 0x06

			traceCREATE_MUTEX( pxNewQueue );

			/* Start with the semaphore in the expected state. */
			( void ) xQueueGenericSend( pxNewQueue, NULL, ( TickType_t ) 0U, queueSEND_TO_BACK );
     daa:	60 e0       	ldi	r22, 0x00	; 0
     dac:	70 e0       	ldi	r23, 0x00	; 0
     dae:	40 e0       	ldi	r20, 0x00	; 0
     db0:	50 e0       	ldi	r21, 0x00	; 0
     db2:	20 e0       	ldi	r18, 0x00	; 0
     db4:	0e 94 20 06 	call	0xc40	; 0xc40 <xQueueGenericSend>

		pxNewQueue = ( Queue_t * ) xQueueGenericCreate( uxMutexLength, uxMutexSize, ucQueueType );
		prvInitialiseMutex( pxNewQueue );

		return pxNewQueue;
	}
     db8:	8c 2f       	mov	r24, r28
     dba:	9d 2f       	mov	r25, r29
     dbc:	df 91       	pop	r29
     dbe:	cf 91       	pop	r28
     dc0:	08 95       	ret

00000dc2 <xQueueGenericSendFromISR>:
	}
}
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue, const void * const pvItemToQueue, BaseType_t * const pxHigherPriorityTaskWoken, const BaseType_t xCopyPosition )
{
     dc2:	ef 92       	push	r14
     dc4:	ff 92       	push	r15
     dc6:	0f 93       	push	r16
     dc8:	1f 93       	push	r17
     dca:	cf 93       	push	r28
     dcc:	8c 01       	movw	r16, r24
     dce:	7a 01       	movw	r14, r20
	read, instead return a flag to say whether a context switch is required or
	not (i.e. has a task with a higher priority than us been woken by this
	post). */
	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
     dd0:	fc 01       	movw	r30, r24
     dd2:	92 8d       	ldd	r25, Z+26	; 0x1a
     dd4:	83 8d       	ldd	r24, Z+27	; 0x1b
     dd6:	98 17       	cp	r25, r24
     dd8:	10 f0       	brcs	.+4      	; 0xdde <xQueueGenericSendFromISR+0x1c>
     dda:	22 30       	cpi	r18, 0x02	; 2
     ddc:	f1 f4       	brne	.+60     	; 0xe1a <xQueueGenericSendFromISR+0x58>
		{
			const int8_t cTxLock = pxQueue->cTxLock;
     dde:	f8 01       	movw	r30, r16
     de0:	c6 8d       	ldd	r28, Z+30	; 0x1e
			/* Semaphores use xQueueGiveFromISR(), so pxQueue will not be a
			semaphore or mutex.  That means prvCopyDataToQueue() cannot result
			in a task disinheriting a priority and prvCopyDataToQueue() can be
			called here even though the disinherit function does not check if
			the scheduler is suspended before accessing the ready lists. */
			( void ) prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
     de2:	c8 01       	movw	r24, r16
     de4:	42 2f       	mov	r20, r18
     de6:	0e 94 52 05 	call	0xaa4	; 0xaa4 <prvCopyDataToQueue>

			/* The event list is not altered if the queue is locked.  This will
			be done when the queue is unlocked later. */
			if( cTxLock == queueUNLOCKED )
     dea:	cf 3f       	cpi	r28, 0xFF	; 255
     dec:	89 f4       	brne	.+34     	; 0xe10 <xQueueGenericSendFromISR+0x4e>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     dee:	f8 01       	movw	r30, r16
     df0:	81 89       	ldd	r24, Z+17	; 0x11
     df2:	88 23       	and	r24, r24
     df4:	a1 f0       	breq	.+40     	; 0xe1e <xQueueGenericSendFromISR+0x5c>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     df6:	c8 01       	movw	r24, r16
     df8:	41 96       	adiw	r24, 0x11	; 17
     dfa:	0e 94 b2 0f 	call	0x1f64	; 0x1f64 <xTaskRemoveFromEventList>
     dfe:	88 23       	and	r24, r24
     e00:	81 f0       	breq	.+32     	; 0xe22 <xQueueGenericSendFromISR+0x60>
						{
							/* The task waiting has a higher priority so record that a
							context	switch is required. */
							if( pxHigherPriorityTaskWoken != NULL )
     e02:	e1 14       	cp	r14, r1
     e04:	f1 04       	cpc	r15, r1
     e06:	79 f0       	breq	.+30     	; 0xe26 <xQueueGenericSendFromISR+0x64>
							{
								*pxHigherPriorityTaskWoken = pdTRUE;
     e08:	81 e0       	ldi	r24, 0x01	; 1
     e0a:	f7 01       	movw	r30, r14
     e0c:	80 83       	st	Z, r24
     e0e:	0c c0       	rjmp	.+24     	; 0xe28 <xQueueGenericSendFromISR+0x66>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
     e10:	cf 5f       	subi	r28, 0xFF	; 255
     e12:	f8 01       	movw	r30, r16
     e14:	c6 8f       	std	Z+30, r28	; 0x1e
			}

			xReturn = pdPASS;
     e16:	81 e0       	ldi	r24, 0x01	; 1
     e18:	07 c0       	rjmp	.+14     	; 0xe28 <xQueueGenericSendFromISR+0x66>
		}
		else
		{
			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
			xReturn = errQUEUE_FULL;
     e1a:	80 e0       	ldi	r24, 0x00	; 0
     e1c:	05 c0       	rjmp	.+10     	; 0xe28 <xQueueGenericSendFromISR+0x66>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
			}

			xReturn = pdPASS;
     e1e:	81 e0       	ldi	r24, 0x01	; 1
     e20:	03 c0       	rjmp	.+6      	; 0xe28 <xQueueGenericSendFromISR+0x66>
     e22:	81 e0       	ldi	r24, 0x01	; 1
     e24:	01 c0       	rjmp	.+2      	; 0xe28 <xQueueGenericSendFromISR+0x66>
     e26:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
     e28:	cf 91       	pop	r28
     e2a:	1f 91       	pop	r17
     e2c:	0f 91       	pop	r16
     e2e:	ff 90       	pop	r15
     e30:	ef 90       	pop	r14
     e32:	08 95       	ret

00000e34 <xQueueGiveFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueGiveFromISR( QueueHandle_t xQueue, BaseType_t * const pxHigherPriorityTaskWoken )
{
     e34:	cf 93       	push	r28
     e36:	df 93       	push	r29
     e38:	fc 01       	movw	r30, r24
     e3a:	eb 01       	movw	r28, r22
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
     e3c:	82 8d       	ldd	r24, Z+26	; 0x1a

		/* When the queue is used to implement a semaphore no data is ever
		moved through the queue but it is still valid to see if the queue 'has
		space'. */
		if( uxMessagesWaiting < pxQueue->uxLength )
     e3e:	93 8d       	ldd	r25, Z+27	; 0x1b
     e40:	89 17       	cp	r24, r25
     e42:	b8 f4       	brcc	.+46     	; 0xe72 <xQueueGiveFromISR+0x3e>
		{
			const int8_t cTxLock = pxQueue->cTxLock;
     e44:	96 8d       	ldd	r25, Z+30	; 0x1e
			holder - and if there is a mutex holder then the mutex cannot be
			given from an ISR.  As this is the ISR version of the function it
			can be assumed there is no mutex holder and no need to determine if
			priority disinheritance is needed.  Simply increase the count of
			messages (semaphores) available. */
			pxQueue->uxMessagesWaiting = uxMessagesWaiting + 1;
     e46:	8f 5f       	subi	r24, 0xFF	; 255
     e48:	82 8f       	std	Z+26, r24	; 0x1a

			/* The event list is not altered if the queue is locked.  This will
			be done when the queue is unlocked later. */
			if( cTxLock == queueUNLOCKED )
     e4a:	9f 3f       	cpi	r25, 0xFF	; 255
     e4c:	71 f4       	brne	.+28     	; 0xe6a <xQueueGiveFromISR+0x36>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     e4e:	81 89       	ldd	r24, Z+17	; 0x11
     e50:	88 23       	and	r24, r24
     e52:	89 f0       	breq	.+34     	; 0xe76 <xQueueGiveFromISR+0x42>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     e54:	cf 01       	movw	r24, r30
     e56:	41 96       	adiw	r24, 0x11	; 17
     e58:	0e 94 b2 0f 	call	0x1f64	; 0x1f64 <xTaskRemoveFromEventList>
     e5c:	88 23       	and	r24, r24
     e5e:	69 f0       	breq	.+26     	; 0xe7a <xQueueGiveFromISR+0x46>
						{
							/* The task waiting has a higher priority so record that a
							context	switch is required. */
							if( pxHigherPriorityTaskWoken != NULL )
     e60:	20 97       	sbiw	r28, 0x00	; 0
     e62:	69 f0       	breq	.+26     	; 0xe7e <xQueueGiveFromISR+0x4a>
							{
								*pxHigherPriorityTaskWoken = pdTRUE;
     e64:	81 e0       	ldi	r24, 0x01	; 1
     e66:	88 83       	st	Y, r24
     e68:	0b c0       	rjmp	.+22     	; 0xe80 <xQueueGiveFromISR+0x4c>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
     e6a:	9f 5f       	subi	r25, 0xFF	; 255
     e6c:	96 8f       	std	Z+30, r25	; 0x1e
			}

			xReturn = pdPASS;
     e6e:	81 e0       	ldi	r24, 0x01	; 1
     e70:	07 c0       	rjmp	.+14     	; 0xe80 <xQueueGiveFromISR+0x4c>
		}
		else
		{
			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
			xReturn = errQUEUE_FULL;
     e72:	80 e0       	ldi	r24, 0x00	; 0
     e74:	05 c0       	rjmp	.+10     	; 0xe80 <xQueueGiveFromISR+0x4c>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
			}

			xReturn = pdPASS;
     e76:	81 e0       	ldi	r24, 0x01	; 1
     e78:	03 c0       	rjmp	.+6      	; 0xe80 <xQueueGiveFromISR+0x4c>
     e7a:	81 e0       	ldi	r24, 0x01	; 1
     e7c:	01 c0       	rjmp	.+2      	; 0xe80 <xQueueGiveFromISR+0x4c>
     e7e:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
     e80:	df 91       	pop	r29
     e82:	cf 91       	pop	r28
     e84:	08 95       	ret

00000e86 <xQueueGenericReceive>:
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait, const BaseType_t xJustPeeking )
{
     e86:	8f 92       	push	r8
     e88:	9f 92       	push	r9
     e8a:	af 92       	push	r10
     e8c:	bf 92       	push	r11
     e8e:	cf 92       	push	r12
     e90:	df 92       	push	r13
     e92:	ef 92       	push	r14
     e94:	ff 92       	push	r15
     e96:	0f 93       	push	r16
     e98:	1f 93       	push	r17
     e9a:	cf 93       	push	r28
     e9c:	df 93       	push	r29
     e9e:	00 d0       	rcall	.+0      	; 0xea0 <xQueueGenericReceive+0x1a>
     ea0:	00 d0       	rcall	.+0      	; 0xea2 <xQueueGenericReceive+0x1c>
     ea2:	0f 92       	push	r0
     ea4:	cd b7       	in	r28, 0x3d	; 61
     ea6:	de b7       	in	r29, 0x3e	; 62
     ea8:	7c 01       	movw	r14, r24
     eaa:	4b 01       	movw	r8, r22
     eac:	5d 83       	std	Y+5, r21	; 0x05
     eae:	4c 83       	std	Y+4, r20	; 0x04
     eb0:	c2 2e       	mov	r12, r18
BaseType_t xEntryTimeSet = pdFALSE;
     eb2:	00 e0       	ldi	r16, 0x00	; 0
				else if( xEntryTimeSet == pdFALSE )
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
     eb4:	dd 24       	eor	r13, r13
     eb6:	d3 94       	inc	r13
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
     eb8:	0f 2e       	mov	r0, r31
     eba:	f1 e1       	ldi	r31, 0x11	; 17
     ebc:	af 2e       	mov	r10, r31
     ebe:	bb 24       	eor	r11, r11
     ec0:	f0 2d       	mov	r31, r0
     ec2:	a8 0e       	add	r10, r24
     ec4:	b9 1e       	adc	r11, r25
	statements within the function itself.  This is done in the interest
	of execution time efficiency. */

	for( ;; )
	{
		taskENTER_CRITICAL();
     ec6:	0f b6       	in	r0, 0x3f	; 63
     ec8:	f8 94       	cli
     eca:	0f 92       	push	r0
		{
			const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
     ecc:	f7 01       	movw	r30, r14
     ece:	12 8d       	ldd	r17, Z+26	; 0x1a

			/* Is there data in the queue now?  To be running the calling task
			must be the highest priority task wanting to access the queue. */
			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
     ed0:	11 23       	and	r17, r17
     ed2:	99 f1       	breq	.+102    	; 0xf3a <xQueueGenericReceive+0xb4>
			{
				/* Remember the read position in case the queue is only being
				peeked. */
				pcOriginalReadPosition = pxQueue->u.pcReadFrom;
     ed4:	a6 80       	ldd	r10, Z+6	; 0x06
     ed6:	b7 80       	ldd	r11, Z+7	; 0x07

				prvCopyDataFromQueue( pxQueue, pvBuffer );
     ed8:	c7 01       	movw	r24, r14
     eda:	b4 01       	movw	r22, r8
     edc:	0e 94 e0 04 	call	0x9c0	; 0x9c0 <prvCopyDataFromQueue>

				if( xJustPeeking == pdFALSE )
     ee0:	cc 20       	and	r12, r12
     ee2:	c9 f4       	brne	.+50     	; 0xf16 <xQueueGenericReceive+0x90>
				{
					traceQUEUE_RECEIVE( pxQueue );

					/* Actually removing data, not just peeking. */
					pxQueue->uxMessagesWaiting = uxMessagesWaiting - 1;
     ee4:	11 50       	subi	r17, 0x01	; 1
     ee6:	f7 01       	movw	r30, r14
     ee8:	12 8f       	std	Z+26, r17	; 0x1a

					#if ( configUSE_MUTEXES == 1 )
					{
						if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
     eea:	80 81       	ld	r24, Z
     eec:	91 81       	ldd	r25, Z+1	; 0x01
     eee:	00 97       	sbiw	r24, 0x00	; 0
     ef0:	29 f4       	brne	.+10     	; 0xefc <xQueueGenericReceive+0x76>
						{
							/* Record the information required to implement
							priority inheritance should it become necessary. */
							pxQueue->pxMutexHolder = ( int8_t * ) pvTaskIncrementMutexHeldCount(); /*lint !e961 Cast is not redundant as TaskHandle_t is a typedef. */
     ef2:	0e 94 37 11 	call	0x226e	; 0x226e <pvTaskIncrementMutexHeldCount>
     ef6:	f7 01       	movw	r30, r14
     ef8:	93 83       	std	Z+3, r25	; 0x03
     efa:	82 83       	std	Z+2, r24	; 0x02
							mtCOVERAGE_TEST_MARKER();
						}
					}
					#endif /* configUSE_MUTEXES */

					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     efc:	f7 01       	movw	r30, r14
     efe:	80 85       	ldd	r24, Z+8	; 0x08
     f00:	88 23       	and	r24, r24
     f02:	b9 f0       	breq	.+46     	; 0xf32 <xQueueGenericReceive+0xac>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
     f04:	c7 01       	movw	r24, r14
     f06:	08 96       	adiw	r24, 0x08	; 8
     f08:	0e 94 b2 0f 	call	0x1f64	; 0x1f64 <xTaskRemoveFromEventList>
     f0c:	88 23       	and	r24, r24
     f0e:	89 f0       	breq	.+34     	; 0xf32 <xQueueGenericReceive+0xac>
						{
							queueYIELD_IF_USING_PREEMPTION();
     f10:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
     f14:	0e c0       	rjmp	.+28     	; 0xf32 <xQueueGenericReceive+0xac>
				{
					traceQUEUE_PEEK( pxQueue );

					/* The data is not being removed, so reset the read
					pointer. */
					pxQueue->u.pcReadFrom = pcOriginalReadPosition;
     f16:	f7 01       	movw	r30, r14
     f18:	b7 82       	std	Z+7, r11	; 0x07
     f1a:	a6 82       	std	Z+6, r10	; 0x06

					/* The data is being left in the queue, so see if there are
					any other tasks waiting for the data. */
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     f1c:	81 89       	ldd	r24, Z+17	; 0x11
     f1e:	88 23       	and	r24, r24
     f20:	41 f0       	breq	.+16     	; 0xf32 <xQueueGenericReceive+0xac>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     f22:	c7 01       	movw	r24, r14
     f24:	41 96       	adiw	r24, 0x11	; 17
     f26:	0e 94 b2 0f 	call	0x1f64	; 0x1f64 <xTaskRemoveFromEventList>
     f2a:	88 23       	and	r24, r24
     f2c:	11 f0       	breq	.+4      	; 0xf32 <xQueueGenericReceive+0xac>
						{
							/* The task waiting has a higher priority than this task. */
							queueYIELD_IF_USING_PREEMPTION();
     f2e:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				taskEXIT_CRITICAL();
     f32:	0f 90       	pop	r0
     f34:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
     f36:	81 e0       	ldi	r24, 0x01	; 1
     f38:	61 c0       	rjmp	.+194    	; 0xffc <xQueueGenericReceive+0x176>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
     f3a:	8c 81       	ldd	r24, Y+4	; 0x04
     f3c:	9d 81       	ldd	r25, Y+5	; 0x05
     f3e:	00 97       	sbiw	r24, 0x00	; 0
     f40:	21 f4       	brne	.+8      	; 0xf4a <xQueueGenericReceive+0xc4>
				{
					/* The queue was empty and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
     f42:	0f 90       	pop	r0
     f44:	0f be       	out	0x3f, r0	; 63
					traceQUEUE_RECEIVE_FAILED( pxQueue );
					return errQUEUE_EMPTY;
     f46:	80 e0       	ldi	r24, 0x00	; 0
     f48:	59 c0       	rjmp	.+178    	; 0xffc <xQueueGenericReceive+0x176>
				}
				else if( xEntryTimeSet == pdFALSE )
     f4a:	00 23       	and	r16, r16
     f4c:	29 f4       	brne	.+10     	; 0xf58 <xQueueGenericReceive+0xd2>
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
     f4e:	ce 01       	movw	r24, r28
     f50:	01 96       	adiw	r24, 0x01	; 1
     f52:	0e 94 37 10 	call	0x206e	; 0x206e <vTaskSetTimeOutState>
					xEntryTimeSet = pdTRUE;
     f56:	0d 2d       	mov	r16, r13
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
     f58:	0f 90       	pop	r0
     f5a:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
     f5c:	0e 94 f3 0c 	call	0x19e6	; 0x19e6 <vTaskSuspendAll>
		prvLockQueue( pxQueue );
     f60:	0f b6       	in	r0, 0x3f	; 63
     f62:	f8 94       	cli
     f64:	0f 92       	push	r0
     f66:	f7 01       	movw	r30, r14
     f68:	85 8d       	ldd	r24, Z+29	; 0x1d
     f6a:	8f 3f       	cpi	r24, 0xFF	; 255
     f6c:	09 f4       	brne	.+2      	; 0xf70 <xQueueGenericReceive+0xea>
     f6e:	15 8e       	std	Z+29, r1	; 0x1d
     f70:	f7 01       	movw	r30, r14
     f72:	86 8d       	ldd	r24, Z+30	; 0x1e
     f74:	8f 3f       	cpi	r24, 0xFF	; 255
     f76:	09 f4       	brne	.+2      	; 0xf7a <xQueueGenericReceive+0xf4>
     f78:	16 8e       	std	Z+30, r1	; 0x1e
     f7a:	0f 90       	pop	r0
     f7c:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
     f7e:	ce 01       	movw	r24, r28
     f80:	01 96       	adiw	r24, 0x01	; 1
     f82:	be 01       	movw	r22, r28
     f84:	6c 5f       	subi	r22, 0xFC	; 252
     f86:	7f 4f       	sbci	r23, 0xFF	; 255
     f88:	0e 94 42 10 	call	0x2084	; 0x2084 <xTaskCheckForTimeOut>
     f8c:	88 23       	and	r24, r24
     f8e:	51 f5       	brne	.+84     	; 0xfe4 <xQueueGenericReceive+0x15e>
		{
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
     f90:	c7 01       	movw	r24, r14
     f92:	0e 94 d5 04 	call	0x9aa	; 0x9aa <prvIsQueueEmpty>
     f96:	88 23       	and	r24, r24
     f98:	f9 f0       	breq	.+62     	; 0xfd8 <xQueueGenericReceive+0x152>
			{
				traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );

				#if ( configUSE_MUTEXES == 1 )
				{
					if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
     f9a:	f7 01       	movw	r30, r14
     f9c:	80 81       	ld	r24, Z
     f9e:	91 81       	ldd	r25, Z+1	; 0x01
     fa0:	00 97       	sbiw	r24, 0x00	; 0
     fa2:	51 f4       	brne	.+20     	; 0xfb8 <xQueueGenericReceive+0x132>
					{
						taskENTER_CRITICAL();
     fa4:	0f b6       	in	r0, 0x3f	; 63
     fa6:	f8 94       	cli
     fa8:	0f 92       	push	r0
						{
							vTaskPriorityInherit( ( void * ) pxQueue->pxMutexHolder );
     faa:	f7 01       	movw	r30, r14
     fac:	82 81       	ldd	r24, Z+2	; 0x02
     fae:	93 81       	ldd	r25, Z+3	; 0x03
     fb0:	0e 94 80 10 	call	0x2100	; 0x2100 <vTaskPriorityInherit>
						}
						taskEXIT_CRITICAL();
     fb4:	0f 90       	pop	r0
     fb6:	0f be       	out	0x3f, r0	; 63
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
     fb8:	6c 81       	ldd	r22, Y+4	; 0x04
     fba:	7d 81       	ldd	r23, Y+5	; 0x05
     fbc:	c5 01       	movw	r24, r10
     fbe:	0e 94 87 0f 	call	0x1f0e	; 0x1f0e <vTaskPlaceOnEventList>
				prvUnlockQueue( pxQueue );
     fc2:	c7 01       	movw	r24, r14
     fc4:	0e 94 fd 04 	call	0x9fa	; 0x9fa <prvUnlockQueue>
				if( xTaskResumeAll() == pdFALSE )
     fc8:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>
     fcc:	88 23       	and	r24, r24
     fce:	09 f0       	breq	.+2      	; 0xfd2 <xQueueGenericReceive+0x14c>
     fd0:	7a cf       	rjmp	.-268    	; 0xec6 <xQueueGenericReceive+0x40>
				{
					portYIELD_WITHIN_API();
     fd2:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
     fd6:	77 cf       	rjmp	.-274    	; 0xec6 <xQueueGenericReceive+0x40>
				}
			}
			else
			{
				/* Try again. */
				prvUnlockQueue( pxQueue );
     fd8:	c7 01       	movw	r24, r14
     fda:	0e 94 fd 04 	call	0x9fa	; 0x9fa <prvUnlockQueue>
				( void ) xTaskResumeAll();
     fde:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>
     fe2:	71 cf       	rjmp	.-286    	; 0xec6 <xQueueGenericReceive+0x40>
			}
		}
		else
		{
			prvUnlockQueue( pxQueue );
     fe4:	c7 01       	movw	r24, r14
     fe6:	0e 94 fd 04 	call	0x9fa	; 0x9fa <prvUnlockQueue>
			( void ) xTaskResumeAll();
     fea:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>

			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
     fee:	c7 01       	movw	r24, r14
     ff0:	0e 94 d5 04 	call	0x9aa	; 0x9aa <prvIsQueueEmpty>
     ff4:	88 23       	and	r24, r24
     ff6:	09 f4       	brne	.+2      	; 0xffa <xQueueGenericReceive+0x174>
     ff8:	66 cf       	rjmp	.-308    	; 0xec6 <xQueueGenericReceive+0x40>
			{
				traceQUEUE_RECEIVE_FAILED( pxQueue );
				return errQUEUE_EMPTY;
     ffa:	80 e0       	ldi	r24, 0x00	; 0
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	}
}
     ffc:	0f 90       	pop	r0
     ffe:	0f 90       	pop	r0
    1000:	0f 90       	pop	r0
    1002:	0f 90       	pop	r0
    1004:	0f 90       	pop	r0
    1006:	df 91       	pop	r29
    1008:	cf 91       	pop	r28
    100a:	1f 91       	pop	r17
    100c:	0f 91       	pop	r16
    100e:	ff 90       	pop	r15
    1010:	ef 90       	pop	r14
    1012:	df 90       	pop	r13
    1014:	cf 90       	pop	r12
    1016:	bf 90       	pop	r11
    1018:	af 90       	pop	r10
    101a:	9f 90       	pop	r9
    101c:	8f 90       	pop	r8
    101e:	08 95       	ret

00001020 <xQueueReceiveFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue, void * const pvBuffer, BaseType_t * const pxHigherPriorityTaskWoken )
{
    1020:	ef 92       	push	r14
    1022:	ff 92       	push	r15
    1024:	0f 93       	push	r16
    1026:	1f 93       	push	r17
    1028:	cf 93       	push	r28
    102a:	df 93       	push	r29
    102c:	8c 01       	movw	r16, r24
    102e:	7a 01       	movw	r14, r20
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    1030:	fc 01       	movw	r30, r24
    1032:	c2 8d       	ldd	r28, Z+26	; 0x1a

		/* Cannot block in an ISR, so check there is data available. */
		if( uxMessagesWaiting > ( UBaseType_t ) 0 )
    1034:	cc 23       	and	r28, r28
    1036:	e9 f0       	breq	.+58     	; 0x1072 <xQueueReceiveFromISR+0x52>
		{
			const int8_t cRxLock = pxQueue->cRxLock;
    1038:	d5 8d       	ldd	r29, Z+29	; 0x1d

			traceQUEUE_RECEIVE_FROM_ISR( pxQueue );

			prvCopyDataFromQueue( pxQueue, pvBuffer );
    103a:	0e 94 e0 04 	call	0x9c0	; 0x9c0 <prvCopyDataFromQueue>
			pxQueue->uxMessagesWaiting = uxMessagesWaiting - 1;
    103e:	c1 50       	subi	r28, 0x01	; 1
    1040:	f8 01       	movw	r30, r16
    1042:	c2 8f       	std	Z+26, r28	; 0x1a

			/* If the queue is locked the event list will not be modified.
			Instead update the lock count so the task that unlocks the queue
			will know that an ISR has removed data while the queue was
			locked. */
			if( cRxLock == queueUNLOCKED )
    1044:	df 3f       	cpi	r29, 0xFF	; 255
    1046:	81 f4       	brne	.+32     	; 0x1068 <xQueueReceiveFromISR+0x48>
			{
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    1048:	80 85       	ldd	r24, Z+8	; 0x08
    104a:	88 23       	and	r24, r24
    104c:	a1 f0       	breq	.+40     	; 0x1076 <xQueueReceiveFromISR+0x56>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    104e:	c8 01       	movw	r24, r16
    1050:	08 96       	adiw	r24, 0x08	; 8
    1052:	0e 94 b2 0f 	call	0x1f64	; 0x1f64 <xTaskRemoveFromEventList>
    1056:	88 23       	and	r24, r24
    1058:	81 f0       	breq	.+32     	; 0x107a <xQueueReceiveFromISR+0x5a>
					{
						/* The task waiting has a higher priority than us so
						force a context switch. */
						if( pxHigherPriorityTaskWoken != NULL )
    105a:	e1 14       	cp	r14, r1
    105c:	f1 04       	cpc	r15, r1
    105e:	79 f0       	breq	.+30     	; 0x107e <xQueueReceiveFromISR+0x5e>
						{
							*pxHigherPriorityTaskWoken = pdTRUE;
    1060:	81 e0       	ldi	r24, 0x01	; 1
    1062:	f7 01       	movw	r30, r14
    1064:	80 83       	st	Z, r24
    1066:	0c c0       	rjmp	.+24     	; 0x1080 <xQueueReceiveFromISR+0x60>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was removed while it was locked. */
				pxQueue->cRxLock = ( int8_t ) ( cRxLock + 1 );
    1068:	df 5f       	subi	r29, 0xFF	; 255
    106a:	f8 01       	movw	r30, r16
    106c:	d5 8f       	std	Z+29, r29	; 0x1d
			}

			xReturn = pdPASS;
    106e:	81 e0       	ldi	r24, 0x01	; 1
    1070:	07 c0       	rjmp	.+14     	; 0x1080 <xQueueReceiveFromISR+0x60>
		}
		else
		{
			xReturn = pdFAIL;
    1072:	80 e0       	ldi	r24, 0x00	; 0
    1074:	05 c0       	rjmp	.+10     	; 0x1080 <xQueueReceiveFromISR+0x60>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was removed while it was locked. */
				pxQueue->cRxLock = ( int8_t ) ( cRxLock + 1 );
			}

			xReturn = pdPASS;
    1076:	81 e0       	ldi	r24, 0x01	; 1
    1078:	03 c0       	rjmp	.+6      	; 0x1080 <xQueueReceiveFromISR+0x60>
    107a:	81 e0       	ldi	r24, 0x01	; 1
    107c:	01 c0       	rjmp	.+2      	; 0x1080 <xQueueReceiveFromISR+0x60>
    107e:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    1080:	df 91       	pop	r29
    1082:	cf 91       	pop	r28
    1084:	1f 91       	pop	r17
    1086:	0f 91       	pop	r16
    1088:	ff 90       	pop	r15
    108a:	ef 90       	pop	r14
    108c:	08 95       	ret

0000108e <xQueuePeekFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueuePeekFromISR( QueueHandle_t xQueue,  void * const pvBuffer )
{
    108e:	0f 93       	push	r16
    1090:	1f 93       	push	r17
    1092:	cf 93       	push	r28
    1094:	df 93       	push	r29
    1096:	ec 01       	movw	r28, r24
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		/* Cannot block in an ISR, so check there is data available. */
		if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
    1098:	8a 8d       	ldd	r24, Y+26	; 0x1a
    109a:	88 23       	and	r24, r24
    109c:	49 f0       	breq	.+18     	; 0x10b0 <xQueuePeekFromISR+0x22>
		{
			traceQUEUE_PEEK_FROM_ISR( pxQueue );

			/* Remember the read position so it can be reset as nothing is
			actually being removed from the queue. */
			pcOriginalReadPosition = pxQueue->u.pcReadFrom;
    109e:	0e 81       	ldd	r16, Y+6	; 0x06
    10a0:	1f 81       	ldd	r17, Y+7	; 0x07
			prvCopyDataFromQueue( pxQueue, pvBuffer );
    10a2:	ce 01       	movw	r24, r28
    10a4:	0e 94 e0 04 	call	0x9c0	; 0x9c0 <prvCopyDataFromQueue>
			pxQueue->u.pcReadFrom = pcOriginalReadPosition;
    10a8:	1f 83       	std	Y+7, r17	; 0x07
    10aa:	0e 83       	std	Y+6, r16	; 0x06

			xReturn = pdPASS;
    10ac:	81 e0       	ldi	r24, 0x01	; 1
    10ae:	01 c0       	rjmp	.+2      	; 0x10b2 <xQueuePeekFromISR+0x24>
		}
		else
		{
			xReturn = pdFAIL;
    10b0:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    10b2:	df 91       	pop	r29
    10b4:	cf 91       	pop	r28
    10b6:	1f 91       	pop	r17
    10b8:	0f 91       	pop	r16
    10ba:	08 95       	ret

000010bc <uxQueueMessagesWaiting>:
{
UBaseType_t uxReturn;

	configASSERT( xQueue );

	taskENTER_CRITICAL();
    10bc:	0f b6       	in	r0, 0x3f	; 63
    10be:	f8 94       	cli
    10c0:	0f 92       	push	r0
	{
		uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
    10c2:	fc 01       	movw	r30, r24
    10c4:	82 8d       	ldd	r24, Z+26	; 0x1a
	}
	taskEXIT_CRITICAL();
    10c6:	0f 90       	pop	r0
    10c8:	0f be       	out	0x3f, r0	; 63

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    10ca:	08 95       	ret

000010cc <uxQueueSpacesAvailable>:
/*-----------------------------------------------------------*/

UBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue )
{
    10cc:	fc 01       	movw	r30, r24
Queue_t *pxQueue;

	pxQueue = ( Queue_t * ) xQueue;
	configASSERT( pxQueue );

	taskENTER_CRITICAL();
    10ce:	0f b6       	in	r0, 0x3f	; 63
    10d0:	f8 94       	cli
    10d2:	0f 92       	push	r0
	{
		uxReturn = pxQueue->uxLength - pxQueue->uxMessagesWaiting;
    10d4:	92 8d       	ldd	r25, Z+26	; 0x1a
	}
	taskEXIT_CRITICAL();
    10d6:	0f 90       	pop	r0
    10d8:	0f be       	out	0x3f, r0	; 63
	pxQueue = ( Queue_t * ) xQueue;
	configASSERT( pxQueue );

	taskENTER_CRITICAL();
	{
		uxReturn = pxQueue->uxLength - pxQueue->uxMessagesWaiting;
    10da:	83 8d       	ldd	r24, Z+27	; 0x1b
	}
	taskEXIT_CRITICAL();

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    10dc:	89 1b       	sub	r24, r25
    10de:	08 95       	ret

000010e0 <uxQueueMessagesWaitingFromISR>:
{
UBaseType_t uxReturn;

	configASSERT( xQueue );

	uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
    10e0:	fc 01       	movw	r30, r24
    10e2:	82 8d       	ldd	r24, Z+26	; 0x1a

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    10e4:	08 95       	ret

000010e6 <xQueueIsQueueEmptyFromISR>:
BaseType_t xQueueIsQueueEmptyFromISR( const QueueHandle_t xQueue )
{
BaseType_t xReturn;

	configASSERT( xQueue );
	if( ( ( Queue_t * ) xQueue )->uxMessagesWaiting == ( UBaseType_t ) 0 )
    10e6:	fc 01       	movw	r30, r24
    10e8:	92 8d       	ldd	r25, Z+26	; 0x1a
	{
		xReturn = pdTRUE;
    10ea:	81 e0       	ldi	r24, 0x01	; 1
    10ec:	91 11       	cpse	r25, r1
    10ee:	80 e0       	ldi	r24, 0x00	; 0
	{
		xReturn = pdFALSE;
	}

	return xReturn;
} /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
    10f0:	08 95       	ret

000010f2 <xQueueIsQueueFullFromISR>:
	return xReturn;
}
/*-----------------------------------------------------------*/

BaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue )
{
    10f2:	fc 01       	movw	r30, r24
BaseType_t xReturn;

	configASSERT( xQueue );
	if( ( ( Queue_t * ) xQueue )->uxMessagesWaiting == ( ( Queue_t * ) xQueue )->uxLength )
    10f4:	22 8d       	ldd	r18, Z+26	; 0x1a
	{
		xReturn = pdTRUE;
    10f6:	81 e0       	ldi	r24, 0x01	; 1
    10f8:	93 8d       	ldd	r25, Z+27	; 0x1b
    10fa:	29 13       	cpse	r18, r25
    10fc:	80 e0       	ldi	r24, 0x00	; 0
	{
		xReturn = pdFALSE;
	}

	return xReturn;
} /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
    10fe:	08 95       	ret

00001100 <vQueueAddToRegistry>:
/*-----------------------------------------------------------*/

#if ( configQUEUE_REGISTRY_SIZE > 0 )

	void vQueueAddToRegistry( QueueHandle_t xQueue, const char *pcQueueName ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
	{
    1100:	dc 01       	movw	r26, r24

		/* See if there is an empty space in the registry.  A NULL name denotes
		a free slot. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
		{
			if( xQueueRegistry[ ux ].pcQueueName == NULL )
    1102:	80 91 06 04 	lds	r24, 0x0406
    1106:	90 91 07 04 	lds	r25, 0x0407
    110a:	00 97       	sbiw	r24, 0x00	; 0
    110c:	51 f0       	breq	.+20     	; 0x1122 <vQueueAddToRegistry+0x22>
    110e:	ea e0       	ldi	r30, 0x0A	; 10
    1110:	f4 e0       	ldi	r31, 0x04	; 4
    1112:	21 e0       	ldi	r18, 0x01	; 1
    1114:	30 e0       	ldi	r19, 0x00	; 0
    1116:	a9 01       	movw	r20, r18
    1118:	80 81       	ld	r24, Z
    111a:	91 81       	ldd	r25, Z+1	; 0x01
    111c:	00 97       	sbiw	r24, 0x00	; 0
    111e:	79 f4       	brne	.+30     	; 0x113e <vQueueAddToRegistry+0x3e>
    1120:	02 c0       	rjmp	.+4      	; 0x1126 <vQueueAddToRegistry+0x26>
    1122:	40 e0       	ldi	r20, 0x00	; 0
    1124:	50 e0       	ldi	r21, 0x00	; 0
			{
				/* Store the information on this queue. */
				xQueueRegistry[ ux ].pcQueueName = pcQueueName;
    1126:	fa 01       	movw	r30, r20
    1128:	ee 0f       	add	r30, r30
    112a:	ff 1f       	adc	r31, r31
    112c:	ee 0f       	add	r30, r30
    112e:	ff 1f       	adc	r31, r31
    1130:	ea 5f       	subi	r30, 0xFA	; 250
    1132:	fb 4f       	sbci	r31, 0xFB	; 251
    1134:	71 83       	std	Z+1, r23	; 0x01
    1136:	60 83       	st	Z, r22
				xQueueRegistry[ ux ].xHandle = xQueue;
    1138:	b3 83       	std	Z+3, r27	; 0x03
    113a:	a2 83       	std	Z+2, r26	; 0x02

				traceQUEUE_REGISTRY_ADD( xQueue, pcQueueName );
				break;
    113c:	08 95       	ret
    113e:	2f 5f       	subi	r18, 0xFF	; 255
    1140:	3f 4f       	sbci	r19, 0xFF	; 255
    1142:	34 96       	adiw	r30, 0x04	; 4
	{
	UBaseType_t ux;

		/* See if there is an empty space in the registry.  A NULL name denotes
		a free slot. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
    1144:	28 30       	cpi	r18, 0x08	; 8
    1146:	31 05       	cpc	r19, r1
    1148:	31 f7       	brne	.-52     	; 0x1116 <vQueueAddToRegistry+0x16>
    114a:	08 95       	ret

0000114c <pcQueueGetName>:
/*-----------------------------------------------------------*/

#if ( configQUEUE_REGISTRY_SIZE > 0 )

	const char *pcQueueGetName( QueueHandle_t xQueue ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
	{
    114c:	ac 01       	movw	r20, r24

		/* Note there is nothing here to protect against another task adding or
		removing entries from the registry while it is being searched. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
		{
			if( xQueueRegistry[ ux ].xHandle == xQueue )
    114e:	80 91 08 04 	lds	r24, 0x0408
    1152:	90 91 09 04 	lds	r25, 0x0409
    1156:	84 17       	cp	r24, r20
    1158:	95 07       	cpc	r25, r21
    115a:	59 f0       	breq	.+22     	; 0x1172 <pcQueueGetName+0x26>
    115c:	ec e0       	ldi	r30, 0x0C	; 12
    115e:	f4 e0       	ldi	r31, 0x04	; 4
    1160:	21 e0       	ldi	r18, 0x01	; 1
    1162:	30 e0       	ldi	r19, 0x00	; 0
    1164:	b9 01       	movw	r22, r18
    1166:	80 81       	ld	r24, Z
    1168:	91 81       	ldd	r25, Z+1	; 0x01
    116a:	84 17       	cp	r24, r20
    116c:	95 07       	cpc	r25, r21
    116e:	69 f4       	brne	.+26     	; 0x118a <pcQueueGetName+0x3e>
    1170:	02 c0       	rjmp	.+4      	; 0x1176 <pcQueueGetName+0x2a>
    1172:	60 e0       	ldi	r22, 0x00	; 0
    1174:	70 e0       	ldi	r23, 0x00	; 0
			{
				pcReturn = xQueueRegistry[ ux ].pcQueueName;
    1176:	fb 01       	movw	r30, r22
    1178:	ee 0f       	add	r30, r30
    117a:	ff 1f       	adc	r31, r31
    117c:	ee 0f       	add	r30, r30
    117e:	ff 1f       	adc	r31, r31
    1180:	ea 5f       	subi	r30, 0xFA	; 250
    1182:	fb 4f       	sbci	r31, 0xFB	; 251
    1184:	80 81       	ld	r24, Z
    1186:	91 81       	ldd	r25, Z+1	; 0x01
				break;
    1188:	08 95       	ret
    118a:	2f 5f       	subi	r18, 0xFF	; 255
    118c:	3f 4f       	sbci	r19, 0xFF	; 255
    118e:	34 96       	adiw	r30, 0x04	; 4
	UBaseType_t ux;
	const char *pcReturn = NULL; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */

		/* Note there is nothing here to protect against another task adding or
		removing entries from the registry while it is being searched. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
    1190:	28 30       	cpi	r18, 0x08	; 8
    1192:	31 05       	cpc	r19, r1
    1194:	39 f7       	brne	.-50     	; 0x1164 <pcQueueGetName+0x18>
#if ( configQUEUE_REGISTRY_SIZE > 0 )

	const char *pcQueueGetName( QueueHandle_t xQueue ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
	{
	UBaseType_t ux;
	const char *pcReturn = NULL; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
    1196:	80 e0       	ldi	r24, 0x00	; 0
    1198:	90 e0       	ldi	r25, 0x00	; 0
				mtCOVERAGE_TEST_MARKER();
			}
		}

		return pcReturn;
	}
    119a:	08 95       	ret

0000119c <vQueueUnregisterQueue>:
/*-----------------------------------------------------------*/

#if ( configQUEUE_REGISTRY_SIZE > 0 )

	void vQueueUnregisterQueue( QueueHandle_t xQueue )
	{
    119c:	ac 01       	movw	r20, r24

		/* See if the handle of the queue being unregistered in actually in the
		registry. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
		{
			if( xQueueRegistry[ ux ].xHandle == xQueue )
    119e:	80 91 08 04 	lds	r24, 0x0408
    11a2:	90 91 09 04 	lds	r25, 0x0409
    11a6:	84 17       	cp	r24, r20
    11a8:	95 07       	cpc	r25, r21
    11aa:	59 f0       	breq	.+22     	; 0x11c2 <vQueueUnregisterQueue+0x26>
    11ac:	ec e0       	ldi	r30, 0x0C	; 12
    11ae:	f4 e0       	ldi	r31, 0x04	; 4
    11b0:	21 e0       	ldi	r18, 0x01	; 1
    11b2:	30 e0       	ldi	r19, 0x00	; 0
    11b4:	b9 01       	movw	r22, r18
    11b6:	80 81       	ld	r24, Z
    11b8:	91 81       	ldd	r25, Z+1	; 0x01
    11ba:	84 17       	cp	r24, r20
    11bc:	95 07       	cpc	r25, r21
    11be:	79 f4       	brne	.+30     	; 0x11de <vQueueUnregisterQueue+0x42>
    11c0:	02 c0       	rjmp	.+4      	; 0x11c6 <vQueueUnregisterQueue+0x2a>
    11c2:	60 e0       	ldi	r22, 0x00	; 0
    11c4:	70 e0       	ldi	r23, 0x00	; 0
			{
				/* Set the name to NULL to show that this slot if free again. */
				xQueueRegistry[ ux ].pcQueueName = NULL;
    11c6:	fb 01       	movw	r30, r22
    11c8:	ee 0f       	add	r30, r30
    11ca:	ff 1f       	adc	r31, r31
    11cc:	ee 0f       	add	r30, r30
    11ce:	ff 1f       	adc	r31, r31
    11d0:	ea 5f       	subi	r30, 0xFA	; 250
    11d2:	fb 4f       	sbci	r31, 0xFB	; 251
    11d4:	11 82       	std	Z+1, r1	; 0x01
    11d6:	10 82       	st	Z, r1

				/* Set the handle to NULL to ensure the same queue handle cannot
				appear in the registry twice if it is added, removed, then
				added again. */
				xQueueRegistry[ ux ].xHandle = ( QueueHandle_t ) 0;
    11d8:	13 82       	std	Z+3, r1	; 0x03
    11da:	12 82       	std	Z+2, r1	; 0x02
				break;
    11dc:	08 95       	ret
    11de:	2f 5f       	subi	r18, 0xFF	; 255
    11e0:	3f 4f       	sbci	r19, 0xFF	; 255
    11e2:	34 96       	adiw	r30, 0x04	; 4
	{
	UBaseType_t ux;

		/* See if the handle of the queue being unregistered in actually in the
		registry. */
		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
    11e4:	28 30       	cpi	r18, 0x08	; 8
    11e6:	31 05       	cpc	r19, r1
    11e8:	29 f7       	brne	.-54     	; 0x11b4 <vQueueUnregisterQueue+0x18>
    11ea:	08 95       	ret

000011ec <vQueueDelete>:
	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
/*-----------------------------------------------------------*/

void vQueueDelete( QueueHandle_t xQueue )
{
    11ec:	cf 93       	push	r28
    11ee:	df 93       	push	r29
    11f0:	ec 01       	movw	r28, r24
	configASSERT( pxQueue );
	traceQUEUE_DELETE( pxQueue );

	#if ( configQUEUE_REGISTRY_SIZE > 0 )
	{
		vQueueUnregisterQueue( pxQueue );
    11f2:	0e 94 ce 08 	call	0x119c	; 0x119c <vQueueUnregisterQueue>

	#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
	{
		/* The queue can only have been allocated dynamically - free it
		again. */
		vPortFree( pxQueue );
    11f6:	ce 01       	movw	r24, r28
    11f8:	0e 94 92 02 	call	0x524	; 0x524 <vPortFree>
		/* The queue must have been statically allocated, so is not going to be
		deleted.  Avoid compiler warnings about the unused parameter. */
		( void ) pxQueue;
	}
	#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
}
    11fc:	df 91       	pop	r29
    11fe:	cf 91       	pop	r28
    1200:	08 95       	ret

00001202 <T2>:
}
void T2(void *pv)
{
	while(1)
	{
		xSemaphoreTake(myMutex,1000);
    1202:	80 91 26 04 	lds	r24, 0x0426
    1206:	90 91 27 04 	lds	r25, 0x0427
    120a:	60 e0       	ldi	r22, 0x00	; 0
    120c:	70 e0       	ldi	r23, 0x00	; 0
    120e:	48 ee       	ldi	r20, 0xE8	; 232
    1210:	53 e0       	ldi	r21, 0x03	; 3
    1212:	20 e0       	ldi	r18, 0x00	; 0
    1214:	0e 94 43 07 	call	0xe86	; 0xe86 <xQueueGenericReceive>
		x++;
    1218:	80 91 95 03 	lds	r24, 0x0395
    121c:	90 91 96 03 	lds	r25, 0x0396
    1220:	01 96       	adiw	r24, 0x01	; 1
    1222:	90 93 96 03 	sts	0x0396, r25
    1226:	80 93 95 03 	sts	0x0395, r24
	#else
		//round up by default
		__ticks_dc = (uint32_t)(ceil(fabs(__tmp)));
	#endif

	__builtin_avr_delay_cycles(__ticks_dc);
    122a:	8f ef       	ldi	r24, 0xFF	; 255
    122c:	92 e5       	ldi	r25, 0x52	; 82
    122e:	a7 e0       	ldi	r26, 0x07	; 7
    1230:	81 50       	subi	r24, 0x01	; 1
    1232:	90 40       	sbci	r25, 0x00	; 0
    1234:	a0 40       	sbci	r26, 0x00	; 0
    1236:	e1 f7       	brne	.-8      	; 0x1230 <T2+0x2e>
    1238:	00 c0       	rjmp	.+0      	; 0x123a <T2+0x38>
    123a:	00 00       	nop
		_delay_ms(200);
		y++;
    123c:	80 91 93 03 	lds	r24, 0x0393
    1240:	90 91 94 03 	lds	r25, 0x0394
    1244:	01 96       	adiw	r24, 0x01	; 1
    1246:	90 93 94 03 	sts	0x0394, r25
    124a:	80 93 93 03 	sts	0x0393, r24
		xSemaphoreGive(myMutex);
    124e:	80 91 26 04 	lds	r24, 0x0426
    1252:	90 91 27 04 	lds	r25, 0x0427
    1256:	60 e0       	ldi	r22, 0x00	; 0
    1258:	70 e0       	ldi	r23, 0x00	; 0
    125a:	40 e0       	ldi	r20, 0x00	; 0
    125c:	50 e0       	ldi	r21, 0x00	; 0
    125e:	20 e0       	ldi	r18, 0x00	; 0
    1260:	0e 94 20 06 	call	0xc40	; 0xc40 <xQueueGenericSend>
    1264:	ce cf       	rjmp	.-100    	; 0x1202 <T2>

00001266 <T1>:

SemaphoreHandle_t myMutex;

void T1(void *pv)
{
	DDRD |= (1<<7);
    1266:	8f 9a       	sbi	0x11, 7	; 17
	while(1)
	{
		xSemaphoreTake(myMutex,1000);
    1268:	80 91 26 04 	lds	r24, 0x0426
    126c:	90 91 27 04 	lds	r25, 0x0427
    1270:	60 e0       	ldi	r22, 0x00	; 0
    1272:	70 e0       	ldi	r23, 0x00	; 0
    1274:	48 ee       	ldi	r20, 0xE8	; 232
    1276:	53 e0       	ldi	r21, 0x03	; 3
    1278:	20 e0       	ldi	r18, 0x00	; 0
    127a:	0e 94 43 07 	call	0xe86	; 0xe86 <xQueueGenericReceive>
		if(x != y)
    127e:	20 91 95 03 	lds	r18, 0x0395
    1282:	30 91 96 03 	lds	r19, 0x0396
    1286:	80 91 93 03 	lds	r24, 0x0393
    128a:	90 91 94 03 	lds	r25, 0x0394
    128e:	28 17       	cp	r18, r24
    1290:	39 07       	cpc	r19, r25
    1292:	19 f0       	breq	.+6      	; 0x129a <T1+0x34>
		{
			PORTD ^= (1<<7);
    1294:	82 b3       	in	r24, 0x12	; 18
    1296:	80 58       	subi	r24, 0x80	; 128
    1298:	82 bb       	out	0x12, r24	; 18
		}
		xSemaphoreGive(myMutex);
    129a:	80 91 26 04 	lds	r24, 0x0426
    129e:	90 91 27 04 	lds	r25, 0x0427
    12a2:	60 e0       	ldi	r22, 0x00	; 0
    12a4:	70 e0       	ldi	r23, 0x00	; 0
    12a6:	40 e0       	ldi	r20, 0x00	; 0
    12a8:	50 e0       	ldi	r21, 0x00	; 0
    12aa:	20 e0       	ldi	r18, 0x00	; 0
    12ac:	0e 94 20 06 	call	0xc40	; 0xc40 <xQueueGenericSend>
		vTaskDelay(100);
    12b0:	84 e6       	ldi	r24, 0x64	; 100
    12b2:	90 e0       	ldi	r25, 0x00	; 0
    12b4:	0e 94 89 0e 	call	0x1d12	; 0x1d12 <vTaskDelay>
	}	
    12b8:	d7 cf       	rjmp	.-82     	; 0x1268 <T1+0x2>

000012ba <main>:
		xSemaphoreGive(myMutex);
	}		
}

int main(void)
{
    12ba:	ef 92       	push	r14
    12bc:	ff 92       	push	r15
    12be:	0f 93       	push	r16
    12c0:	1f 93       	push	r17
    12c2:	cf 93       	push	r28
    12c4:	df 93       	push	r29
    myMutex = xSemaphoreCreateMutex();
    12c6:	81 e0       	ldi	r24, 0x01	; 1
    12c8:	0e 94 c6 06 	call	0xd8c	; 0xd8c <xQueueCreateMutex>
    12cc:	90 93 27 04 	sts	0x0427, r25
    12d0:	80 93 26 04 	sts	0x0426, r24
	xTaskCreate(T1," ",100,NULL,2,NULL);
    12d4:	c2 e6       	ldi	r28, 0x62	; 98
    12d6:	d0 e0       	ldi	r29, 0x00	; 0
    12d8:	83 e3       	ldi	r24, 0x33	; 51
    12da:	99 e0       	ldi	r25, 0x09	; 9
    12dc:	be 01       	movw	r22, r28
    12de:	44 e6       	ldi	r20, 0x64	; 100
    12e0:	50 e0       	ldi	r21, 0x00	; 0
    12e2:	20 e0       	ldi	r18, 0x00	; 0
    12e4:	30 e0       	ldi	r19, 0x00	; 0
    12e6:	02 e0       	ldi	r16, 0x02	; 2
    12e8:	10 e0       	ldi	r17, 0x00	; 0
    12ea:	ee 24       	eor	r14, r14
    12ec:	ff 24       	eor	r15, r15
    12ee:	0e 94 2a 0a 	call	0x1454	; 0x1454 <xTaskCreate>
	xTaskCreate(T2," ",100,NULL,1,NULL);
    12f2:	81 e0       	ldi	r24, 0x01	; 1
    12f4:	99 e0       	ldi	r25, 0x09	; 9
    12f6:	be 01       	movw	r22, r28
    12f8:	44 e6       	ldi	r20, 0x64	; 100
    12fa:	50 e0       	ldi	r21, 0x00	; 0
    12fc:	20 e0       	ldi	r18, 0x00	; 0
    12fe:	30 e0       	ldi	r19, 0x00	; 0
    1300:	01 e0       	ldi	r16, 0x01	; 1
    1302:	10 e0       	ldi	r17, 0x00	; 0
    1304:	0e 94 2a 0a 	call	0x1454	; 0x1454 <xTaskCreate>
	vTaskStartScheduler();
    1308:	0e 94 c3 0c 	call	0x1986	; 0x1986 <vTaskStartScheduler>
    130c:	80 e0       	ldi	r24, 0x00	; 0
    130e:	90 e0       	ldi	r25, 0x00	; 0
    1310:	df 91       	pop	r29
    1312:	cf 91       	pop	r28
    1314:	1f 91       	pop	r17
    1316:	0f 91       	pop	r16
    1318:	ff 90       	pop	r15
    131a:	ef 90       	pop	r14
    131c:	08 95       	ret

0000131e <prvTaskIsTaskSuspended>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskSuspend == 1 )

	static BaseType_t prvTaskIsTaskSuspended( const TaskHandle_t xTask )
	{
    131e:	fc 01       	movw	r30, r24

		/* It does not make sense to check if the calling task is suspended. */
		configASSERT( xTask );

		/* Is the task being resumed actually in the suspended list? */
		if( listIS_CONTAINED_WITHIN( &xSuspendedTaskList, &( pxTCB->xStateListItem ) ) != pdFALSE )
    1320:	82 85       	ldd	r24, Z+10	; 0x0a
    1322:	93 85       	ldd	r25, Z+11	; 0x0b
    1324:	23 e0       	ldi	r18, 0x03	; 3
    1326:	8b 3f       	cpi	r24, 0xFB	; 251
    1328:	92 07       	cpc	r25, r18
    132a:	61 f4       	brne	.+24     	; 0x1344 <prvTaskIsTaskSuspended+0x26>
		{
			/* Has the task already been resumed from within an ISR? */
			if( listIS_CONTAINED_WITHIN( &xPendingReadyList, &( pxTCB->xEventListItem ) ) == pdFALSE )
    132c:	24 89       	ldd	r18, Z+20	; 0x14
    132e:	35 89       	ldd	r19, Z+21	; 0x15
    1330:	83 e0       	ldi	r24, 0x03	; 3
    1332:	29 3e       	cpi	r18, 0xE9	; 233
    1334:	38 07       	cpc	r19, r24
    1336:	41 f0       	breq	.+16     	; 0x1348 <prvTaskIsTaskSuspended+0x2a>

#if ( INCLUDE_vTaskSuspend == 1 )

	static BaseType_t prvTaskIsTaskSuspended( const TaskHandle_t xTask )
	{
	BaseType_t xReturn = pdFALSE;
    1338:	81 e0       	ldi	r24, 0x01	; 1
    133a:	21 15       	cp	r18, r1
    133c:	31 05       	cpc	r19, r1
    133e:	29 f0       	breq	.+10     	; 0x134a <prvTaskIsTaskSuspended+0x2c>
    1340:	80 e0       	ldi	r24, 0x00	; 0
    1342:	08 95       	ret
    1344:	80 e0       	ldi	r24, 0x00	; 0
    1346:	08 95       	ret
    1348:	80 e0       	ldi	r24, 0x00	; 0
		{
			mtCOVERAGE_TEST_MARKER();
		}

		return xReturn;
	} /*lint !e818 xTask cannot be a pointer to const because it is a typedef. */
    134a:	08 95       	ret

0000134c <prvResetNextTaskUnblockTime>:

static void prvResetNextTaskUnblockTime( void )
{
TCB_t *pxTCB;

	if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
    134c:	e0 91 a7 03 	lds	r30, 0x03A7
    1350:	f0 91 a8 03 	lds	r31, 0x03A8
    1354:	80 81       	ld	r24, Z
    1356:	88 23       	and	r24, r24
    1358:	39 f4       	brne	.+14     	; 0x1368 <prvResetNextTaskUnblockTime+0x1c>
	{
		/* The new current delayed list is empty.  Set xNextTaskUnblockTime to
		the maximum possible value so it is	extremely unlikely that the
		if( xTickCount >= xNextTaskUnblockTime ) test will pass until
		there is an item in the delayed list. */
		xNextTaskUnblockTime = portMAX_DELAY;
    135a:	8f ef       	ldi	r24, 0xFF	; 255
    135c:	9f ef       	ldi	r25, 0xFF	; 255
    135e:	90 93 9b 03 	sts	0x039B, r25
    1362:	80 93 9a 03 	sts	0x039A, r24
    1366:	08 95       	ret
	{
		/* The new current delayed list is not empty, get the value of
		the item at the head of the delayed list.  This is the time at
		which the task at the head of the delayed list should be removed
		from the Blocked state. */
		( pxTCB ) = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList );
    1368:	e0 91 a7 03 	lds	r30, 0x03A7
    136c:	f0 91 a8 03 	lds	r31, 0x03A8
    1370:	05 80       	ldd	r0, Z+5	; 0x05
    1372:	f6 81       	ldd	r31, Z+6	; 0x06
    1374:	e0 2d       	mov	r30, r0
		xNextTaskUnblockTime = listGET_LIST_ITEM_VALUE( &( ( pxTCB )->xStateListItem ) );
    1376:	06 80       	ldd	r0, Z+6	; 0x06
    1378:	f7 81       	ldd	r31, Z+7	; 0x07
    137a:	e0 2d       	mov	r30, r0
    137c:	82 81       	ldd	r24, Z+2	; 0x02
    137e:	93 81       	ldd	r25, Z+3	; 0x03
    1380:	90 93 9b 03 	sts	0x039B, r25
    1384:	80 93 9a 03 	sts	0x039A, r24
    1388:	08 95       	ret

0000138a <prvAddCurrentTaskToDelayedList>:
#endif /* configUSE_TASK_NOTIFICATIONS */
/*-----------------------------------------------------------*/


static void prvAddCurrentTaskToDelayedList( TickType_t xTicksToWait, const BaseType_t xCanBlockIndefinitely )
{
    138a:	ef 92       	push	r14
    138c:	ff 92       	push	r15
    138e:	1f 93       	push	r17
    1390:	cf 93       	push	r28
    1392:	df 93       	push	r29
    1394:	ec 01       	movw	r28, r24
    1396:	16 2f       	mov	r17, r22
TickType_t xTimeToWake;
const TickType_t xConstTickCount = xTickCount;
    1398:	e0 90 a1 03 	lds	r14, 0x03A1
    139c:	f0 90 a2 03 	lds	r15, 0x03A2
	}
	#endif

	/* Remove the task from the ready list before adding it to the blocked list
	as the same list item is used for both lists. */
	if( uxListRemove( &( pxCurrentTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    13a0:	80 91 97 03 	lds	r24, 0x0397
    13a4:	90 91 98 03 	lds	r25, 0x0398
    13a8:	02 96       	adiw	r24, 0x02	; 2
    13aa:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
		mtCOVERAGE_TEST_MARKER();
	}

	#if ( INCLUDE_vTaskSuspend == 1 )
	{
		if( ( xTicksToWait == portMAX_DELAY ) && ( xCanBlockIndefinitely != pdFALSE ) )
    13ae:	8f ef       	ldi	r24, 0xFF	; 255
    13b0:	cf 3f       	cpi	r28, 0xFF	; 255
    13b2:	d8 07       	cpc	r29, r24
    13b4:	69 f4       	brne	.+26     	; 0x13d0 <prvAddCurrentTaskToDelayedList+0x46>
    13b6:	11 23       	and	r17, r17
    13b8:	59 f0       	breq	.+22     	; 0x13d0 <prvAddCurrentTaskToDelayedList+0x46>
		{
			/* Add the task to the suspended task list instead of a delayed task
			list to ensure it is not woken by a timing event.  It will block
			indefinitely. */
			vListInsertEnd( &xSuspendedTaskList, &( pxCurrentTCB->xStateListItem ) );
    13ba:	60 91 97 03 	lds	r22, 0x0397
    13be:	70 91 98 03 	lds	r23, 0x0398
    13c2:	6e 5f       	subi	r22, 0xFE	; 254
    13c4:	7f 4f       	sbci	r23, 0xFF	; 255
    13c6:	8b ef       	ldi	r24, 0xFB	; 251
    13c8:	93 e0       	ldi	r25, 0x03	; 3
    13ca:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
    13ce:	2f c0       	rjmp	.+94     	; 0x142e <prvAddCurrentTaskToDelayedList+0xa4>
		else
		{
			/* Calculate the time at which the task should be woken if the event
			does not occur.  This may overflow but this doesn't matter, the
			kernel will manage it correctly. */
			xTimeToWake = xConstTickCount + xTicksToWait;
    13d0:	ce 0d       	add	r28, r14
    13d2:	df 1d       	adc	r29, r15

			/* The list item will be inserted in wake time order. */
			listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xStateListItem ), xTimeToWake );
    13d4:	e0 91 97 03 	lds	r30, 0x0397
    13d8:	f0 91 98 03 	lds	r31, 0x0398
    13dc:	d3 83       	std	Z+3, r29	; 0x03
    13de:	c2 83       	std	Z+2, r28	; 0x02

			if( xTimeToWake < xConstTickCount )
    13e0:	ce 15       	cp	r28, r14
    13e2:	df 05       	cpc	r29, r15
    13e4:	68 f4       	brcc	.+26     	; 0x1400 <prvAddCurrentTaskToDelayedList+0x76>
			{
				/* Wake time has overflowed.  Place this item in the overflow
				list. */
				vListInsert( pxOverflowDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
    13e6:	80 91 a5 03 	lds	r24, 0x03A5
    13ea:	90 91 a6 03 	lds	r25, 0x03A6
    13ee:	60 91 97 03 	lds	r22, 0x0397
    13f2:	70 91 98 03 	lds	r23, 0x0398
    13f6:	6e 5f       	subi	r22, 0xFE	; 254
    13f8:	7f 4f       	sbci	r23, 0xFF	; 255
    13fa:	0e 94 fc 02 	call	0x5f8	; 0x5f8 <vListInsert>
    13fe:	17 c0       	rjmp	.+46     	; 0x142e <prvAddCurrentTaskToDelayedList+0xa4>
			}
			else
			{
				/* The wake time has not overflowed, so the current block list
				is used. */
				vListInsert( pxDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
    1400:	80 91 a7 03 	lds	r24, 0x03A7
    1404:	90 91 a8 03 	lds	r25, 0x03A8
    1408:	60 91 97 03 	lds	r22, 0x0397
    140c:	70 91 98 03 	lds	r23, 0x0398
    1410:	6e 5f       	subi	r22, 0xFE	; 254
    1412:	7f 4f       	sbci	r23, 0xFF	; 255
    1414:	0e 94 fc 02 	call	0x5f8	; 0x5f8 <vListInsert>

				/* If the task entering the blocked state was placed at the
				head of the list of blocked tasks then xNextTaskUnblockTime
				needs to be updated too. */
				if( xTimeToWake < xNextTaskUnblockTime )
    1418:	80 91 9a 03 	lds	r24, 0x039A
    141c:	90 91 9b 03 	lds	r25, 0x039B
    1420:	c8 17       	cp	r28, r24
    1422:	d9 07       	cpc	r29, r25
    1424:	20 f4       	brcc	.+8      	; 0x142e <prvAddCurrentTaskToDelayedList+0xa4>
				{
					xNextTaskUnblockTime = xTimeToWake;
    1426:	d0 93 9b 03 	sts	0x039B, r29
    142a:	c0 93 9a 03 	sts	0x039A, r28

		/* Avoid compiler warning when INCLUDE_vTaskSuspend is not 1. */
		( void ) xCanBlockIndefinitely;
	}
	#endif /* INCLUDE_vTaskSuspend */
}
    142e:	df 91       	pop	r29
    1430:	cf 91       	pop	r28
    1432:	1f 91       	pop	r17
    1434:	ff 90       	pop	r15
    1436:	ef 90       	pop	r14
    1438:	08 95       	ret

0000143a <prvDeleteTCB>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelete == 1 )

	static void prvDeleteTCB( TCB_t *pxTCB )
	{
    143a:	cf 93       	push	r28
    143c:	df 93       	push	r29
    143e:	ec 01       	movw	r28, r24

		#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) && ( portUSING_MPU_WRAPPERS == 0 ) )
		{
			/* The task can only have been allocated dynamically - free both
			the stack and TCB. */
			vPortFree( pxTCB->pxStack );
    1440:	8f 89       	ldd	r24, Y+23	; 0x17
    1442:	98 8d       	ldd	r25, Y+24	; 0x18
    1444:	0e 94 92 02 	call	0x524	; 0x524 <vPortFree>
			vPortFree( pxTCB );
    1448:	ce 01       	movw	r24, r28
    144a:	0e 94 92 02 	call	0x524	; 0x524 <vPortFree>
				configASSERT( pxTCB->ucStaticallyAllocated == tskSTATICALLY_ALLOCATED_STACK_AND_TCB	)
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
	}
    144e:	df 91       	pop	r29
    1450:	cf 91       	pop	r28
    1452:	08 95       	ret

00001454 <xTaskCreate>:
							const char * const pcName,
							const uint16_t usStackDepth,
							void * const pvParameters,
							UBaseType_t uxPriority,
							TaskHandle_t * const pxCreatedTask ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
	{
    1454:	2f 92       	push	r2
    1456:	3f 92       	push	r3
    1458:	4f 92       	push	r4
    145a:	5f 92       	push	r5
    145c:	6f 92       	push	r6
    145e:	7f 92       	push	r7
    1460:	8f 92       	push	r8
    1462:	9f 92       	push	r9
    1464:	af 92       	push	r10
    1466:	bf 92       	push	r11
    1468:	df 92       	push	r13
    146a:	ef 92       	push	r14
    146c:	ff 92       	push	r15
    146e:	0f 93       	push	r16
    1470:	1f 93       	push	r17
    1472:	cf 93       	push	r28
    1474:	df 93       	push	r29
    1476:	3c 01       	movw	r6, r24
    1478:	5b 01       	movw	r10, r22
    147a:	ea 01       	movw	r28, r20
    147c:	29 01       	movw	r4, r18
    147e:	d0 2e       	mov	r13, r16
    1480:	47 01       	movw	r8, r14
		#else /* portSTACK_GROWTH */
		{
		StackType_t *pxStack;

			/* Allocate space for the stack used by the task being created. */
			pxStack = ( StackType_t * ) pvPortMalloc( ( ( ( size_t ) usStackDepth ) * sizeof( StackType_t ) ) ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    1482:	ca 01       	movw	r24, r20
    1484:	0e 94 f2 01 	call	0x3e4	; 0x3e4 <pvPortMalloc>
    1488:	7c 01       	movw	r14, r24

			if( pxStack != NULL )
    148a:	00 97       	sbiw	r24, 0x00	; 0
    148c:	09 f4       	brne	.+2      	; 0x1490 <xTaskCreate+0x3c>
    148e:	ed c0       	rjmp	.+474    	; 0x166a <xTaskCreate+0x216>
			{
				/* Allocate space for the TCB. */
				pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) ); /*lint !e961 MISRA exception as the casts are only redundant for some paths. */
    1490:	8a e2       	ldi	r24, 0x2A	; 42
    1492:	90 e0       	ldi	r25, 0x00	; 0
    1494:	0e 94 f2 01 	call	0x3e4	; 0x3e4 <pvPortMalloc>
    1498:	8c 01       	movw	r16, r24

				if( pxNewTCB != NULL )
    149a:	00 97       	sbiw	r24, 0x00	; 0
    149c:	81 f0       	breq	.+32     	; 0x14be <xTaskCreate+0x6a>
				{
					/* Store the stack location in the TCB. */
					pxNewTCB->pxStack = pxStack;
    149e:	fc 01       	movw	r30, r24
    14a0:	f0 8e       	std	Z+24, r15	; 0x18
    14a2:	e7 8a       	std	Z+23, r14	; 0x17
	grows from high memory to low (as per the 80x86) or vice versa.
	portSTACK_GROWTH is used to make the result positive or negative as required
	by the port. */
	#if( portSTACK_GROWTH < 0 )
	{
		pxTopOfStack = pxNewTCB->pxStack + ( ulStackDepth - ( uint32_t ) 1 );
    14a4:	21 97       	sbiw	r28, 0x01	; 1
    14a6:	17 01       	movw	r2, r14
    14a8:	2c 0e       	add	r2, r28
    14aa:	3d 1e       	adc	r3, r29
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
	{
		pxNewTCB->pcTaskName[ x ] = pcName[ x ];
    14ac:	f5 01       	movw	r30, r10
    14ae:	80 81       	ld	r24, Z
    14b0:	f8 01       	movw	r30, r16
    14b2:	81 8f       	std	Z+25, r24	; 0x19

		/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
		configMAX_TASK_NAME_LEN characters just in case the memory after the
		string is not accessible (extremely unlikely). */
		if( pcName[ x ] == 0x00 )
    14b4:	f5 01       	movw	r30, r10
    14b6:	80 81       	ld	r24, Z
    14b8:	88 23       	and	r24, r24
    14ba:	31 f4       	brne	.+12     	; 0x14c8 <xTaskCreate+0x74>
    14bc:	13 c0       	rjmp	.+38     	; 0x14e4 <xTaskCreate+0x90>
				}
				else
				{
					/* The stack cannot be used as the TCB was not created.  Free
					it again. */
					vPortFree( pxStack );
    14be:	c7 01       	movw	r24, r14
    14c0:	0e 94 92 02 	call	0x524	; 0x524 <vPortFree>
			prvAddNewTaskToReadyList( pxNewTCB );
			xReturn = pdPASS;
		}
		else
		{
			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
    14c4:	8f ef       	ldi	r24, 0xFF	; 255
    14c6:	d6 c0       	rjmp	.+428    	; 0x1674 <xTaskCreate+0x220>
#endif /* portUSING_MPU_WRAPPERS */
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	BaseType_t xTaskCreate(	TaskFunction_t pxTaskCode,
    14c8:	e8 01       	movw	r28, r16
    14ca:	6a 96       	adiw	r28, 0x1a	; 26
    14cc:	d5 01       	movw	r26, r10
    14ce:	11 96       	adiw	r26, 0x01	; 1
		pxNewTCB->pxEndOfStack = pxNewTCB->pxStack + ( ulStackDepth - ( uint32_t ) 1 );
	}
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
    14d0:	81 e0       	ldi	r24, 0x01	; 1
#endif /* portUSING_MPU_WRAPPERS */
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	BaseType_t xTaskCreate(	TaskFunction_t pxTaskCode,
    14d2:	fd 01       	movw	r30, r26
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
	{
		pxNewTCB->pcTaskName[ x ] = pcName[ x ];
    14d4:	9d 91       	ld	r25, X+
    14d6:	99 93       	st	Y+, r25

		/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
		configMAX_TASK_NAME_LEN characters just in case the memory after the
		string is not accessible (extremely unlikely). */
		if( pcName[ x ] == 0x00 )
    14d8:	90 81       	ld	r25, Z
    14da:	99 23       	and	r25, r25
    14dc:	19 f0       	breq	.+6      	; 0x14e4 <xTaskCreate+0x90>
		pxNewTCB->pxEndOfStack = pxNewTCB->pxStack + ( ulStackDepth - ( uint32_t ) 1 );
	}
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
    14de:	8f 5f       	subi	r24, 0xFF	; 255
    14e0:	8a 30       	cpi	r24, 0x0A	; 10
    14e2:	b9 f7       	brne	.-18     	; 0x14d2 <xTaskCreate+0x7e>
		}
	}

	/* Ensure the name string is terminated in the case that the string length
	was greater or equal to configMAX_TASK_NAME_LEN. */
	pxNewTCB->pcTaskName[ configMAX_TASK_NAME_LEN - 1 ] = '\0';
    14e4:	f8 01       	movw	r30, r16
    14e6:	12 a2       	lds	r17, 0x92
    14e8:	cd 2d       	mov	r28, r13
    14ea:	c5 30       	cpi	r28, 0x05	; 5
    14ec:	08 f0       	brcs	.+2      	; 0x14f0 <xTaskCreate+0x9c>
    14ee:	c4 e0       	ldi	r28, 0x04	; 4
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxNewTCB->uxPriority = uxPriority;
    14f0:	f8 01       	movw	r30, r16
    14f2:	c6 8b       	std	Z+22, r28	; 0x16
	#if ( configUSE_MUTEXES == 1 )
	{
		pxNewTCB->uxBasePriority = uxPriority;
    14f4:	c3 a3       	lds	r28, 0x53
		pxNewTCB->uxMutexesHeld = 0;
    14f6:	14 a2       	lds	r17, 0x94
	}
	#endif /* configUSE_MUTEXES */

	vListInitialiseItem( &( pxNewTCB->xStateListItem ) );
    14f8:	ee 24       	eor	r14, r14
    14fa:	ff 24       	eor	r15, r15
    14fc:	68 94       	set
    14fe:	e1 f8       	bld	r14, 1
    1500:	e0 0e       	add	r14, r16
    1502:	f1 1e       	adc	r15, r17
    1504:	c7 01       	movw	r24, r14
    1506:	0e 94 d9 02 	call	0x5b2	; 0x5b2 <vListInitialiseItem>
	vListInitialiseItem( &( pxNewTCB->xEventListItem ) );
    150a:	c8 01       	movw	r24, r16
    150c:	0c 96       	adiw	r24, 0x0c	; 12
    150e:	0e 94 d9 02 	call	0x5b2	; 0x5b2 <vListInitialiseItem>

	/* Set the pxNewTCB as a link back from the ListItem_t.  This is so we can get
	back to	the containing TCB from a generic item in a list. */
	listSET_LIST_ITEM_OWNER( &( pxNewTCB->xStateListItem ), pxNewTCB );
    1512:	f8 01       	movw	r30, r16
    1514:	11 87       	std	Z+9, r17	; 0x09
    1516:	00 87       	std	Z+8, r16	; 0x08

	/* Event lists are always in priority order. */
	listSET_LIST_ITEM_VALUE( &( pxNewTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxPriority ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    1518:	85 e0       	ldi	r24, 0x05	; 5
    151a:	90 e0       	ldi	r25, 0x00	; 0
    151c:	8c 1b       	sub	r24, r28
    151e:	91 09       	sbc	r25, r1
    1520:	95 87       	std	Z+13, r25	; 0x0d
    1522:	84 87       	std	Z+12, r24	; 0x0c
	listSET_LIST_ITEM_OWNER( &( pxNewTCB->xEventListItem ), pxNewTCB );
    1524:	13 8b       	std	Z+19, r17	; 0x13
    1526:	02 8b       	std	Z+18, r16	; 0x12
	}
	#endif

	#if ( configUSE_TASK_NOTIFICATIONS == 1 )
	{
		pxNewTCB->ulNotifiedValue = 0;
    1528:	15 a2       	lds	r17, 0x95
    152a:	16 a2       	lds	r17, 0x96
    152c:	17 a2       	lds	r17, 0x97
    152e:	10 a6       	lds	r17, 0xb0
		pxNewTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    1530:	11 a6       	lds	r17, 0xb1
	{
		pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters, xRunPrivileged );
	}
	#else /* portUSING_MPU_WRAPPERS */
	{
		pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters );
    1532:	c1 01       	movw	r24, r2
    1534:	b3 01       	movw	r22, r6
    1536:	a2 01       	movw	r20, r4
    1538:	0e 94 56 03 	call	0x6ac	; 0x6ac <pxPortInitialiseStack>
    153c:	f8 01       	movw	r30, r16
    153e:	91 83       	std	Z+1, r25	; 0x01
    1540:	80 83       	st	Z, r24
	}
	#endif /* portUSING_MPU_WRAPPERS */

	if( ( void * ) pxCreatedTask != NULL )
    1542:	81 14       	cp	r8, r1
    1544:	91 04       	cpc	r9, r1
    1546:	19 f0       	breq	.+6      	; 0x154e <xTaskCreate+0xfa>
	{
		/* Pass the handle out in an anonymous way.  The handle can be used to
		change the created task's priority, delete the created task, etc.*/
		*pxCreatedTask = ( TaskHandle_t ) pxNewTCB;
    1548:	f4 01       	movw	r30, r8
    154a:	11 83       	std	Z+1, r17	; 0x01
    154c:	00 83       	st	Z, r16

static void prvAddNewTaskToReadyList( TCB_t *pxNewTCB )
{
	/* Ensure interrupts don't access the task lists while the lists are being
	updated. */
	taskENTER_CRITICAL();
    154e:	0f b6       	in	r0, 0x3f	; 63
    1550:	f8 94       	cli
    1552:	0f 92       	push	r0
	{
		uxCurrentNumberOfTasks++;
    1554:	80 91 a3 03 	lds	r24, 0x03A3
    1558:	8f 5f       	subi	r24, 0xFF	; 255
    155a:	80 93 a3 03 	sts	0x03A3, r24
		if( pxCurrentTCB == NULL )
    155e:	80 91 97 03 	lds	r24, 0x0397
    1562:	90 91 98 03 	lds	r25, 0x0398
    1566:	00 97       	sbiw	r24, 0x00	; 0
    1568:	09 f0       	breq	.+2      	; 0x156c <xTaskCreate+0x118>
    156a:	3f c0       	rjmp	.+126    	; 0x15ea <xTaskCreate+0x196>
		{
			/* There are no other tasks, or all the other tasks are in
			the suspended state - make this the current task. */
			pxCurrentTCB = pxNewTCB;
    156c:	10 93 98 03 	sts	0x0398, r17
    1570:	00 93 97 03 	sts	0x0397, r16

			if( uxCurrentNumberOfTasks == ( UBaseType_t ) 1 )
    1574:	80 91 a3 03 	lds	r24, 0x03A3
    1578:	81 30       	cpi	r24, 0x01	; 1
    157a:	09 f0       	breq	.+2      	; 0x157e <xTaskCreate+0x12a>
    157c:	47 c0       	rjmp	.+142    	; 0x160c <xTaskCreate+0x1b8>
    157e:	c0 e0       	ldi	r28, 0x00	; 0
    1580:	d0 e0       	ldi	r29, 0x00	; 0
{
UBaseType_t uxPriority;

	for( uxPriority = ( UBaseType_t ) 0U; uxPriority < ( UBaseType_t ) configMAX_PRIORITIES; uxPriority++ )
	{
		vListInitialise( &( pxReadyTasksLists[ uxPriority ] ) );
    1582:	ce 01       	movw	r24, r28
    1584:	88 0f       	add	r24, r24
    1586:	99 1f       	adc	r25, r25
    1588:	88 0f       	add	r24, r24
    158a:	99 1f       	adc	r25, r25
    158c:	88 0f       	add	r24, r24
    158e:	99 1f       	adc	r25, r25
    1590:	8c 0f       	add	r24, r28
    1592:	9d 1f       	adc	r25, r29
    1594:	86 55       	subi	r24, 0x56	; 86
    1596:	9c 4f       	sbci	r25, 0xFC	; 252
    1598:	0e 94 cb 02 	call	0x596	; 0x596 <vListInitialise>
    159c:	21 96       	adiw	r28, 0x01	; 1

static void prvInitialiseTaskLists( void )
{
UBaseType_t uxPriority;

	for( uxPriority = ( UBaseType_t ) 0U; uxPriority < ( UBaseType_t ) configMAX_PRIORITIES; uxPriority++ )
    159e:	c5 30       	cpi	r28, 0x05	; 5
    15a0:	d1 05       	cpc	r29, r1
    15a2:	79 f7       	brne	.-34     	; 0x1582 <xTaskCreate+0x12e>
	{
		vListInitialise( &( pxReadyTasksLists[ uxPriority ] ) );
	}

	vListInitialise( &xDelayedTaskList1 );
    15a4:	c7 ed       	ldi	r28, 0xD7	; 215
    15a6:	d3 e0       	ldi	r29, 0x03	; 3
    15a8:	ce 01       	movw	r24, r28
    15aa:	0e 94 cb 02 	call	0x596	; 0x596 <vListInitialise>
	vListInitialise( &xDelayedTaskList2 );
    15ae:	0f 2e       	mov	r0, r31
    15b0:	f0 ee       	ldi	r31, 0xE0	; 224
    15b2:	af 2e       	mov	r10, r31
    15b4:	f3 e0       	ldi	r31, 0x03	; 3
    15b6:	bf 2e       	mov	r11, r31
    15b8:	f0 2d       	mov	r31, r0
    15ba:	c5 01       	movw	r24, r10
    15bc:	0e 94 cb 02 	call	0x596	; 0x596 <vListInitialise>
	vListInitialise( &xPendingReadyList );
    15c0:	89 ee       	ldi	r24, 0xE9	; 233
    15c2:	93 e0       	ldi	r25, 0x03	; 3
    15c4:	0e 94 cb 02 	call	0x596	; 0x596 <vListInitialise>

	#if ( INCLUDE_vTaskDelete == 1 )
	{
		vListInitialise( &xTasksWaitingTermination );
    15c8:	82 ef       	ldi	r24, 0xF2	; 242
    15ca:	93 e0       	ldi	r25, 0x03	; 3
    15cc:	0e 94 cb 02 	call	0x596	; 0x596 <vListInitialise>
	}
	#endif /* INCLUDE_vTaskDelete */

	#if ( INCLUDE_vTaskSuspend == 1 )
	{
		vListInitialise( &xSuspendedTaskList );
    15d0:	8b ef       	ldi	r24, 0xFB	; 251
    15d2:	93 e0       	ldi	r25, 0x03	; 3
    15d4:	0e 94 cb 02 	call	0x596	; 0x596 <vListInitialise>
	}
	#endif /* INCLUDE_vTaskSuspend */

	/* Start with pxDelayedTaskList using list1 and the pxOverflowDelayedTaskList
	using list2. */
	pxDelayedTaskList = &xDelayedTaskList1;
    15d8:	d0 93 a8 03 	sts	0x03A8, r29
    15dc:	c0 93 a7 03 	sts	0x03A7, r28
	pxOverflowDelayedTaskList = &xDelayedTaskList2;
    15e0:	b0 92 a6 03 	sts	0x03A6, r11
    15e4:	a0 92 a5 03 	sts	0x03A5, r10
    15e8:	11 c0       	rjmp	.+34     	; 0x160c <xTaskCreate+0x1b8>
		else
		{
			/* If the scheduler is not already running, make this task the
			current task if it is the highest priority task to be created
			so far. */
			if( xSchedulerRunning == pdFALSE )
    15ea:	80 91 9f 03 	lds	r24, 0x039F
    15ee:	88 23       	and	r24, r24
    15f0:	69 f4       	brne	.+26     	; 0x160c <xTaskCreate+0x1b8>
			{
				if( pxCurrentTCB->uxPriority <= pxNewTCB->uxPriority )
    15f2:	e0 91 97 03 	lds	r30, 0x0397
    15f6:	f0 91 98 03 	lds	r31, 0x0398
    15fa:	96 89       	ldd	r25, Z+22	; 0x16
    15fc:	f8 01       	movw	r30, r16
    15fe:	86 89       	ldd	r24, Z+22	; 0x16
    1600:	89 17       	cp	r24, r25
    1602:	20 f0       	brcs	.+8      	; 0x160c <xTaskCreate+0x1b8>
				{
					pxCurrentTCB = pxNewTCB;
    1604:	10 93 98 03 	sts	0x0398, r17
    1608:	00 93 97 03 	sts	0x0397, r16
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}

		uxTaskNumber++;
    160c:	80 91 a9 03 	lds	r24, 0x03A9
    1610:	8f 5f       	subi	r24, 0xFF	; 255
    1612:	80 93 a9 03 	sts	0x03A9, r24
			pxNewTCB->uxTCBNumber = uxTaskNumber;
		}
		#endif /* configUSE_TRACE_FACILITY */
		traceTASK_CREATE( pxNewTCB );

		prvAddTaskToReadyList( pxNewTCB );
    1616:	f8 01       	movw	r30, r16
    1618:	86 89       	ldd	r24, Z+22	; 0x16
    161a:	90 91 a0 03 	lds	r25, 0x03A0
    161e:	98 17       	cp	r25, r24
    1620:	10 f4       	brcc	.+4      	; 0x1626 <xTaskCreate+0x1d2>
    1622:	80 93 a0 03 	sts	0x03A0, r24
    1626:	90 e0       	ldi	r25, 0x00	; 0
    1628:	9c 01       	movw	r18, r24
    162a:	22 0f       	add	r18, r18
    162c:	33 1f       	adc	r19, r19
    162e:	22 0f       	add	r18, r18
    1630:	33 1f       	adc	r19, r19
    1632:	22 0f       	add	r18, r18
    1634:	33 1f       	adc	r19, r19
    1636:	82 0f       	add	r24, r18
    1638:	93 1f       	adc	r25, r19
    163a:	86 55       	subi	r24, 0x56	; 86
    163c:	9c 4f       	sbci	r25, 0xFC	; 252
    163e:	b7 01       	movw	r22, r14
    1640:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>

		portSETUP_TCB( pxNewTCB );
	}
	taskEXIT_CRITICAL();
    1644:	0f 90       	pop	r0
    1646:	0f be       	out	0x3f, r0	; 63

	if( xSchedulerRunning != pdFALSE )
    1648:	80 91 9f 03 	lds	r24, 0x039F
    164c:	88 23       	and	r24, r24
    164e:	79 f0       	breq	.+30     	; 0x166e <xTaskCreate+0x21a>
	{
		/* If the created task is of a higher priority than the current task
		then it should run now. */
		if( pxCurrentTCB->uxPriority < pxNewTCB->uxPriority )
    1650:	e0 91 97 03 	lds	r30, 0x0397
    1654:	f0 91 98 03 	lds	r31, 0x0398
    1658:	96 89       	ldd	r25, Z+22	; 0x16
    165a:	f8 01       	movw	r30, r16
    165c:	86 89       	ldd	r24, Z+22	; 0x16
    165e:	98 17       	cp	r25, r24
    1660:	40 f4       	brcc	.+16     	; 0x1672 <xTaskCreate+0x21e>
		{
			taskYIELD_IF_USING_PREEMPTION();
    1662:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
			}
			#endif /* configSUPPORT_STATIC_ALLOCATION */

			prvInitialiseNewTask( pxTaskCode, pcName, ( uint32_t ) usStackDepth, pvParameters, uxPriority, pxCreatedTask, pxNewTCB, NULL );
			prvAddNewTaskToReadyList( pxNewTCB );
			xReturn = pdPASS;
    1666:	81 e0       	ldi	r24, 0x01	; 1
    1668:	05 c0       	rjmp	.+10     	; 0x1674 <xTaskCreate+0x220>
		}
		else
		{
			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
    166a:	8f ef       	ldi	r24, 0xFF	; 255
    166c:	03 c0       	rjmp	.+6      	; 0x1674 <xTaskCreate+0x220>
			}
			#endif /* configSUPPORT_STATIC_ALLOCATION */

			prvInitialiseNewTask( pxTaskCode, pcName, ( uint32_t ) usStackDepth, pvParameters, uxPriority, pxCreatedTask, pxNewTCB, NULL );
			prvAddNewTaskToReadyList( pxNewTCB );
			xReturn = pdPASS;
    166e:	81 e0       	ldi	r24, 0x01	; 1
    1670:	01 c0       	rjmp	.+2      	; 0x1674 <xTaskCreate+0x220>
    1672:	81 e0       	ldi	r24, 0x01	; 1
		{
			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
		}

		return xReturn;
	}
    1674:	df 91       	pop	r29
    1676:	cf 91       	pop	r28
    1678:	1f 91       	pop	r17
    167a:	0f 91       	pop	r16
    167c:	ff 90       	pop	r15
    167e:	ef 90       	pop	r14
    1680:	df 90       	pop	r13
    1682:	bf 90       	pop	r11
    1684:	af 90       	pop	r10
    1686:	9f 90       	pop	r9
    1688:	8f 90       	pop	r8
    168a:	7f 90       	pop	r7
    168c:	6f 90       	pop	r6
    168e:	5f 90       	pop	r5
    1690:	4f 90       	pop	r4
    1692:	3f 90       	pop	r3
    1694:	2f 90       	pop	r2
    1696:	08 95       	ret

00001698 <vTaskDelete>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelete == 1 )

	void vTaskDelete( TaskHandle_t xTaskToDelete )
	{
    1698:	0f 93       	push	r16
    169a:	1f 93       	push	r17
    169c:	cf 93       	push	r28
    169e:	df 93       	push	r29
	TCB_t *pxTCB;

		taskENTER_CRITICAL();
    16a0:	0f b6       	in	r0, 0x3f	; 63
    16a2:	f8 94       	cli
    16a4:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the calling task that is
			being deleted. */
			pxTCB = prvGetTCBFromHandle( xTaskToDelete );
    16a6:	00 97       	sbiw	r24, 0x00	; 0
    16a8:	29 f4       	brne	.+10     	; 0x16b4 <vTaskDelete+0x1c>
    16aa:	c0 91 97 03 	lds	r28, 0x0397
    16ae:	d0 91 98 03 	lds	r29, 0x0398
    16b2:	01 c0       	rjmp	.+2      	; 0x16b6 <vTaskDelete+0x1e>
    16b4:	ec 01       	movw	r28, r24

			/* Remove task from the ready list. */
			if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    16b6:	8e 01       	movw	r16, r28
    16b8:	0e 5f       	subi	r16, 0xFE	; 254
    16ba:	1f 4f       	sbci	r17, 0xFF	; 255
    16bc:	c8 01       	movw	r24, r16
    16be:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
			{
				mtCOVERAGE_TEST_MARKER();
			}

			/* Is the task waiting on an event also? */
			if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
    16c2:	8c 89       	ldd	r24, Y+20	; 0x14
    16c4:	9d 89       	ldd	r25, Y+21	; 0x15
    16c6:	00 97       	sbiw	r24, 0x00	; 0
    16c8:	21 f0       	breq	.+8      	; 0x16d2 <vTaskDelete+0x3a>
			{
				( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    16ca:	ce 01       	movw	r24, r28
    16cc:	0c 96       	adiw	r24, 0x0c	; 12
    16ce:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>

			/* Increment the uxTaskNumber also so kernel aware debuggers can
			detect that the task lists need re-generating.  This is done before
			portPRE_TASK_DELETE_HOOK() as in the Windows port that macro will
			not return. */
			uxTaskNumber++;
    16d2:	80 91 a9 03 	lds	r24, 0x03A9
    16d6:	8f 5f       	subi	r24, 0xFF	; 255
    16d8:	80 93 a9 03 	sts	0x03A9, r24

			if( pxTCB == pxCurrentTCB )
    16dc:	80 91 97 03 	lds	r24, 0x0397
    16e0:	90 91 98 03 	lds	r25, 0x0398
    16e4:	c8 17       	cp	r28, r24
    16e6:	d9 07       	cpc	r29, r25
    16e8:	59 f4       	brne	.+22     	; 0x1700 <vTaskDelete+0x68>
				/* A task is deleting itself.  This cannot complete within the
				task itself, as a context switch to another task is required.
				Place the task in the termination list.  The idle task will
				check the termination list and free up any memory allocated by
				the scheduler for the TCB and stack of the deleted task. */
				vListInsertEnd( &xTasksWaitingTermination, &( pxTCB->xStateListItem ) );
    16ea:	82 ef       	ldi	r24, 0xF2	; 242
    16ec:	93 e0       	ldi	r25, 0x03	; 3
    16ee:	b8 01       	movw	r22, r16
    16f0:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>

				/* Increment the ucTasksDeleted variable so the idle task knows
				there is a task that has been deleted and that it should therefore
				check the xTasksWaitingTermination list. */
				++uxDeletedTasksWaitingCleanUp;
    16f4:	80 91 a4 03 	lds	r24, 0x03A4
    16f8:	8f 5f       	subi	r24, 0xFF	; 255
    16fa:	80 93 a4 03 	sts	0x03A4, r24
    16fe:	0a c0       	rjmp	.+20     	; 0x1714 <vTaskDelete+0x7c>
				required. */
				portPRE_TASK_DELETE_HOOK( pxTCB, &xYieldPending );
			}
			else
			{
				--uxCurrentNumberOfTasks;
    1700:	80 91 a3 03 	lds	r24, 0x03A3
    1704:	81 50       	subi	r24, 0x01	; 1
    1706:	80 93 a3 03 	sts	0x03A3, r24
				prvDeleteTCB( pxTCB );
    170a:	ce 01       	movw	r24, r28
    170c:	0e 94 1d 0a 	call	0x143a	; 0x143a <prvDeleteTCB>

				/* Reset the next expected unblock time in case it referred to
				the task that has just been deleted. */
				prvResetNextTaskUnblockTime();
    1710:	0e 94 a6 09 	call	0x134c	; 0x134c <prvResetNextTaskUnblockTime>
			}

			traceTASK_DELETE( pxTCB );
		}
		taskEXIT_CRITICAL();
    1714:	0f 90       	pop	r0
    1716:	0f be       	out	0x3f, r0	; 63

		/* Force a reschedule if it is the currently running task that has just
		been deleted. */
		if( xSchedulerRunning != pdFALSE )
    1718:	80 91 9f 03 	lds	r24, 0x039F
    171c:	88 23       	and	r24, r24
    171e:	49 f0       	breq	.+18     	; 0x1732 <vTaskDelete+0x9a>
		{
			if( pxTCB == pxCurrentTCB )
    1720:	80 91 97 03 	lds	r24, 0x0397
    1724:	90 91 98 03 	lds	r25, 0x0398
    1728:	c8 17       	cp	r28, r24
    172a:	d9 07       	cpc	r29, r25
    172c:	11 f4       	brne	.+4      	; 0x1732 <vTaskDelete+0x9a>
			{
				configASSERT( uxSchedulerSuspended == 0 );
				portYIELD_WITHIN_API();
    172e:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	}
    1732:	df 91       	pop	r29
    1734:	cf 91       	pop	r28
    1736:	1f 91       	pop	r17
    1738:	0f 91       	pop	r16
    173a:	08 95       	ret

0000173c <uxTaskPriorityGet>:
	UBaseType_t uxTaskPriorityGet( TaskHandle_t xTask )
	{
	TCB_t *pxTCB;
	UBaseType_t uxReturn;

		taskENTER_CRITICAL();
    173c:	0f b6       	in	r0, 0x3f	; 63
    173e:	f8 94       	cli
    1740:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the priority of the that
			called uxTaskPriorityGet() that is being queried. */
			pxTCB = prvGetTCBFromHandle( xTask );
    1742:	00 97       	sbiw	r24, 0x00	; 0
    1744:	29 f4       	brne	.+10     	; 0x1750 <uxTaskPriorityGet+0x14>
    1746:	e0 91 97 03 	lds	r30, 0x0397
    174a:	f0 91 98 03 	lds	r31, 0x0398
    174e:	01 c0       	rjmp	.+2      	; 0x1752 <uxTaskPriorityGet+0x16>
    1750:	fc 01       	movw	r30, r24
			uxReturn = pxTCB->uxPriority;
		}
		taskEXIT_CRITICAL();
    1752:	0f 90       	pop	r0
    1754:	0f be       	out	0x3f, r0	; 63

		return uxReturn;
	}
    1756:	86 89       	ldd	r24, Z+22	; 0x16
    1758:	08 95       	ret

0000175a <uxTaskPriorityGetFromISR>:

		uxSavedInterruptState = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			/* If null is passed in here then it is the priority of the calling
			task that is being queried. */
			pxTCB = prvGetTCBFromHandle( xTask );
    175a:	00 97       	sbiw	r24, 0x00	; 0
    175c:	29 f4       	brne	.+10     	; 0x1768 <uxTaskPriorityGetFromISR+0xe>
    175e:	e0 91 97 03 	lds	r30, 0x0397
    1762:	f0 91 98 03 	lds	r31, 0x0398
    1766:	01 c0       	rjmp	.+2      	; 0x176a <uxTaskPriorityGetFromISR+0x10>
    1768:	fc 01       	movw	r30, r24
			uxReturn = pxTCB->uxPriority;
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptState );

		return uxReturn;
	}
    176a:	86 89       	ldd	r24, Z+22	; 0x16
    176c:	08 95       	ret

0000176e <vTaskPrioritySet>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskPrioritySet == 1 )

	void vTaskPrioritySet( TaskHandle_t xTask, UBaseType_t uxNewPriority )
	{
    176e:	ef 92       	push	r14
    1770:	ff 92       	push	r15
    1772:	1f 93       	push	r17
    1774:	cf 93       	push	r28
    1776:	df 93       	push	r29
	TCB_t *pxTCB;
	UBaseType_t uxCurrentBasePriority, uxPriorityUsedOnEntry;
	BaseType_t xYieldRequired = pdFALSE;
    1778:	65 30       	cpi	r22, 0x05	; 5
    177a:	08 f0       	brcs	.+2      	; 0x177e <vTaskPrioritySet+0x10>
    177c:	64 e0       	ldi	r22, 0x04	; 4
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		taskENTER_CRITICAL();
    177e:	0f b6       	in	r0, 0x3f	; 63
    1780:	f8 94       	cli
    1782:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the priority of the calling
			task that is being changed. */
			pxTCB = prvGetTCBFromHandle( xTask );
    1784:	00 97       	sbiw	r24, 0x00	; 0
    1786:	29 f4       	brne	.+10     	; 0x1792 <vTaskPrioritySet+0x24>
    1788:	c0 91 97 03 	lds	r28, 0x0397
    178c:	d0 91 98 03 	lds	r29, 0x0398
    1790:	01 c0       	rjmp	.+2      	; 0x1794 <vTaskPrioritySet+0x26>
    1792:	ec 01       	movw	r28, r24

			traceTASK_PRIORITY_SET( pxTCB, uxNewPriority );

			#if ( configUSE_MUTEXES == 1 )
			{
				uxCurrentBasePriority = pxTCB->uxBasePriority;
    1794:	2b a1       	lds	r18, 0x4b
			{
				uxCurrentBasePriority = pxTCB->uxPriority;
			}
			#endif

			if( uxCurrentBasePriority != uxNewPriority )
    1796:	26 17       	cp	r18, r22
    1798:	09 f4       	brne	.+2      	; 0x179c <vTaskPrioritySet+0x2e>
    179a:	61 c0       	rjmp	.+194    	; 0x185e <vTaskPrioritySet+0xf0>
			{
				/* The priority change may have readied a task of higher
				priority than the calling task. */
				if( uxNewPriority > uxCurrentBasePriority )
    179c:	26 17       	cp	r18, r22
    179e:	88 f4       	brcc	.+34     	; 0x17c2 <vTaskPrioritySet+0x54>
				{
					if( pxTCB != pxCurrentTCB )
    17a0:	80 91 97 03 	lds	r24, 0x0397
    17a4:	90 91 98 03 	lds	r25, 0x0398
    17a8:	c8 17       	cp	r28, r24
    17aa:	d9 07       	cpc	r29, r25
    17ac:	a1 f0       	breq	.+40     	; 0x17d6 <vTaskPrioritySet+0x68>
					{
						/* The priority of a task other than the currently
						running task is being raised.  Is the priority being
						raised above that of the running task? */
						if( uxNewPriority >= pxCurrentTCB->uxPriority )
    17ae:	e0 91 97 03 	lds	r30, 0x0397
    17b2:	f0 91 98 03 	lds	r31, 0x0398
						{
							xYieldRequired = pdTRUE;
    17b6:	11 e0       	ldi	r17, 0x01	; 1
    17b8:	86 89       	ldd	r24, Z+22	; 0x16
    17ba:	68 17       	cp	r22, r24
    17bc:	68 f4       	brcc	.+26     	; 0x17d8 <vTaskPrioritySet+0x6a>
    17be:	10 e0       	ldi	r17, 0x00	; 0
    17c0:	0b c0       	rjmp	.+22     	; 0x17d8 <vTaskPrioritySet+0x6a>
						/* The priority of the running task is being raised,
						but the running task must already be the highest
						priority task able to run so no yield is required. */
					}
				}
				else if( pxTCB == pxCurrentTCB )
    17c2:	80 91 97 03 	lds	r24, 0x0397
    17c6:	90 91 98 03 	lds	r25, 0x0398
						/* The priority of a task other than the currently
						running task is being raised.  Is the priority being
						raised above that of the running task? */
						if( uxNewPriority >= pxCurrentTCB->uxPriority )
						{
							xYieldRequired = pdTRUE;
    17ca:	11 e0       	ldi	r17, 0x01	; 1
    17cc:	c8 17       	cp	r28, r24
    17ce:	d9 07       	cpc	r29, r25
    17d0:	19 f0       	breq	.+6      	; 0x17d8 <vTaskPrioritySet+0x6a>
    17d2:	10 e0       	ldi	r17, 0x00	; 0
    17d4:	01 c0       	rjmp	.+2      	; 0x17d8 <vTaskPrioritySet+0x6a>

	void vTaskPrioritySet( TaskHandle_t xTask, UBaseType_t uxNewPriority )
	{
	TCB_t *pxTCB;
	UBaseType_t uxCurrentBasePriority, uxPriorityUsedOnEntry;
	BaseType_t xYieldRequired = pdFALSE;
    17d6:	10 e0       	ldi	r17, 0x00	; 0
				}

				/* Remember the ready list the task might be referenced from
				before its uxPriority member is changed so the
				taskRESET_READY_PRIORITY() macro can function correctly. */
				uxPriorityUsedOnEntry = pxTCB->uxPriority;
    17d8:	8e 89       	ldd	r24, Y+22	; 0x16

				#if ( configUSE_MUTEXES == 1 )
				{
					/* Only change the priority being used if the task is not
					currently using an inherited priority. */
					if( pxTCB->uxBasePriority == pxTCB->uxPriority )
    17da:	28 17       	cp	r18, r24
    17dc:	09 f4       	brne	.+2      	; 0x17e0 <vTaskPrioritySet+0x72>
					{
						pxTCB->uxPriority = uxNewPriority;
    17de:	6e 8b       	std	Y+22, r22	; 0x16
					{
						mtCOVERAGE_TEST_MARKER();
					}

					/* The base priority gets set whatever. */
					pxTCB->uxBasePriority = uxNewPriority;
    17e0:	6b a3       	lds	r22, 0x5b
				}
				#endif

				/* Only reset the event list item value if the value is not
				being used for anything else. */
				if( ( listGET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ) ) & taskEVENT_LIST_ITEM_VALUE_IN_USE ) == 0UL )
    17e2:	2c 85       	ldd	r18, Y+12	; 0x0c
    17e4:	3d 85       	ldd	r19, Y+13	; 0x0d
    17e6:	33 23       	and	r19, r19
    17e8:	34 f0       	brlt	.+12     	; 0x17f6 <vTaskPrioritySet+0x88>
				{
					listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxNewPriority ) ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    17ea:	25 e0       	ldi	r18, 0x05	; 5
    17ec:	30 e0       	ldi	r19, 0x00	; 0
    17ee:	26 1b       	sub	r18, r22
    17f0:	31 09       	sbc	r19, r1
    17f2:	3d 87       	std	Y+13, r19	; 0x0d
    17f4:	2c 87       	std	Y+12, r18	; 0x0c

				/* If the task is in the blocked or suspended list we need do
				nothing more than change it's priority variable. However, if
				the task is in a ready list it needs to be removed and placed
				in the list appropriate to its new priority. */
				if( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ uxPriorityUsedOnEntry ] ), &( pxTCB->xStateListItem ) ) != pdFALSE )
    17f6:	90 e0       	ldi	r25, 0x00	; 0
    17f8:	9c 01       	movw	r18, r24
    17fa:	22 0f       	add	r18, r18
    17fc:	33 1f       	adc	r19, r19
    17fe:	22 0f       	add	r18, r18
    1800:	33 1f       	adc	r19, r19
    1802:	22 0f       	add	r18, r18
    1804:	33 1f       	adc	r19, r19
    1806:	82 0f       	add	r24, r18
    1808:	93 1f       	adc	r25, r19
    180a:	86 55       	subi	r24, 0x56	; 86
    180c:	9c 4f       	sbci	r25, 0xFC	; 252
    180e:	2a 85       	ldd	r18, Y+10	; 0x0a
    1810:	3b 85       	ldd	r19, Y+11	; 0x0b
    1812:	28 17       	cp	r18, r24
    1814:	39 07       	cpc	r19, r25
    1816:	f9 f4       	brne	.+62     	; 0x1856 <vTaskPrioritySet+0xe8>
				{
					/* The task is currently in its ready list - remove before adding
					it to it's new ready list.  As we are in a critical section we
					can do this even if the scheduler is suspended. */
					if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    1818:	ee 24       	eor	r14, r14
    181a:	ff 24       	eor	r15, r15
    181c:	68 94       	set
    181e:	e1 f8       	bld	r14, 1
    1820:	ec 0e       	add	r14, r28
    1822:	fd 1e       	adc	r15, r29
    1824:	c7 01       	movw	r24, r14
    1826:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
					}
					else
					{
						mtCOVERAGE_TEST_MARKER();
					}
					prvAddTaskToReadyList( pxTCB );
    182a:	8e 89       	ldd	r24, Y+22	; 0x16
    182c:	90 91 a0 03 	lds	r25, 0x03A0
    1830:	98 17       	cp	r25, r24
    1832:	10 f4       	brcc	.+4      	; 0x1838 <vTaskPrioritySet+0xca>
    1834:	80 93 a0 03 	sts	0x03A0, r24
    1838:	90 e0       	ldi	r25, 0x00	; 0
    183a:	9c 01       	movw	r18, r24
    183c:	22 0f       	add	r18, r18
    183e:	33 1f       	adc	r19, r19
    1840:	22 0f       	add	r18, r18
    1842:	33 1f       	adc	r19, r19
    1844:	22 0f       	add	r18, r18
    1846:	33 1f       	adc	r19, r19
    1848:	82 0f       	add	r24, r18
    184a:	93 1f       	adc	r25, r19
    184c:	86 55       	subi	r24, 0x56	; 86
    184e:	9c 4f       	sbci	r25, 0xFC	; 252
    1850:	b7 01       	movw	r22, r14
    1852:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				if( xYieldRequired != pdFALSE )
    1856:	11 23       	and	r17, r17
    1858:	11 f0       	breq	.+4      	; 0x185e <vTaskPrioritySet+0xf0>
				{
					taskYIELD_IF_USING_PREEMPTION();
    185a:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
				/* Remove compiler warning about unused variables when the port
				optimised task selection is not being used. */
				( void ) uxPriorityUsedOnEntry;
			}
		}
		taskEXIT_CRITICAL();
    185e:	0f 90       	pop	r0
    1860:	0f be       	out	0x3f, r0	; 63
	}
    1862:	df 91       	pop	r29
    1864:	cf 91       	pop	r28
    1866:	1f 91       	pop	r17
    1868:	ff 90       	pop	r15
    186a:	ef 90       	pop	r14
    186c:	08 95       	ret

0000186e <vTaskResume>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskSuspend == 1 )

	void vTaskResume( TaskHandle_t xTaskToResume )
	{
    186e:	0f 93       	push	r16
    1870:	1f 93       	push	r17
    1872:	cf 93       	push	r28
    1874:	df 93       	push	r29
    1876:	ec 01       	movw	r28, r24
		/* It does not make sense to resume the calling task. */
		configASSERT( xTaskToResume );

		/* The parameter cannot be NULL as it is impossible to resume the
		currently executing task. */
		if( ( pxTCB != NULL ) && ( pxTCB != pxCurrentTCB ) )
    1878:	00 97       	sbiw	r24, 0x00	; 0
    187a:	b9 f1       	breq	.+110    	; 0x18ea <vTaskResume+0x7c>
    187c:	80 91 97 03 	lds	r24, 0x0397
    1880:	90 91 98 03 	lds	r25, 0x0398
    1884:	c8 17       	cp	r28, r24
    1886:	d9 07       	cpc	r29, r25
    1888:	81 f1       	breq	.+96     	; 0x18ea <vTaskResume+0x7c>
		{
			taskENTER_CRITICAL();
    188a:	0f b6       	in	r0, 0x3f	; 63
    188c:	f8 94       	cli
    188e:	0f 92       	push	r0
			{
				if( prvTaskIsTaskSuspended( pxTCB ) != pdFALSE )
    1890:	ce 01       	movw	r24, r28
    1892:	0e 94 8f 09 	call	0x131e	; 0x131e <prvTaskIsTaskSuspended>
    1896:	88 23       	and	r24, r24
    1898:	31 f1       	breq	.+76     	; 0x18e6 <vTaskResume+0x78>
				{
					traceTASK_RESUME( pxTCB );

					/* As we are in a critical section we can access the ready
					lists even if the scheduler is suspended. */
					( void ) uxListRemove(  &( pxTCB->xStateListItem ) );
    189a:	8e 01       	movw	r16, r28
    189c:	0e 5f       	subi	r16, 0xFE	; 254
    189e:	1f 4f       	sbci	r17, 0xFF	; 255
    18a0:	c8 01       	movw	r24, r16
    18a2:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    18a6:	8e 89       	ldd	r24, Y+22	; 0x16
    18a8:	90 91 a0 03 	lds	r25, 0x03A0
    18ac:	98 17       	cp	r25, r24
    18ae:	10 f4       	brcc	.+4      	; 0x18b4 <vTaskResume+0x46>
    18b0:	80 93 a0 03 	sts	0x03A0, r24
    18b4:	90 e0       	ldi	r25, 0x00	; 0
    18b6:	9c 01       	movw	r18, r24
    18b8:	22 0f       	add	r18, r18
    18ba:	33 1f       	adc	r19, r19
    18bc:	22 0f       	add	r18, r18
    18be:	33 1f       	adc	r19, r19
    18c0:	22 0f       	add	r18, r18
    18c2:	33 1f       	adc	r19, r19
    18c4:	82 0f       	add	r24, r18
    18c6:	93 1f       	adc	r25, r19
    18c8:	86 55       	subi	r24, 0x56	; 86
    18ca:	9c 4f       	sbci	r25, 0xFC	; 252
    18cc:	b8 01       	movw	r22, r16
    18ce:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>

					/* We may have just resumed a higher priority task. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    18d2:	e0 91 97 03 	lds	r30, 0x0397
    18d6:	f0 91 98 03 	lds	r31, 0x0398
    18da:	9e 89       	ldd	r25, Y+22	; 0x16
    18dc:	86 89       	ldd	r24, Z+22	; 0x16
    18de:	98 17       	cp	r25, r24
    18e0:	10 f0       	brcs	.+4      	; 0x18e6 <vTaskResume+0x78>
					{
						/* This yield may not cause the task just resumed to run,
						but will leave the lists in the correct state for the
						next yield. */
						taskYIELD_IF_USING_PREEMPTION();
    18e2:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			taskEXIT_CRITICAL();
    18e6:	0f 90       	pop	r0
    18e8:	0f be       	out	0x3f, r0	; 63
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    18ea:	df 91       	pop	r29
    18ec:	cf 91       	pop	r28
    18ee:	1f 91       	pop	r17
    18f0:	0f 91       	pop	r16
    18f2:	08 95       	ret

000018f4 <xTaskResumeFromISR>:
/*-----------------------------------------------------------*/

#if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )

	BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )
	{
    18f4:	ef 92       	push	r14
    18f6:	ff 92       	push	r15
    18f8:	1f 93       	push	r17
    18fa:	cf 93       	push	r28
    18fc:	df 93       	push	r29
    18fe:	ec 01       	movw	r28, r24
		http://www.freertos.org/RTOS-Cortex-M3-M4.html */
		portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			if( prvTaskIsTaskSuspended( pxTCB ) != pdFALSE )
    1900:	0e 94 8f 09 	call	0x131e	; 0x131e <prvTaskIsTaskSuspended>
    1904:	88 23       	and	r24, r24
    1906:	b9 f1       	breq	.+110    	; 0x1976 <xTaskResumeFromISR+0x82>
			{
				traceTASK_RESUME_FROM_ISR( pxTCB );

				/* Check the ready lists can be accessed. */
				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1908:	80 91 99 03 	lds	r24, 0x0399
    190c:	88 23       	and	r24, r24
    190e:	51 f5       	brne	.+84     	; 0x1964 <xTaskResumeFromISR+0x70>
				{
					/* Ready lists can be accessed so move the task from the
					suspended list to the ready list directly. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    1910:	e0 91 97 03 	lds	r30, 0x0397
    1914:	f0 91 98 03 	lds	r31, 0x0398

#if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )

	BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )
	{
	BaseType_t xYieldRequired = pdFALSE;
    1918:	11 e0       	ldi	r17, 0x01	; 1
    191a:	9e 89       	ldd	r25, Y+22	; 0x16
    191c:	86 89       	ldd	r24, Z+22	; 0x16
    191e:	98 17       	cp	r25, r24
    1920:	08 f4       	brcc	.+2      	; 0x1924 <xTaskResumeFromISR+0x30>
    1922:	10 e0       	ldi	r17, 0x00	; 0
					else
					{
						mtCOVERAGE_TEST_MARKER();
					}

					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1924:	ee 24       	eor	r14, r14
    1926:	ff 24       	eor	r15, r15
    1928:	68 94       	set
    192a:	e1 f8       	bld	r14, 1
    192c:	ec 0e       	add	r14, r28
    192e:	fd 1e       	adc	r15, r29
    1930:	c7 01       	movw	r24, r14
    1932:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    1936:	8e 89       	ldd	r24, Y+22	; 0x16
    1938:	90 91 a0 03 	lds	r25, 0x03A0
    193c:	98 17       	cp	r25, r24
    193e:	10 f4       	brcc	.+4      	; 0x1944 <xTaskResumeFromISR+0x50>
    1940:	80 93 a0 03 	sts	0x03A0, r24
    1944:	90 e0       	ldi	r25, 0x00	; 0
    1946:	9c 01       	movw	r18, r24
    1948:	22 0f       	add	r18, r18
    194a:	33 1f       	adc	r19, r19
    194c:	22 0f       	add	r18, r18
    194e:	33 1f       	adc	r19, r19
    1950:	22 0f       	add	r18, r18
    1952:	33 1f       	adc	r19, r19
    1954:	82 0f       	add	r24, r18
    1956:	93 1f       	adc	r25, r19
    1958:	86 55       	subi	r24, 0x56	; 86
    195a:	9c 4f       	sbci	r25, 0xFC	; 252
    195c:	b7 01       	movw	r22, r14
    195e:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
    1962:	0a c0       	rjmp	.+20     	; 0x1978 <xTaskResumeFromISR+0x84>
				else
				{
					/* The delayed or ready lists cannot be accessed so the task
					is held in the pending ready list until the scheduler is
					unsuspended. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    1964:	be 01       	movw	r22, r28
    1966:	64 5f       	subi	r22, 0xF4	; 244
    1968:	7f 4f       	sbci	r23, 0xFF	; 255
    196a:	89 ee       	ldi	r24, 0xE9	; 233
    196c:	93 e0       	ldi	r25, 0x03	; 3
    196e:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>

#if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )

	BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )
	{
	BaseType_t xYieldRequired = pdFALSE;
    1972:	10 e0       	ldi	r17, 0x00	; 0
    1974:	01 c0       	rjmp	.+2      	; 0x1978 <xTaskResumeFromISR+0x84>
    1976:	10 e0       	ldi	r17, 0x00	; 0
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

		return xYieldRequired;
	}
    1978:	81 2f       	mov	r24, r17
    197a:	df 91       	pop	r29
    197c:	cf 91       	pop	r28
    197e:	1f 91       	pop	r17
    1980:	ff 90       	pop	r15
    1982:	ef 90       	pop	r14
    1984:	08 95       	ret

00001986 <vTaskStartScheduler>:

#endif /* ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) ) */
/*-----------------------------------------------------------*/

void vTaskStartScheduler( void )
{
    1986:	ef 92       	push	r14
    1988:	ff 92       	push	r15
    198a:	0f 93       	push	r16
		}
	}
	#else
	{
		/* The Idle task is being created using dynamically allocated RAM. */
		xReturn = xTaskCreate(	prvIdleTask,
    198c:	81 e5       	ldi	r24, 0x51	; 81
    198e:	9e e0       	ldi	r25, 0x0E	; 14
    1990:	64 e6       	ldi	r22, 0x64	; 100
    1992:	70 e0       	ldi	r23, 0x00	; 0
    1994:	48 ec       	ldi	r20, 0xC8	; 200
    1996:	50 e0       	ldi	r21, 0x00	; 0
    1998:	20 e0       	ldi	r18, 0x00	; 0
    199a:	30 e0       	ldi	r19, 0x00	; 0
    199c:	00 e0       	ldi	r16, 0x00	; 0
    199e:	0f 2e       	mov	r0, r31
    19a0:	f4 e0       	ldi	r31, 0x04	; 4
    19a2:	ef 2e       	mov	r14, r31
    19a4:	f4 e0       	ldi	r31, 0x04	; 4
    19a6:	ff 2e       	mov	r15, r31
    19a8:	f0 2d       	mov	r31, r0
    19aa:	0e 94 2a 0a 	call	0x1454	; 0x1454 <xTaskCreate>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	#endif /* configUSE_TIMERS */

	if( xReturn == pdPASS )
    19ae:	81 30       	cpi	r24, 0x01	; 1
    19b0:	81 f4       	brne	.+32     	; 0x19d2 <vTaskStartScheduler+0x4c>
		/* Interrupts are turned off here, to ensure a tick does not occur
		before or during the call to xPortStartScheduler().  The stacks of
		the created tasks contain a status word with interrupts switched on
		so interrupts will automatically get re-enabled when the first task
		starts to run. */
		portDISABLE_INTERRUPTS();
    19b2:	f8 94       	cli
			structure specific to the task that will run first. */
			_impure_ptr = &( pxCurrentTCB->xNewLib_reent );
		}
		#endif /* configUSE_NEWLIB_REENTRANT */

		xNextTaskUnblockTime = portMAX_DELAY;
    19b4:	8f ef       	ldi	r24, 0xFF	; 255
    19b6:	9f ef       	ldi	r25, 0xFF	; 255
    19b8:	90 93 9b 03 	sts	0x039B, r25
    19bc:	80 93 9a 03 	sts	0x039A, r24
		xSchedulerRunning = pdTRUE;
    19c0:	81 e0       	ldi	r24, 0x01	; 1
    19c2:	80 93 9f 03 	sts	0x039F, r24
		xTickCount = ( TickType_t ) 0U;
    19c6:	10 92 a2 03 	sts	0x03A2, r1
    19ca:	10 92 a1 03 	sts	0x03A1, r1
		the run time counter time base. */
		portCONFIGURE_TIMER_FOR_RUN_TIME_STATS();

		/* Setting up the timer tick is hardware specific and thus in the
		portable interface. */
		if( xPortStartScheduler() != pdFALSE )
    19ce:	0e 94 e6 03 	call	0x7cc	; 0x7cc <xPortStartScheduler>
	}

	/* Prevent compiler warnings if INCLUDE_xTaskGetIdleTaskHandle is set to 0,
	meaning xIdleTaskHandle is not used anywhere else. */
	( void ) xIdleTaskHandle;
}
    19d2:	0f 91       	pop	r16
    19d4:	ff 90       	pop	r15
    19d6:	ef 90       	pop	r14
    19d8:	08 95       	ret

000019da <vTaskEndScheduler>:
void vTaskEndScheduler( void )
{
	/* Stop the scheduler interrupts and call the portable scheduler end
	routine so the original ISRs can be restored if necessary.  The port
	layer must ensure interrupts enable	bit is left in the correct state. */
	portDISABLE_INTERRUPTS();
    19da:	f8 94       	cli
	xSchedulerRunning = pdFALSE;
    19dc:	10 92 9f 03 	sts	0x039F, r1
	vPortEndScheduler();
    19e0:	0e 94 1b 04 	call	0x836	; 0x836 <vPortEndScheduler>
}
    19e4:	08 95       	ret

000019e6 <vTaskSuspendAll>:
{
	/* A critical section is not required as the variable is of type
	BaseType_t.  Please read Richard Barry's reply in the following link to a
	post in the FreeRTOS support forum before reporting this as a bug! -
	http://goo.gl/wu4acr */
	++uxSchedulerSuspended;
    19e6:	80 91 99 03 	lds	r24, 0x0399
    19ea:	8f 5f       	subi	r24, 0xFF	; 255
    19ec:	80 93 99 03 	sts	0x0399, r24
}
    19f0:	08 95       	ret

000019f2 <xTaskGetTickCount>:
TickType_t xTaskGetTickCount( void )
{
TickType_t xTicks;

	/* Critical section required if running on a 16 bit processor. */
	portTICK_TYPE_ENTER_CRITICAL();
    19f2:	0f b6       	in	r0, 0x3f	; 63
    19f4:	f8 94       	cli
    19f6:	0f 92       	push	r0
	{
		xTicks = xTickCount;
    19f8:	80 91 a1 03 	lds	r24, 0x03A1
    19fc:	90 91 a2 03 	lds	r25, 0x03A2
	}
	portTICK_TYPE_EXIT_CRITICAL();
    1a00:	0f 90       	pop	r0
    1a02:	0f be       	out	0x3f, r0	; 63

	return xTicks;
}
    1a04:	08 95       	ret

00001a06 <xTaskGetTickCountFromISR>:
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portTICK_TYPE_SET_INTERRUPT_MASK_FROM_ISR();
	{
		xReturn = xTickCount;
    1a06:	80 91 a1 03 	lds	r24, 0x03A1
    1a0a:	90 91 a2 03 	lds	r25, 0x03A2
	}
	portTICK_TYPE_CLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    1a0e:	08 95       	ret

00001a10 <uxTaskGetNumberOfTasks>:

UBaseType_t uxTaskGetNumberOfTasks( void )
{
	/* A critical section is not required because the variables are of type
	BaseType_t. */
	return uxCurrentNumberOfTasks;
    1a10:	80 91 a3 03 	lds	r24, 0x03A3
}
    1a14:	08 95       	ret

00001a16 <pcTaskGetName>:
{
TCB_t *pxTCB;

	/* If null is passed in here then the name of the calling task is being
	queried. */
	pxTCB = prvGetTCBFromHandle( xTaskToQuery );
    1a16:	00 97       	sbiw	r24, 0x00	; 0
    1a18:	21 f4       	brne	.+8      	; 0x1a22 <pcTaskGetName+0xc>
    1a1a:	80 91 97 03 	lds	r24, 0x0397
    1a1e:	90 91 98 03 	lds	r25, 0x0398
	configASSERT( pxTCB );
	return &( pxTCB->pcTaskName[ 0 ] );
    1a22:	49 96       	adiw	r24, 0x19	; 25
}
    1a24:	08 95       	ret

00001a26 <xTaskIncrementTick>:

#endif /* INCLUDE_xTaskAbortDelay */
/*----------------------------------------------------------*/

BaseType_t xTaskIncrementTick( void )
{
    1a26:	cf 92       	push	r12
    1a28:	df 92       	push	r13
    1a2a:	ef 92       	push	r14
    1a2c:	ff 92       	push	r15
    1a2e:	0f 93       	push	r16
    1a30:	1f 93       	push	r17
    1a32:	cf 93       	push	r28
    1a34:	df 93       	push	r29

	/* Called by the portable layer each time a tick interrupt occurs.
	Increments the tick then checks to see if the new tick value will cause any
	tasks to be unblocked. */
	traceTASK_INCREMENT_TICK( xTickCount );
	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1a36:	80 91 99 03 	lds	r24, 0x0399
    1a3a:	88 23       	and	r24, r24
    1a3c:	09 f0       	breq	.+2      	; 0x1a40 <xTaskIncrementTick+0x1a>
    1a3e:	98 c0       	rjmp	.+304    	; 0x1b70 <xTaskIncrementTick+0x14a>
	{
		/* Minor optimisation.  The tick count cannot change in this
		block. */
		const TickType_t xConstTickCount = xTickCount + 1;
    1a40:	c0 90 a1 03 	lds	r12, 0x03A1
    1a44:	d0 90 a2 03 	lds	r13, 0x03A2
    1a48:	08 94       	sec
    1a4a:	c1 1c       	adc	r12, r1
    1a4c:	d1 1c       	adc	r13, r1

		/* Increment the RTOS tick, switching the delayed and overflowed
		delayed lists if it wraps to 0. */
		xTickCount = xConstTickCount;
    1a4e:	d0 92 a2 03 	sts	0x03A2, r13
    1a52:	c0 92 a1 03 	sts	0x03A1, r12

		if( xConstTickCount == ( TickType_t ) 0U )
    1a56:	c1 14       	cp	r12, r1
    1a58:	d1 04       	cpc	r13, r1
    1a5a:	b9 f4       	brne	.+46     	; 0x1a8a <xTaskIncrementTick+0x64>
		{
			taskSWITCH_DELAYED_LISTS();
    1a5c:	80 91 a7 03 	lds	r24, 0x03A7
    1a60:	90 91 a8 03 	lds	r25, 0x03A8
    1a64:	20 91 a5 03 	lds	r18, 0x03A5
    1a68:	30 91 a6 03 	lds	r19, 0x03A6
    1a6c:	30 93 a8 03 	sts	0x03A8, r19
    1a70:	20 93 a7 03 	sts	0x03A7, r18
    1a74:	90 93 a6 03 	sts	0x03A6, r25
    1a78:	80 93 a5 03 	sts	0x03A5, r24
    1a7c:	80 91 9c 03 	lds	r24, 0x039C
    1a80:	8f 5f       	subi	r24, 0xFF	; 255
    1a82:	80 93 9c 03 	sts	0x039C, r24
    1a86:	0e 94 a6 09 	call	0x134c	; 0x134c <prvResetNextTaskUnblockTime>

		/* See if this tick has made a timeout expire.  Tasks are stored in
		the	queue in the order of their wake time - meaning once one task
		has been found whose block time has not expired there is no need to
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
    1a8a:	80 91 9a 03 	lds	r24, 0x039A
    1a8e:	90 91 9b 03 	lds	r25, 0x039B
    1a92:	c8 16       	cp	r12, r24
    1a94:	d9 06       	cpc	r13, r25
    1a96:	20 f4       	brcc	.+8      	; 0x1aa0 <xTaskIncrementTick+0x7a>

BaseType_t xTaskIncrementTick( void )
{
TCB_t * pxTCB;
TickType_t xItemValue;
BaseType_t xSwitchRequired = pdFALSE;
    1a98:	ff 24       	eor	r15, r15
    1a9a:	54 c0       	rjmp	.+168    	; 0x1b44 <xTaskIncrementTick+0x11e>
						only be performed if the unblocked task has a
						priority that is equal to or higher than the
						currently executing task. */
						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
						{
							xSwitchRequired = pdTRUE;
    1a9c:	fe 2c       	mov	r15, r14
    1a9e:	03 c0       	rjmp	.+6      	; 0x1aa6 <xTaskIncrementTick+0x80>

		/* See if this tick has made a timeout expire.  Tasks are stored in
		the	queue in the order of their wake time - meaning once one task
		has been found whose block time has not expired there is no need to
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
    1aa0:	ff 24       	eor	r15, r15
						only be performed if the unblocked task has a
						priority that is equal to or higher than the
						currently executing task. */
						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
						{
							xSwitchRequired = pdTRUE;
    1aa2:	ee 24       	eor	r14, r14
    1aa4:	e3 94       	inc	r14
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
		{
			for( ;; )
			{
				if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
    1aa6:	e0 91 a7 03 	lds	r30, 0x03A7
    1aaa:	f0 91 a8 03 	lds	r31, 0x03A8
    1aae:	80 81       	ld	r24, Z
    1ab0:	88 23       	and	r24, r24
    1ab2:	39 f4       	brne	.+14     	; 0x1ac2 <xTaskIncrementTick+0x9c>
					/* The delayed list is empty.  Set xNextTaskUnblockTime
					to the maximum possible value so it is extremely
					unlikely that the
					if( xTickCount >= xNextTaskUnblockTime ) test will pass
					next time through. */
					xNextTaskUnblockTime = portMAX_DELAY; /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    1ab4:	8f ef       	ldi	r24, 0xFF	; 255
    1ab6:	9f ef       	ldi	r25, 0xFF	; 255
    1ab8:	90 93 9b 03 	sts	0x039B, r25
    1abc:	80 93 9a 03 	sts	0x039A, r24
					break;
    1ac0:	41 c0       	rjmp	.+130    	; 0x1b44 <xTaskIncrementTick+0x11e>
				{
					/* The delayed list is not empty, get the value of the
					item at the head of the delayed list.  This is the time
					at which the task at the head of the delayed list must
					be removed from the Blocked state. */
					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList );
    1ac2:	e0 91 a7 03 	lds	r30, 0x03A7
    1ac6:	f0 91 a8 03 	lds	r31, 0x03A8
    1aca:	05 80       	ldd	r0, Z+5	; 0x05
    1acc:	f6 81       	ldd	r31, Z+6	; 0x06
    1ace:	e0 2d       	mov	r30, r0
    1ad0:	c6 81       	ldd	r28, Z+6	; 0x06
    1ad2:	d7 81       	ldd	r29, Z+7	; 0x07
					xItemValue = listGET_LIST_ITEM_VALUE( &( pxTCB->xStateListItem ) );
    1ad4:	8a 81       	ldd	r24, Y+2	; 0x02
    1ad6:	9b 81       	ldd	r25, Y+3	; 0x03

					if( xConstTickCount < xItemValue )
    1ad8:	c8 16       	cp	r12, r24
    1ada:	d9 06       	cpc	r13, r25
    1adc:	28 f4       	brcc	.+10     	; 0x1ae8 <xTaskIncrementTick+0xc2>
						/* It is not time to unblock this item yet, but the
						item value is the time at which the task at the head
						of the blocked list must be removed from the Blocked
						state -	so record the item value in
						xNextTaskUnblockTime. */
						xNextTaskUnblockTime = xItemValue;
    1ade:	90 93 9b 03 	sts	0x039B, r25
    1ae2:	80 93 9a 03 	sts	0x039A, r24
						break;
    1ae6:	2e c0       	rjmp	.+92     	; 0x1b44 <xTaskIncrementTick+0x11e>
					{
						mtCOVERAGE_TEST_MARKER();
					}

					/* It is time to remove the item from the Blocked state. */
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1ae8:	8e 01       	movw	r16, r28
    1aea:	0e 5f       	subi	r16, 0xFE	; 254
    1aec:	1f 4f       	sbci	r17, 0xFF	; 255
    1aee:	c8 01       	movw	r24, r16
    1af0:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>

					/* Is the task waiting on an event also?  If so remove
					it from the event list. */
					if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
    1af4:	8c 89       	ldd	r24, Y+20	; 0x14
    1af6:	9d 89       	ldd	r25, Y+21	; 0x15
    1af8:	00 97       	sbiw	r24, 0x00	; 0
    1afa:	21 f0       	breq	.+8      	; 0x1b04 <xTaskIncrementTick+0xde>
					{
						( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1afc:	ce 01       	movw	r24, r28
    1afe:	0c 96       	adiw	r24, 0x0c	; 12
    1b00:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
						mtCOVERAGE_TEST_MARKER();
					}

					/* Place the unblocked task into the appropriate ready
					list. */
					prvAddTaskToReadyList( pxTCB );
    1b04:	8e 89       	ldd	r24, Y+22	; 0x16
    1b06:	90 91 a0 03 	lds	r25, 0x03A0
    1b0a:	98 17       	cp	r25, r24
    1b0c:	10 f4       	brcc	.+4      	; 0x1b12 <xTaskIncrementTick+0xec>
    1b0e:	80 93 a0 03 	sts	0x03A0, r24
    1b12:	90 e0       	ldi	r25, 0x00	; 0
    1b14:	9c 01       	movw	r18, r24
    1b16:	22 0f       	add	r18, r18
    1b18:	33 1f       	adc	r19, r19
    1b1a:	22 0f       	add	r18, r18
    1b1c:	33 1f       	adc	r19, r19
    1b1e:	22 0f       	add	r18, r18
    1b20:	33 1f       	adc	r19, r19
    1b22:	82 0f       	add	r24, r18
    1b24:	93 1f       	adc	r25, r19
    1b26:	86 55       	subi	r24, 0x56	; 86
    1b28:	9c 4f       	sbci	r25, 0xFC	; 252
    1b2a:	b8 01       	movw	r22, r16
    1b2c:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
					{
						/* Preemption is on, but a context switch should
						only be performed if the unblocked task has a
						priority that is equal to or higher than the
						currently executing task. */
						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    1b30:	e0 91 97 03 	lds	r30, 0x0397
    1b34:	f0 91 98 03 	lds	r31, 0x0398
    1b38:	9e 89       	ldd	r25, Y+22	; 0x16
    1b3a:	86 89       	ldd	r24, Z+22	; 0x16
    1b3c:	98 17       	cp	r25, r24
    1b3e:	08 f0       	brcs	.+2      	; 0x1b42 <xTaskIncrementTick+0x11c>
    1b40:	ad cf       	rjmp	.-166    	; 0x1a9c <xTaskIncrementTick+0x76>
    1b42:	b1 cf       	rjmp	.-158    	; 0x1aa6 <xTaskIncrementTick+0x80>
		/* Tasks of equal priority to the currently running task will share
		processing time (time slice) if preemption is on, and the application
		writer has not explicitly turned time slicing off. */
		#if ( ( configUSE_PREEMPTION == 1 ) && ( configUSE_TIME_SLICING == 1 ) )
		{
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ pxCurrentTCB->uxPriority ] ) ) > ( UBaseType_t ) 1 )
    1b44:	e0 91 97 03 	lds	r30, 0x0397
    1b48:	f0 91 98 03 	lds	r31, 0x0398
    1b4c:	86 89       	ldd	r24, Z+22	; 0x16
    1b4e:	90 e0       	ldi	r25, 0x00	; 0
    1b50:	fc 01       	movw	r30, r24
    1b52:	ee 0f       	add	r30, r30
    1b54:	ff 1f       	adc	r31, r31
    1b56:	ee 0f       	add	r30, r30
    1b58:	ff 1f       	adc	r31, r31
    1b5a:	ee 0f       	add	r30, r30
    1b5c:	ff 1f       	adc	r31, r31
    1b5e:	8e 0f       	add	r24, r30
    1b60:	9f 1f       	adc	r25, r31
    1b62:	fc 01       	movw	r30, r24
    1b64:	e6 55       	subi	r30, 0x56	; 86
    1b66:	fc 4f       	sbci	r31, 0xFC	; 252
    1b68:	80 81       	ld	r24, Z
    1b6a:	82 30       	cpi	r24, 0x02	; 2
    1b6c:	40 f4       	brcc	.+16     	; 0x1b7e <xTaskIncrementTick+0x158>
    1b6e:	09 c0       	rjmp	.+18     	; 0x1b82 <xTaskIncrementTick+0x15c>
		}
		#endif /* configUSE_TICK_HOOK */
	}
	else
	{
		++uxPendedTicks;
    1b70:	80 91 9e 03 	lds	r24, 0x039E
    1b74:	8f 5f       	subi	r24, 0xFF	; 255
    1b76:	80 93 9e 03 	sts	0x039E, r24

BaseType_t xTaskIncrementTick( void )
{
TCB_t * pxTCB;
TickType_t xItemValue;
BaseType_t xSwitchRequired = pdFALSE;
    1b7a:	ff 24       	eor	r15, r15
    1b7c:	02 c0       	rjmp	.+4      	; 0x1b82 <xTaskIncrementTick+0x15c>
		writer has not explicitly turned time slicing off. */
		#if ( ( configUSE_PREEMPTION == 1 ) && ( configUSE_TIME_SLICING == 1 ) )
		{
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ pxCurrentTCB->uxPriority ] ) ) > ( UBaseType_t ) 1 )
			{
				xSwitchRequired = pdTRUE;
    1b7e:	ff 24       	eor	r15, r15
    1b80:	f3 94       	inc	r15
		#endif
	}

	#if ( configUSE_PREEMPTION == 1 )
	{
		if( xYieldPending != pdFALSE )
    1b82:	80 91 9d 03 	lds	r24, 0x039D
    1b86:	88 23       	and	r24, r24
    1b88:	11 f0       	breq	.+4      	; 0x1b8e <xTaskIncrementTick+0x168>
		{
			xSwitchRequired = pdTRUE;
    1b8a:	ff 24       	eor	r15, r15
    1b8c:	f3 94       	inc	r15
		}
	}
	#endif /* configUSE_PREEMPTION */

	return xSwitchRequired;
}
    1b8e:	8f 2d       	mov	r24, r15
    1b90:	df 91       	pop	r29
    1b92:	cf 91       	pop	r28
    1b94:	1f 91       	pop	r17
    1b96:	0f 91       	pop	r16
    1b98:	ff 90       	pop	r15
    1b9a:	ef 90       	pop	r14
    1b9c:	df 90       	pop	r13
    1b9e:	cf 90       	pop	r12
    1ba0:	08 95       	ret

00001ba2 <xTaskResumeAll>:

#endif /* configUSE_TICKLESS_IDLE */
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
    1ba2:	df 92       	push	r13
    1ba4:	ef 92       	push	r14
    1ba6:	ff 92       	push	r15
    1ba8:	0f 93       	push	r16
    1baa:	1f 93       	push	r17
    1bac:	cf 93       	push	r28
    1bae:	df 93       	push	r29
	/* It is possible that an ISR caused a task to be removed from an event
	list while the scheduler was suspended.  If this was the case then the
	removed task will have been added to the xPendingReadyList.  Once the
	scheduler has been resumed it is safe to move all the pending ready
	tasks from this list into their appropriate ready list. */
	taskENTER_CRITICAL();
    1bb0:	0f b6       	in	r0, 0x3f	; 63
    1bb2:	f8 94       	cli
    1bb4:	0f 92       	push	r0
	{
		--uxSchedulerSuspended;
    1bb6:	80 91 99 03 	lds	r24, 0x0399
    1bba:	81 50       	subi	r24, 0x01	; 1
    1bbc:	80 93 99 03 	sts	0x0399, r24

		if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1bc0:	80 91 99 03 	lds	r24, 0x0399
    1bc4:	88 23       	and	r24, r24
    1bc6:	09 f0       	breq	.+2      	; 0x1bca <xTaskResumeAll+0x28>
    1bc8:	5f c0       	rjmp	.+190    	; 0x1c88 <xTaskResumeAll+0xe6>
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
    1bca:	80 91 a3 03 	lds	r24, 0x03A3
    1bce:	88 23       	and	r24, r24
    1bd0:	91 f5       	brne	.+100    	; 0x1c36 <xTaskResumeAll+0x94>
    1bd2:	5d c0       	rjmp	.+186    	; 0x1c8e <xTaskResumeAll+0xec>
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
				{
					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( ( &xPendingReadyList ) );
    1bd4:	e0 91 ee 03 	lds	r30, 0x03EE
    1bd8:	f0 91 ef 03 	lds	r31, 0x03EF
    1bdc:	c6 81       	ldd	r28, Z+6	; 0x06
    1bde:	d7 81       	ldd	r29, Z+7	; 0x07
					( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1be0:	ce 01       	movw	r24, r28
    1be2:	0c 96       	adiw	r24, 0x0c	; 12
    1be4:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1be8:	8e 01       	movw	r16, r28
    1bea:	0e 5f       	subi	r16, 0xFE	; 254
    1bec:	1f 4f       	sbci	r17, 0xFF	; 255
    1bee:	c8 01       	movw	r24, r16
    1bf0:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    1bf4:	8e 89       	ldd	r24, Y+22	; 0x16
    1bf6:	90 91 a0 03 	lds	r25, 0x03A0
    1bfa:	98 17       	cp	r25, r24
    1bfc:	10 f4       	brcc	.+4      	; 0x1c02 <xTaskResumeAll+0x60>
    1bfe:	80 93 a0 03 	sts	0x03A0, r24
    1c02:	90 e0       	ldi	r25, 0x00	; 0
    1c04:	9c 01       	movw	r18, r24
    1c06:	22 0f       	add	r18, r18
    1c08:	33 1f       	adc	r19, r19
    1c0a:	22 0f       	add	r18, r18
    1c0c:	33 1f       	adc	r19, r19
    1c0e:	22 0f       	add	r18, r18
    1c10:	33 1f       	adc	r19, r19
    1c12:	82 0f       	add	r24, r18
    1c14:	93 1f       	adc	r25, r19
    1c16:	86 55       	subi	r24, 0x56	; 86
    1c18:	9c 4f       	sbci	r25, 0xFC	; 252
    1c1a:	b8 01       	movw	r22, r16
    1c1c:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    1c20:	e0 91 97 03 	lds	r30, 0x0397
    1c24:	f0 91 98 03 	lds	r31, 0x0398
    1c28:	9e 89       	ldd	r25, Y+22	; 0x16
    1c2a:	86 89       	ldd	r24, Z+22	; 0x16
    1c2c:	98 17       	cp	r25, r24
    1c2e:	68 f0       	brcs	.+26     	; 0x1c4a <xTaskResumeAll+0xa8>
					{
						xYieldPending = pdTRUE;
    1c30:	d0 92 9d 03 	sts	0x039D, r13
    1c34:	0a c0       	rjmp	.+20     	; 0x1c4a <xTaskResumeAll+0xa8>
	{
		--uxSchedulerSuspended;

		if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
    1c36:	c0 e0       	ldi	r28, 0x00	; 0
    1c38:	d0 e0       	ldi	r29, 0x00	; 0
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
    1c3a:	0f 2e       	mov	r0, r31
    1c3c:	f9 ee       	ldi	r31, 0xE9	; 233
    1c3e:	ef 2e       	mov	r14, r31
    1c40:	f3 e0       	ldi	r31, 0x03	; 3
    1c42:	ff 2e       	mov	r15, r31
    1c44:	f0 2d       	mov	r31, r0

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
					{
						xYieldPending = pdTRUE;
    1c46:	dd 24       	eor	r13, r13
    1c48:	d3 94       	inc	r13
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
    1c4a:	f7 01       	movw	r30, r14
    1c4c:	80 81       	ld	r24, Z
    1c4e:	88 23       	and	r24, r24
    1c50:	09 f6       	brne	.-126    	; 0x1bd4 <xTaskResumeAll+0x32>
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				if( pxTCB != NULL )
    1c52:	20 97       	sbiw	r28, 0x00	; 0
    1c54:	11 f0       	breq	.+4      	; 0x1c5a <xTaskResumeAll+0xb8>
					which may have prevented the next unblock time from being
					re-calculated, in which case re-calculate it now.  Mainly
					important for low power tickless implementations, where
					this can prevent an unnecessary exit from low power
					state. */
					prvResetNextTaskUnblockTime();
    1c56:	0e 94 a6 09 	call	0x134c	; 0x134c <prvResetNextTaskUnblockTime>
				/* If any ticks occurred while the scheduler was suspended then
				they should be processed now.  This ensures the tick count does
				not	slip, and that any delayed tasks are resumed at the correct
				time. */
				{
					UBaseType_t uxPendedCounts = uxPendedTicks; /* Non-volatile copy. */
    1c5a:	c0 91 9e 03 	lds	r28, 0x039E

					if( uxPendedCounts > ( UBaseType_t ) 0U )
    1c5e:	cc 23       	and	r28, r28
    1c60:	59 f0       	breq	.+22     	; 0x1c78 <xTaskResumeAll+0xd6>
					{
						do
						{
							if( xTaskIncrementTick() != pdFALSE )
							{
								xYieldPending = pdTRUE;
    1c62:	01 e0       	ldi	r16, 0x01	; 1

					if( uxPendedCounts > ( UBaseType_t ) 0U )
					{
						do
						{
							if( xTaskIncrementTick() != pdFALSE )
    1c64:	0e 94 13 0d 	call	0x1a26	; 0x1a26 <xTaskIncrementTick>
    1c68:	88 23       	and	r24, r24
    1c6a:	11 f0       	breq	.+4      	; 0x1c70 <xTaskResumeAll+0xce>
							{
								xYieldPending = pdTRUE;
    1c6c:	00 93 9d 03 	sts	0x039D, r16
							}
							else
							{
								mtCOVERAGE_TEST_MARKER();
							}
							--uxPendedCounts;
    1c70:	c1 50       	subi	r28, 0x01	; 1
						} while( uxPendedCounts > ( UBaseType_t ) 0U );
    1c72:	c1 f7       	brne	.-16     	; 0x1c64 <xTaskResumeAll+0xc2>

						uxPendedTicks = 0;
    1c74:	10 92 9e 03 	sts	0x039E, r1
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				if( xYieldPending != pdFALSE )
    1c78:	80 91 9d 03 	lds	r24, 0x039D
    1c7c:	88 23       	and	r24, r24
    1c7e:	31 f0       	breq	.+12     	; 0x1c8c <xTaskResumeAll+0xea>
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
					}
					#endif
					taskYIELD_IF_USING_PREEMPTION();
    1c80:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>

				if( xYieldPending != pdFALSE )
				{
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
    1c84:	81 e0       	ldi	r24, 0x01	; 1
    1c86:	03 c0       	rjmp	.+6      	; 0x1c8e <xTaskResumeAll+0xec>
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
TCB_t *pxTCB = NULL;
BaseType_t xAlreadyYielded = pdFALSE;
    1c88:	80 e0       	ldi	r24, 0x00	; 0
    1c8a:	01 c0       	rjmp	.+2      	; 0x1c8e <xTaskResumeAll+0xec>
    1c8c:	80 e0       	ldi	r24, 0x00	; 0
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
	taskEXIT_CRITICAL();
    1c8e:	0f 90       	pop	r0
    1c90:	0f be       	out	0x3f, r0	; 63

	return xAlreadyYielded;
}
    1c92:	df 91       	pop	r29
    1c94:	cf 91       	pop	r28
    1c96:	1f 91       	pop	r17
    1c98:	0f 91       	pop	r16
    1c9a:	ff 90       	pop	r15
    1c9c:	ef 90       	pop	r14
    1c9e:	df 90       	pop	r13
    1ca0:	08 95       	ret

00001ca2 <prvIdleTask>:
		too often in the idle task. */
		while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )
		{
			vTaskSuspendAll();
			{
				xListIsEmpty = listLIST_IS_EMPTY( &xTasksWaitingTermination );
    1ca2:	02 ef       	ldi	r16, 0xF2	; 242
    1ca4:	13 e0       	ldi	r17, 0x03	; 3

			A critical region is not required here as we are just reading from
			the list, and an occasional incorrect value will not matter.  If
			the ready list at the idle priority contains more than one task
			then a task other than the idle task is ready to execute. */
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
    1ca6:	0f 2e       	mov	r0, r31
    1ca8:	fa ea       	ldi	r31, 0xAA	; 170
    1caa:	ef 2e       	mov	r14, r31
    1cac:	f3 e0       	ldi	r31, 0x03	; 3
    1cae:	ff 2e       	mov	r15, r31
    1cb0:	f0 2d       	mov	r31, r0
    1cb2:	24 c0       	rjmp	.+72     	; 0x1cfc <prvIdleTask+0x5a>

		/* ucTasksDeleted is used to prevent vTaskSuspendAll() being called
		too often in the idle task. */
		while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )
		{
			vTaskSuspendAll();
    1cb4:	0e 94 f3 0c 	call	0x19e6	; 0x19e6 <vTaskSuspendAll>
			{
				xListIsEmpty = listLIST_IS_EMPTY( &xTasksWaitingTermination );
    1cb8:	f8 01       	movw	r30, r16
    1cba:	c0 81       	ld	r28, Z
			}
			( void ) xTaskResumeAll();
    1cbc:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>

			if( xListIsEmpty == pdFALSE )
    1cc0:	cc 23       	and	r28, r28
    1cc2:	e1 f0       	breq	.+56     	; 0x1cfc <prvIdleTask+0x5a>
			{
				TCB_t *pxTCB;

				taskENTER_CRITICAL();
    1cc4:	0f b6       	in	r0, 0x3f	; 63
    1cc6:	f8 94       	cli
    1cc8:	0f 92       	push	r0
				{
					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( ( &xTasksWaitingTermination ) );
    1cca:	e0 91 f7 03 	lds	r30, 0x03F7
    1cce:	f0 91 f8 03 	lds	r31, 0x03F8
    1cd2:	c6 81       	ldd	r28, Z+6	; 0x06
    1cd4:	d7 81       	ldd	r29, Z+7	; 0x07
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1cd6:	ce 01       	movw	r24, r28
    1cd8:	02 96       	adiw	r24, 0x02	; 2
    1cda:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
					--uxCurrentNumberOfTasks;
    1cde:	80 91 a3 03 	lds	r24, 0x03A3
    1ce2:	81 50       	subi	r24, 0x01	; 1
    1ce4:	80 93 a3 03 	sts	0x03A3, r24
					--uxDeletedTasksWaitingCleanUp;
    1ce8:	80 91 a4 03 	lds	r24, 0x03A4
    1cec:	81 50       	subi	r24, 0x01	; 1
    1cee:	80 93 a4 03 	sts	0x03A4, r24
				}
				taskEXIT_CRITICAL();
    1cf2:	0f 90       	pop	r0
    1cf4:	0f be       	out	0x3f, r0	; 63

				prvDeleteTCB( pxTCB );
    1cf6:	ce 01       	movw	r24, r28
    1cf8:	0e 94 1d 0a 	call	0x143a	; 0x143a <prvDeleteTCB>
	{
		BaseType_t xListIsEmpty;

		/* ucTasksDeleted is used to prevent vTaskSuspendAll() being called
		too often in the idle task. */
		while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )
    1cfc:	80 91 a4 03 	lds	r24, 0x03A4
    1d00:	88 23       	and	r24, r24
    1d02:	c1 f6       	brne	.-80     	; 0x1cb4 <prvIdleTask+0x12>

			A critical region is not required here as we are just reading from
			the list, and an occasional incorrect value will not matter.  If
			the ready list at the idle priority contains more than one task
			then a task other than the idle task is ready to execute. */
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
    1d04:	f7 01       	movw	r30, r14
    1d06:	80 81       	ld	r24, Z
    1d08:	82 30       	cpi	r24, 0x02	; 2
    1d0a:	c0 f3       	brcs	.-16     	; 0x1cfc <prvIdleTask+0x5a>
			{
				taskYIELD();
    1d0c:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
    1d10:	f5 cf       	rjmp	.-22     	; 0x1cfc <prvIdleTask+0x5a>

00001d12 <vTaskDelay>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelay == 1 )

	void vTaskDelay( const TickType_t xTicksToDelay )
	{
    1d12:	cf 93       	push	r28
    1d14:	df 93       	push	r29
    1d16:	ec 01       	movw	r28, r24
	BaseType_t xAlreadyYielded = pdFALSE;

		/* A delay time of zero just forces a reschedule. */
		if( xTicksToDelay > ( TickType_t ) 0U )
    1d18:	00 97       	sbiw	r24, 0x00	; 0
    1d1a:	51 f0       	breq	.+20     	; 0x1d30 <vTaskDelay+0x1e>
		{
			configASSERT( uxSchedulerSuspended == 0 );
			vTaskSuspendAll();
    1d1c:	0e 94 f3 0c 	call	0x19e6	; 0x19e6 <vTaskSuspendAll>
				list or removed from the blocked list until the scheduler
				is resumed.

				This task cannot be in an event list as it is the currently
				executing task. */
				prvAddCurrentTaskToDelayedList( xTicksToDelay, pdFALSE );
    1d20:	ce 01       	movw	r24, r28
    1d22:	60 e0       	ldi	r22, 0x00	; 0
    1d24:	0e 94 c5 09 	call	0x138a	; 0x138a <prvAddCurrentTaskToDelayedList>
			}
			xAlreadyYielded = xTaskResumeAll();
    1d28:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>
			mtCOVERAGE_TEST_MARKER();
		}

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
    1d2c:	88 23       	and	r24, r24
    1d2e:	11 f4       	brne	.+4      	; 0x1d34 <vTaskDelay+0x22>
		{
			portYIELD_WITHIN_API();
    1d30:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    1d34:	df 91       	pop	r29
    1d36:	cf 91       	pop	r28
    1d38:	08 95       	ret

00001d3a <vTaskDelayUntil>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelayUntil == 1 )

	void vTaskDelayUntil( TickType_t * const pxPreviousWakeTime, const TickType_t xTimeIncrement )
	{
    1d3a:	0f 93       	push	r16
    1d3c:	1f 93       	push	r17
    1d3e:	cf 93       	push	r28
    1d40:	df 93       	push	r29
    1d42:	8c 01       	movw	r16, r24
    1d44:	eb 01       	movw	r28, r22

		configASSERT( pxPreviousWakeTime );
		configASSERT( ( xTimeIncrement > 0U ) );
		configASSERT( uxSchedulerSuspended == 0 );

		vTaskSuspendAll();
    1d46:	0e 94 f3 0c 	call	0x19e6	; 0x19e6 <vTaskSuspendAll>
		{
			/* Minor optimisation.  The tick count cannot change in this
			block. */
			const TickType_t xConstTickCount = xTickCount;
    1d4a:	80 91 a1 03 	lds	r24, 0x03A1
    1d4e:	90 91 a2 03 	lds	r25, 0x03A2

			/* Generate the tick time at which the task wants to wake. */
			xTimeToWake = *pxPreviousWakeTime + xTimeIncrement;
    1d52:	f8 01       	movw	r30, r16
    1d54:	20 81       	ld	r18, Z
    1d56:	31 81       	ldd	r19, Z+1	; 0x01
    1d58:	c2 0f       	add	r28, r18
    1d5a:	d3 1f       	adc	r29, r19

			if( xConstTickCount < *pxPreviousWakeTime )
    1d5c:	82 17       	cp	r24, r18
    1d5e:	93 07       	cpc	r25, r19
    1d60:	48 f4       	brcc	.+18     	; 0x1d74 <vTaskDelayUntil+0x3a>
				/* The tick count has overflowed since this function was
				lasted called.  In this case the only time we should ever
				actually delay is if the wake time has also	overflowed,
				and the wake time is greater than the tick time.  When this
				is the case it is as if neither time had overflowed. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) && ( xTimeToWake > xConstTickCount ) )
    1d62:	c2 17       	cp	r28, r18
    1d64:	d3 07       	cpc	r29, r19
    1d66:	f8 f4       	brcc	.+62     	; 0x1da6 <vTaskDelayUntil+0x6c>
					mtCOVERAGE_TEST_MARKER();
				}
			}

			/* Update the wake time ready for the next call. */
			*pxPreviousWakeTime = xTimeToWake;
    1d68:	d1 83       	std	Z+1, r29	; 0x01
    1d6a:	c0 83       	st	Z, r28

			if( xShouldDelay != pdFALSE )
    1d6c:	8c 17       	cp	r24, r28
    1d6e:	9d 07       	cpc	r25, r29
    1d70:	78 f4       	brcc	.+30     	; 0x1d90 <vTaskDelayUntil+0x56>
    1d72:	07 c0       	rjmp	.+14     	; 0x1d82 <vTaskDelayUntil+0x48>
			else
			{
				/* The tick time has not overflowed.  In this case we will
				delay if either the wake time has overflowed, and/or the
				tick time is less than the wake time. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) || ( xTimeToWake > xConstTickCount ) )
    1d74:	c2 17       	cp	r28, r18
    1d76:	d3 07       	cpc	r29, r19
    1d78:	90 f0       	brcs	.+36     	; 0x1d9e <vTaskDelayUntil+0x64>
    1d7a:	8c 17       	cp	r24, r28
    1d7c:	9d 07       	cpc	r25, r29
    1d7e:	78 f0       	brcs	.+30     	; 0x1d9e <vTaskDelayUntil+0x64>
    1d80:	12 c0       	rjmp	.+36     	; 0x1da6 <vTaskDelayUntil+0x6c>
			{
				traceTASK_DELAY_UNTIL( xTimeToWake );

				/* prvAddCurrentTaskToDelayedList() needs the block time, not
				the time to wake, so subtract the current tick count. */
				prvAddCurrentTaskToDelayedList( xTimeToWake - xConstTickCount, pdFALSE );
    1d82:	9e 01       	movw	r18, r28
    1d84:	28 1b       	sub	r18, r24
    1d86:	39 0b       	sbc	r19, r25
    1d88:	c9 01       	movw	r24, r18
    1d8a:	60 e0       	ldi	r22, 0x00	; 0
    1d8c:	0e 94 c5 09 	call	0x138a	; 0x138a <prvAddCurrentTaskToDelayedList>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		xAlreadyYielded = xTaskResumeAll();
    1d90:	0e 94 d1 0d 	call	0x1ba2	; 0x1ba2 <xTaskResumeAll>

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
    1d94:	88 23       	and	r24, r24
    1d96:	59 f4       	brne	.+22     	; 0x1dae <vTaskDelayUntil+0x74>
		{
			portYIELD_WITHIN_API();
    1d98:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
    1d9c:	08 c0       	rjmp	.+16     	; 0x1dae <vTaskDelayUntil+0x74>
					mtCOVERAGE_TEST_MARKER();
				}
			}

			/* Update the wake time ready for the next call. */
			*pxPreviousWakeTime = xTimeToWake;
    1d9e:	f8 01       	movw	r30, r16
    1da0:	d1 83       	std	Z+1, r29	; 0x01
    1da2:	c0 83       	st	Z, r28
    1da4:	ee cf       	rjmp	.-36     	; 0x1d82 <vTaskDelayUntil+0x48>
    1da6:	f8 01       	movw	r30, r16
    1da8:	d1 83       	std	Z+1, r29	; 0x01
    1daa:	c0 83       	st	Z, r28
    1dac:	f1 cf       	rjmp	.-30     	; 0x1d90 <vTaskDelayUntil+0x56>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    1dae:	df 91       	pop	r29
    1db0:	cf 91       	pop	r28
    1db2:	1f 91       	pop	r17
    1db4:	0f 91       	pop	r16
    1db6:	08 95       	ret

00001db8 <vTaskSwitchContext>:
#endif /* configUSE_APPLICATION_TASK_TAG */
/*-----------------------------------------------------------*/

void vTaskSwitchContext( void )
{
	if( uxSchedulerSuspended != ( UBaseType_t ) pdFALSE )
    1db8:	80 91 99 03 	lds	r24, 0x0399
    1dbc:	88 23       	and	r24, r24
    1dbe:	21 f0       	breq	.+8      	; 0x1dc8 <vTaskSwitchContext+0x10>
	{
		/* The scheduler is currently suspended - do not allow a context
		switch. */
		xYieldPending = pdTRUE;
    1dc0:	81 e0       	ldi	r24, 0x01	; 1
    1dc2:	80 93 9d 03 	sts	0x039D, r24
    1dc6:	08 95       	ret
	}
	else
	{
		xYieldPending = pdFALSE;
    1dc8:	10 92 9d 03 	sts	0x039D, r1
		/* Check for stack overflow, if configured. */
		taskCHECK_FOR_STACK_OVERFLOW();

		/* Select a new task to run using either the generic C or port
		optimised asm code. */
		taskSELECT_HIGHEST_PRIORITY_TASK();
    1dcc:	20 91 a0 03 	lds	r18, 0x03A0
    1dd0:	82 2f       	mov	r24, r18
    1dd2:	90 e0       	ldi	r25, 0x00	; 0
    1dd4:	fc 01       	movw	r30, r24
    1dd6:	ee 0f       	add	r30, r30
    1dd8:	ff 1f       	adc	r31, r31
    1dda:	ee 0f       	add	r30, r30
    1ddc:	ff 1f       	adc	r31, r31
    1dde:	ee 0f       	add	r30, r30
    1de0:	ff 1f       	adc	r31, r31
    1de2:	e8 0f       	add	r30, r24
    1de4:	f9 1f       	adc	r31, r25
    1de6:	e6 55       	subi	r30, 0x56	; 86
    1de8:	fc 4f       	sbci	r31, 0xFC	; 252
    1dea:	30 81       	ld	r19, Z
    1dec:	33 23       	and	r19, r19
    1dee:	89 f4       	brne	.+34     	; 0x1e12 <vTaskSwitchContext+0x5a>
    1df0:	21 50       	subi	r18, 0x01	; 1
    1df2:	82 2f       	mov	r24, r18
    1df4:	90 e0       	ldi	r25, 0x00	; 0
    1df6:	fc 01       	movw	r30, r24
    1df8:	ee 0f       	add	r30, r30
    1dfa:	ff 1f       	adc	r31, r31
    1dfc:	ee 0f       	add	r30, r30
    1dfe:	ff 1f       	adc	r31, r31
    1e00:	ee 0f       	add	r30, r30
    1e02:	ff 1f       	adc	r31, r31
    1e04:	e8 0f       	add	r30, r24
    1e06:	f9 1f       	adc	r31, r25
    1e08:	e6 55       	subi	r30, 0x56	; 86
    1e0a:	fc 4f       	sbci	r31, 0xFC	; 252
    1e0c:	30 81       	ld	r19, Z
    1e0e:	33 23       	and	r19, r19
    1e10:	79 f3       	breq	.-34     	; 0x1df0 <vTaskSwitchContext+0x38>
    1e12:	dc 01       	movw	r26, r24
    1e14:	aa 0f       	add	r26, r26
    1e16:	bb 1f       	adc	r27, r27
    1e18:	aa 0f       	add	r26, r26
    1e1a:	bb 1f       	adc	r27, r27
    1e1c:	aa 0f       	add	r26, r26
    1e1e:	bb 1f       	adc	r27, r27
    1e20:	8a 0f       	add	r24, r26
    1e22:	9b 1f       	adc	r25, r27
    1e24:	dc 01       	movw	r26, r24
    1e26:	a6 55       	subi	r26, 0x56	; 86
    1e28:	bc 4f       	sbci	r27, 0xFC	; 252
    1e2a:	11 96       	adiw	r26, 0x01	; 1
    1e2c:	ed 91       	ld	r30, X+
    1e2e:	fc 91       	ld	r31, X
    1e30:	12 97       	sbiw	r26, 0x02	; 2
    1e32:	02 80       	ldd	r0, Z+2	; 0x02
    1e34:	f3 81       	ldd	r31, Z+3	; 0x03
    1e36:	e0 2d       	mov	r30, r0
    1e38:	12 96       	adiw	r26, 0x02	; 2
    1e3a:	fc 93       	st	X, r31
    1e3c:	ee 93       	st	-X, r30
    1e3e:	11 97       	sbiw	r26, 0x01	; 1
    1e40:	cd 01       	movw	r24, r26
    1e42:	03 96       	adiw	r24, 0x03	; 3
    1e44:	e8 17       	cp	r30, r24
    1e46:	f9 07       	cpc	r31, r25
    1e48:	31 f4       	brne	.+12     	; 0x1e56 <vTaskSwitchContext+0x9e>
    1e4a:	82 81       	ldd	r24, Z+2	; 0x02
    1e4c:	93 81       	ldd	r25, Z+3	; 0x03
    1e4e:	12 96       	adiw	r26, 0x02	; 2
    1e50:	9c 93       	st	X, r25
    1e52:	8e 93       	st	-X, r24
    1e54:	11 97       	sbiw	r26, 0x01	; 1
    1e56:	11 96       	adiw	r26, 0x01	; 1
    1e58:	ed 91       	ld	r30, X+
    1e5a:	fc 91       	ld	r31, X
    1e5c:	12 97       	sbiw	r26, 0x02	; 2
    1e5e:	86 81       	ldd	r24, Z+6	; 0x06
    1e60:	97 81       	ldd	r25, Z+7	; 0x07
    1e62:	90 93 98 03 	sts	0x0398, r25
    1e66:	80 93 97 03 	sts	0x0397, r24
    1e6a:	20 93 a0 03 	sts	0x03A0, r18
    1e6e:	08 95       	ret

00001e70 <vTaskSuspend>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskSuspend == 1 )

	void vTaskSuspend( TaskHandle_t xTaskToSuspend )
	{
    1e70:	0f 93       	push	r16
    1e72:	1f 93       	push	r17
    1e74:	cf 93       	push	r28
    1e76:	df 93       	push	r29
	TCB_t *pxTCB;

		taskENTER_CRITICAL();
    1e78:	0f b6       	in	r0, 0x3f	; 63
    1e7a:	f8 94       	cli
    1e7c:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the running task that is
			being suspended. */
			pxTCB = prvGetTCBFromHandle( xTaskToSuspend );
    1e7e:	00 97       	sbiw	r24, 0x00	; 0
    1e80:	29 f4       	brne	.+10     	; 0x1e8c <vTaskSuspend+0x1c>
    1e82:	00 91 97 03 	lds	r16, 0x0397
    1e86:	10 91 98 03 	lds	r17, 0x0398
    1e8a:	01 c0       	rjmp	.+2      	; 0x1e8e <vTaskSuspend+0x1e>
    1e8c:	8c 01       	movw	r16, r24

			traceTASK_SUSPEND( pxTCB );

			/* Remove task from the ready/delayed list and place in the
			suspended list. */
			if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    1e8e:	e8 01       	movw	r28, r16
    1e90:	22 96       	adiw	r28, 0x02	; 2
    1e92:	ce 01       	movw	r24, r28
    1e94:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
			{
				mtCOVERAGE_TEST_MARKER();
			}

			/* Is the task waiting on an event also? */
			if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
    1e98:	f8 01       	movw	r30, r16
    1e9a:	84 89       	ldd	r24, Z+20	; 0x14
    1e9c:	95 89       	ldd	r25, Z+21	; 0x15
    1e9e:	00 97       	sbiw	r24, 0x00	; 0
    1ea0:	21 f0       	breq	.+8      	; 0x1eaa <vTaskSuspend+0x3a>
			{
				( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1ea2:	c8 01       	movw	r24, r16
    1ea4:	0c 96       	adiw	r24, 0x0c	; 12
    1ea6:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			vListInsertEnd( &xSuspendedTaskList, &( pxTCB->xStateListItem ) );
    1eaa:	8b ef       	ldi	r24, 0xFB	; 251
    1eac:	93 e0       	ldi	r25, 0x03	; 3
    1eae:	be 01       	movw	r22, r28
    1eb0:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
		}
		taskEXIT_CRITICAL();
    1eb4:	0f 90       	pop	r0
    1eb6:	0f be       	out	0x3f, r0	; 63

		if( xSchedulerRunning != pdFALSE )
    1eb8:	80 91 9f 03 	lds	r24, 0x039F
    1ebc:	88 23       	and	r24, r24
    1ebe:	39 f0       	breq	.+14     	; 0x1ece <vTaskSuspend+0x5e>
		{
			/* Reset the next expected unblock time in case it referred to the
			task that is now in the Suspended state. */
			taskENTER_CRITICAL();
    1ec0:	0f b6       	in	r0, 0x3f	; 63
    1ec2:	f8 94       	cli
    1ec4:	0f 92       	push	r0
			{
				prvResetNextTaskUnblockTime();
    1ec6:	0e 94 a6 09 	call	0x134c	; 0x134c <prvResetNextTaskUnblockTime>
			}
			taskEXIT_CRITICAL();
    1eca:	0f 90       	pop	r0
    1ecc:	0f be       	out	0x3f, r0	; 63
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		if( pxTCB == pxCurrentTCB )
    1ece:	80 91 97 03 	lds	r24, 0x0397
    1ed2:	90 91 98 03 	lds	r25, 0x0398
    1ed6:	08 17       	cp	r16, r24
    1ed8:	19 07       	cpc	r17, r25
    1eda:	a1 f4       	brne	.+40     	; 0x1f04 <vTaskSuspend+0x94>
		{
			if( xSchedulerRunning != pdFALSE )
    1edc:	80 91 9f 03 	lds	r24, 0x039F
    1ee0:	88 23       	and	r24, r24
    1ee2:	19 f0       	breq	.+6      	; 0x1eea <vTaskSuspend+0x7a>
			{
				/* The current task has just been suspended. */
				configASSERT( uxSchedulerSuspended == 0 );
				portYIELD_WITHIN_API();
    1ee4:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
    1ee8:	0d c0       	rjmp	.+26     	; 0x1f04 <vTaskSuspend+0x94>
			else
			{
				/* The scheduler is not running, but the task that was pointed
				to by pxCurrentTCB has just been suspended and pxCurrentTCB
				must be adjusted to point to a different task. */
				if( listCURRENT_LIST_LENGTH( &xSuspendedTaskList ) == uxCurrentNumberOfTasks )
    1eea:	80 91 a3 03 	lds	r24, 0x03A3
    1eee:	90 91 fb 03 	lds	r25, 0x03FB
    1ef2:	98 17       	cp	r25, r24
    1ef4:	29 f4       	brne	.+10     	; 0x1f00 <vTaskSuspend+0x90>
				{
					/* No other tasks are ready, so set pxCurrentTCB back to
					NULL so when the next task is created pxCurrentTCB will
					be set to point to it no matter what its relative priority
					is. */
					pxCurrentTCB = NULL;
    1ef6:	10 92 98 03 	sts	0x0398, r1
    1efa:	10 92 97 03 	sts	0x0397, r1
    1efe:	02 c0       	rjmp	.+4      	; 0x1f04 <vTaskSuspend+0x94>
				}
				else
				{
					vTaskSwitchContext();
    1f00:	0e 94 dc 0e 	call	0x1db8	; 0x1db8 <vTaskSwitchContext>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    1f04:	df 91       	pop	r29
    1f06:	cf 91       	pop	r28
    1f08:	1f 91       	pop	r17
    1f0a:	0f 91       	pop	r16
    1f0c:	08 95       	ret

00001f0e <vTaskPlaceOnEventList>:
	}
}
/*-----------------------------------------------------------*/

void vTaskPlaceOnEventList( List_t * const pxEventList, const TickType_t xTicksToWait )
{
    1f0e:	cf 93       	push	r28
    1f10:	df 93       	push	r29
    1f12:	eb 01       	movw	r28, r22

	/* Place the event list item of the TCB in the appropriate event list.
	This is placed in the list in priority order so the highest priority task
	is the first to be woken by the event.  The queue that contains the event
	list is locked, preventing simultaneous access from interrupts. */
	vListInsert( pxEventList, &( pxCurrentTCB->xEventListItem ) );
    1f14:	60 91 97 03 	lds	r22, 0x0397
    1f18:	70 91 98 03 	lds	r23, 0x0398
    1f1c:	64 5f       	subi	r22, 0xF4	; 244
    1f1e:	7f 4f       	sbci	r23, 0xFF	; 255
    1f20:	0e 94 fc 02 	call	0x5f8	; 0x5f8 <vListInsert>

	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    1f24:	ce 01       	movw	r24, r28
    1f26:	61 e0       	ldi	r22, 0x01	; 1
    1f28:	0e 94 c5 09 	call	0x138a	; 0x138a <prvAddCurrentTaskToDelayedList>
}
    1f2c:	df 91       	pop	r29
    1f2e:	cf 91       	pop	r28
    1f30:	08 95       	ret

00001f32 <vTaskPlaceOnUnorderedEventList>:
/*-----------------------------------------------------------*/

void vTaskPlaceOnUnorderedEventList( List_t * pxEventList, const TickType_t xItemValue, const TickType_t xTicksToWait )
{
    1f32:	cf 93       	push	r28
    1f34:	df 93       	push	r29
    1f36:	ea 01       	movw	r28, r20
	configASSERT( uxSchedulerSuspended != 0 );

	/* Store the item value in the event list item.  It is safe to access the
	event list item here as interrupts won't access the event list item of a
	task that is not in the Blocked state. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
    1f38:	e0 91 97 03 	lds	r30, 0x0397
    1f3c:	f0 91 98 03 	lds	r31, 0x0398
    1f40:	70 68       	ori	r23, 0x80	; 128
    1f42:	75 87       	std	Z+13, r23	; 0x0d
    1f44:	64 87       	std	Z+12, r22	; 0x0c
	/* Place the event list item of the TCB at the end of the appropriate event
	list.  It is safe to access the event list here because it is part of an
	event group implementation - and interrupts don't access event groups
	directly (instead they access them indirectly by pending function calls to
	the task level). */
	vListInsertEnd( pxEventList, &( pxCurrentTCB->xEventListItem ) );
    1f46:	60 91 97 03 	lds	r22, 0x0397
    1f4a:	70 91 98 03 	lds	r23, 0x0398
    1f4e:	64 5f       	subi	r22, 0xF4	; 244
    1f50:	7f 4f       	sbci	r23, 0xFF	; 255
    1f52:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>

	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    1f56:	ce 01       	movw	r24, r28
    1f58:	61 e0       	ldi	r22, 0x01	; 1
    1f5a:	0e 94 c5 09 	call	0x138a	; 0x138a <prvAddCurrentTaskToDelayedList>
}
    1f5e:	df 91       	pop	r29
    1f60:	cf 91       	pop	r28
    1f62:	08 95       	ret

00001f64 <xTaskRemoveFromEventList>:

#endif /* configUSE_TIMERS */
/*-----------------------------------------------------------*/

BaseType_t xTaskRemoveFromEventList( const List_t * const pxEventList )
{
    1f64:	0f 93       	push	r16
    1f66:	1f 93       	push	r17
    1f68:	cf 93       	push	r28
    1f6a:	df 93       	push	r29
	get called - the lock count on the queue will get modified instead.  This
	means exclusive access to the event list is guaranteed here.

	This function assumes that a check has already been made to ensure that
	pxEventList is not empty. */
	pxUnblockedTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxEventList );
    1f6c:	dc 01       	movw	r26, r24
    1f6e:	15 96       	adiw	r26, 0x05	; 5
    1f70:	ed 91       	ld	r30, X+
    1f72:	fc 91       	ld	r31, X
    1f74:	16 97       	sbiw	r26, 0x06	; 6
    1f76:	06 81       	ldd	r16, Z+6	; 0x06
    1f78:	17 81       	ldd	r17, Z+7	; 0x07
	configASSERT( pxUnblockedTCB );
	( void ) uxListRemove( &( pxUnblockedTCB->xEventListItem ) );
    1f7a:	e8 01       	movw	r28, r16
    1f7c:	2c 96       	adiw	r28, 0x0c	; 12
    1f7e:	ce 01       	movw	r24, r28
    1f80:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>

	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1f84:	80 91 99 03 	lds	r24, 0x0399
    1f88:	88 23       	and	r24, r24
    1f8a:	e9 f4       	brne	.+58     	; 0x1fc6 <xTaskRemoveFromEventList+0x62>
	{
		( void ) uxListRemove( &( pxUnblockedTCB->xStateListItem ) );
    1f8c:	e8 01       	movw	r28, r16
    1f8e:	22 96       	adiw	r28, 0x02	; 2
    1f90:	ce 01       	movw	r24, r28
    1f92:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
		prvAddTaskToReadyList( pxUnblockedTCB );
    1f96:	f8 01       	movw	r30, r16
    1f98:	86 89       	ldd	r24, Z+22	; 0x16
    1f9a:	90 91 a0 03 	lds	r25, 0x03A0
    1f9e:	98 17       	cp	r25, r24
    1fa0:	10 f4       	brcc	.+4      	; 0x1fa6 <xTaskRemoveFromEventList+0x42>
    1fa2:	80 93 a0 03 	sts	0x03A0, r24
    1fa6:	90 e0       	ldi	r25, 0x00	; 0
    1fa8:	9c 01       	movw	r18, r24
    1faa:	22 0f       	add	r18, r18
    1fac:	33 1f       	adc	r19, r19
    1fae:	22 0f       	add	r18, r18
    1fb0:	33 1f       	adc	r19, r19
    1fb2:	22 0f       	add	r18, r18
    1fb4:	33 1f       	adc	r19, r19
    1fb6:	82 0f       	add	r24, r18
    1fb8:	93 1f       	adc	r25, r19
    1fba:	86 55       	subi	r24, 0x56	; 86
    1fbc:	9c 4f       	sbci	r25, 0xFC	; 252
    1fbe:	be 01       	movw	r22, r28
    1fc0:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
    1fc4:	05 c0       	rjmp	.+10     	; 0x1fd0 <xTaskRemoveFromEventList+0x6c>
	}
	else
	{
		/* The delayed and ready lists cannot be accessed, so hold this task
		pending until the scheduler is resumed. */
		vListInsertEnd( &( xPendingReadyList ), &( pxUnblockedTCB->xEventListItem ) );
    1fc6:	89 ee       	ldi	r24, 0xE9	; 233
    1fc8:	93 e0       	ldi	r25, 0x03	; 3
    1fca:	be 01       	movw	r22, r28
    1fcc:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
	}

	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
    1fd0:	e0 91 97 03 	lds	r30, 0x0397
    1fd4:	f0 91 98 03 	lds	r31, 0x0398
    1fd8:	d8 01       	movw	r26, r16
    1fda:	56 96       	adiw	r26, 0x16	; 22
    1fdc:	9c 91       	ld	r25, X
    1fde:	56 97       	sbiw	r26, 0x16	; 22
    1fe0:	86 89       	ldd	r24, Z+22	; 0x16
    1fe2:	89 17       	cp	r24, r25
    1fe4:	20 f4       	brcc	.+8      	; 0x1fee <xTaskRemoveFromEventList+0x8a>
		it should force a context switch now. */
		xReturn = pdTRUE;

		/* Mark that a yield is pending in case the user is not using the
		"xHigherPriorityTaskWoken" parameter to an ISR safe FreeRTOS function. */
		xYieldPending = pdTRUE;
    1fe6:	81 e0       	ldi	r24, 0x01	; 1
    1fe8:	80 93 9d 03 	sts	0x039D, r24
    1fec:	01 c0       	rjmp	.+2      	; 0x1ff0 <xTaskRemoveFromEventList+0x8c>
	}
	else
	{
		xReturn = pdFALSE;
    1fee:	80 e0       	ldi	r24, 0x00	; 0
		prvResetNextTaskUnblockTime();
	}
	#endif

	return xReturn;
}
    1ff0:	df 91       	pop	r29
    1ff2:	cf 91       	pop	r28
    1ff4:	1f 91       	pop	r17
    1ff6:	0f 91       	pop	r16
    1ff8:	08 95       	ret

00001ffa <xTaskRemoveFromUnorderedEventList>:
/*-----------------------------------------------------------*/

BaseType_t xTaskRemoveFromUnorderedEventList( ListItem_t * pxEventListItem, const TickType_t xItemValue )
{
    1ffa:	0f 93       	push	r16
    1ffc:	1f 93       	push	r17
    1ffe:	cf 93       	push	r28
    2000:	df 93       	push	r29
	/* THIS FUNCTION MUST BE CALLED WITH THE SCHEDULER SUSPENDED.  It is used by
	the event flags implementation. */
	configASSERT( uxSchedulerSuspended != pdFALSE );

	/* Store the new item value in the event list. */
	listSET_LIST_ITEM_VALUE( pxEventListItem, xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
    2002:	70 68       	ori	r23, 0x80	; 128
    2004:	fc 01       	movw	r30, r24
    2006:	71 83       	std	Z+1, r23	; 0x01
    2008:	60 83       	st	Z, r22

	/* Remove the event list form the event flag.  Interrupts do not access
	event flags. */
	pxUnblockedTCB = ( TCB_t * ) listGET_LIST_ITEM_OWNER( pxEventListItem );
    200a:	c6 81       	ldd	r28, Z+6	; 0x06
    200c:	d7 81       	ldd	r29, Z+7	; 0x07
	configASSERT( pxUnblockedTCB );
	( void ) uxListRemove( pxEventListItem );
    200e:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>

	/* Remove the task from the delayed list and add it to the ready list.  The
	scheduler is suspended so interrupts will not be accessing the ready
	lists. */
	( void ) uxListRemove( &( pxUnblockedTCB->xStateListItem ) );
    2012:	8e 01       	movw	r16, r28
    2014:	0e 5f       	subi	r16, 0xFE	; 254
    2016:	1f 4f       	sbci	r17, 0xFF	; 255
    2018:	c8 01       	movw	r24, r16
    201a:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
	prvAddTaskToReadyList( pxUnblockedTCB );
    201e:	8e 89       	ldd	r24, Y+22	; 0x16
    2020:	90 91 a0 03 	lds	r25, 0x03A0
    2024:	98 17       	cp	r25, r24
    2026:	10 f4       	brcc	.+4      	; 0x202c <xTaskRemoveFromUnorderedEventList+0x32>
    2028:	80 93 a0 03 	sts	0x03A0, r24
    202c:	90 e0       	ldi	r25, 0x00	; 0
    202e:	9c 01       	movw	r18, r24
    2030:	22 0f       	add	r18, r18
    2032:	33 1f       	adc	r19, r19
    2034:	22 0f       	add	r18, r18
    2036:	33 1f       	adc	r19, r19
    2038:	22 0f       	add	r18, r18
    203a:	33 1f       	adc	r19, r19
    203c:	82 0f       	add	r24, r18
    203e:	93 1f       	adc	r25, r19
    2040:	86 55       	subi	r24, 0x56	; 86
    2042:	9c 4f       	sbci	r25, 0xFC	; 252
    2044:	b8 01       	movw	r22, r16
    2046:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>

	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
    204a:	e0 91 97 03 	lds	r30, 0x0397
    204e:	f0 91 98 03 	lds	r31, 0x0398
    2052:	9e 89       	ldd	r25, Y+22	; 0x16
    2054:	86 89       	ldd	r24, Z+22	; 0x16
    2056:	89 17       	cp	r24, r25
    2058:	20 f4       	brcc	.+8      	; 0x2062 <xTaskRemoveFromUnorderedEventList+0x68>
		switch now. */
		xReturn = pdTRUE;

		/* Mark that a yield is pending in case the user is not using the
		"xHigherPriorityTaskWoken" parameter to an ISR safe FreeRTOS function. */
		xYieldPending = pdTRUE;
    205a:	81 e0       	ldi	r24, 0x01	; 1
    205c:	80 93 9d 03 	sts	0x039D, r24
    2060:	01 c0       	rjmp	.+2      	; 0x2064 <xTaskRemoveFromUnorderedEventList+0x6a>
	}
	else
	{
		xReturn = pdFALSE;
    2062:	80 e0       	ldi	r24, 0x00	; 0
	}

	return xReturn;
}
    2064:	df 91       	pop	r29
    2066:	cf 91       	pop	r28
    2068:	1f 91       	pop	r17
    206a:	0f 91       	pop	r16
    206c:	08 95       	ret

0000206e <vTaskSetTimeOutState>:
/*-----------------------------------------------------------*/

void vTaskSetTimeOutState( TimeOut_t * const pxTimeOut )
{
    206e:	fc 01       	movw	r30, r24
	configASSERT( pxTimeOut );
	pxTimeOut->xOverflowCount = xNumOfOverflows;
    2070:	80 91 9c 03 	lds	r24, 0x039C
    2074:	80 83       	st	Z, r24
	pxTimeOut->xTimeOnEntering = xTickCount;
    2076:	80 91 a1 03 	lds	r24, 0x03A1
    207a:	90 91 a2 03 	lds	r25, 0x03A2
    207e:	92 83       	std	Z+2, r25	; 0x02
    2080:	81 83       	std	Z+1, r24	; 0x01
}
    2082:	08 95       	ret

00002084 <xTaskCheckForTimeOut>:
/*-----------------------------------------------------------*/

BaseType_t xTaskCheckForTimeOut( TimeOut_t * const pxTimeOut, TickType_t * const pxTicksToWait )
{
    2084:	fc 01       	movw	r30, r24
    2086:	db 01       	movw	r26, r22
BaseType_t xReturn;

	configASSERT( pxTimeOut );
	configASSERT( pxTicksToWait );

	taskENTER_CRITICAL();
    2088:	0f b6       	in	r0, 0x3f	; 63
    208a:	f8 94       	cli
    208c:	0f 92       	push	r0
	{
		/* Minor optimisation.  The tick count cannot change in this block. */
		const TickType_t xConstTickCount = xTickCount;
    208e:	60 91 a1 03 	lds	r22, 0x03A1
    2092:	70 91 a2 03 	lds	r23, 0x03A2
			}
			else
		#endif

		#if ( INCLUDE_vTaskSuspend == 1 )
			if( *pxTicksToWait == portMAX_DELAY )
    2096:	4d 91       	ld	r20, X+
    2098:	5c 91       	ld	r21, X
    209a:	11 97       	sbiw	r26, 0x01	; 1
    209c:	8f ef       	ldi	r24, 0xFF	; 255
    209e:	4f 3f       	cpi	r20, 0xFF	; 255
    20a0:	58 07       	cpc	r21, r24
    20a2:	e9 f0       	breq	.+58     	; 0x20de <xTaskCheckForTimeOut+0x5a>
				xReturn = pdFALSE;
			}
			else
		#endif

		if( ( xNumOfOverflows != pxTimeOut->xOverflowCount ) && ( xConstTickCount >= pxTimeOut->xTimeOnEntering ) ) /*lint !e525 Indentation preferred as is to make code within pre-processor directives clearer. */
    20a4:	80 91 9c 03 	lds	r24, 0x039C
    20a8:	90 81       	ld	r25, Z
    20aa:	98 17       	cp	r25, r24
    20ac:	29 f0       	breq	.+10     	; 0x20b8 <xTaskCheckForTimeOut+0x34>
    20ae:	81 81       	ldd	r24, Z+1	; 0x01
    20b0:	92 81       	ldd	r25, Z+2	; 0x02
    20b2:	68 17       	cp	r22, r24
    20b4:	79 07       	cpc	r23, r25
    20b6:	a8 f4       	brcc	.+42     	; 0x20e2 <xTaskCheckForTimeOut+0x5e>
			vTaskSetTimeOut() was called.  It must have wrapped all the way
			around and gone past again. This passed since vTaskSetTimeout()
			was called. */
			xReturn = pdTRUE;
		}
		else if( ( ( TickType_t ) ( xConstTickCount - pxTimeOut->xTimeOnEntering ) ) < *pxTicksToWait ) /*lint !e961 Explicit casting is only redundant with some compilers, whereas others require it to prevent integer conversion errors. */
    20b8:	81 81       	ldd	r24, Z+1	; 0x01
    20ba:	92 81       	ldd	r25, Z+2	; 0x02
    20bc:	9b 01       	movw	r18, r22
    20be:	28 1b       	sub	r18, r24
    20c0:	39 0b       	sbc	r19, r25
    20c2:	24 17       	cp	r18, r20
    20c4:	35 07       	cpc	r19, r21
    20c6:	78 f4       	brcc	.+30     	; 0x20e6 <xTaskCheckForTimeOut+0x62>
		{
			/* Not a genuine timeout. Adjust parameters for time remaining. */
			*pxTicksToWait -= ( xConstTickCount - pxTimeOut->xTimeOnEntering );
    20c8:	86 1b       	sub	r24, r22
    20ca:	97 0b       	sbc	r25, r23
    20cc:	84 0f       	add	r24, r20
    20ce:	95 1f       	adc	r25, r21
    20d0:	8d 93       	st	X+, r24
    20d2:	9c 93       	st	X, r25
			vTaskSetTimeOutState( pxTimeOut );
    20d4:	cf 01       	movw	r24, r30
    20d6:	0e 94 37 10 	call	0x206e	; 0x206e <vTaskSetTimeOutState>
			xReturn = pdFALSE;
    20da:	80 e0       	ldi	r24, 0x00	; 0
    20dc:	05 c0       	rjmp	.+10     	; 0x20e8 <xTaskCheckForTimeOut+0x64>
			if( *pxTicksToWait == portMAX_DELAY )
			{
				/* If INCLUDE_vTaskSuspend is set to 1 and the block time
				specified is the maximum block time then the task should block
				indefinitely, and therefore never time out. */
				xReturn = pdFALSE;
    20de:	80 e0       	ldi	r24, 0x00	; 0
    20e0:	03 c0       	rjmp	.+6      	; 0x20e8 <xTaskCheckForTimeOut+0x64>
			/* The tick count is greater than the time at which
			vTaskSetTimeout() was called, but has also overflowed since
			vTaskSetTimeOut() was called.  It must have wrapped all the way
			around and gone past again. This passed since vTaskSetTimeout()
			was called. */
			xReturn = pdTRUE;
    20e2:	81 e0       	ldi	r24, 0x01	; 1
    20e4:	01 c0       	rjmp	.+2      	; 0x20e8 <xTaskCheckForTimeOut+0x64>
			vTaskSetTimeOutState( pxTimeOut );
			xReturn = pdFALSE;
		}
		else
		{
			xReturn = pdTRUE;
    20e6:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	taskEXIT_CRITICAL();
    20e8:	0f 90       	pop	r0
    20ea:	0f be       	out	0x3f, r0	; 63

	return xReturn;
}
    20ec:	08 95       	ret

000020ee <vTaskMissedYield>:
/*-----------------------------------------------------------*/

void vTaskMissedYield( void )
{
	xYieldPending = pdTRUE;
    20ee:	81 e0       	ldi	r24, 0x01	; 1
    20f0:	80 93 9d 03 	sts	0x039D, r24
}
    20f4:	08 95       	ret

000020f6 <xTaskGetCurrentTaskHandle>:
	TaskHandle_t xReturn;

		/* A critical section is not required as this is not called from
		an interrupt and the current TCB will always be the same for any
		individual execution thread. */
		xReturn = pxCurrentTCB;
    20f6:	80 91 97 03 	lds	r24, 0x0397
    20fa:	90 91 98 03 	lds	r25, 0x0398

		return xReturn;
	}
    20fe:	08 95       	ret

00002100 <vTaskPriorityInherit>:
/*-----------------------------------------------------------*/

#if ( configUSE_MUTEXES == 1 )

	void vTaskPriorityInherit( TaskHandle_t const pxMutexHolder )
	{
    2100:	0f 93       	push	r16
    2102:	1f 93       	push	r17
    2104:	cf 93       	push	r28
    2106:	df 93       	push	r29
    2108:	ec 01       	movw	r28, r24
	TCB_t * const pxTCB = ( TCB_t * ) pxMutexHolder;

		/* If the mutex was given back by an interrupt while the queue was
		locked then the mutex holder might now be NULL. */
		if( pxMutexHolder != NULL )
    210a:	00 97       	sbiw	r24, 0x00	; 0
    210c:	09 f4       	brne	.+2      	; 0x2110 <vTaskPriorityInherit+0x10>
    210e:	51 c0       	rjmp	.+162    	; 0x21b2 <vTaskPriorityInherit+0xb2>
		{
			/* If the holder of the mutex has a priority below the priority of
			the task attempting to obtain the mutex then it will temporarily
			inherit the priority of the task attempting to obtain the mutex. */
			if( pxTCB->uxPriority < pxCurrentTCB->uxPriority )
    2110:	8e 89       	ldd	r24, Y+22	; 0x16
    2112:	e0 91 97 03 	lds	r30, 0x0397
    2116:	f0 91 98 03 	lds	r31, 0x0398
    211a:	96 89       	ldd	r25, Z+22	; 0x16
    211c:	89 17       	cp	r24, r25
    211e:	08 f0       	brcs	.+2      	; 0x2122 <vTaskPriorityInherit+0x22>
    2120:	48 c0       	rjmp	.+144    	; 0x21b2 <vTaskPriorityInherit+0xb2>
			{
				/* Adjust the mutex holder state to account for its new
				priority.  Only reset the event list item value if the value is
				not	being used for anything else. */
				if( ( listGET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ) ) & taskEVENT_LIST_ITEM_VALUE_IN_USE ) == 0UL )
    2122:	2c 85       	ldd	r18, Y+12	; 0x0c
    2124:	3d 85       	ldd	r19, Y+13	; 0x0d
    2126:	33 23       	and	r19, r19
    2128:	5c f0       	brlt	.+22     	; 0x2140 <vTaskPriorityInherit+0x40>
				{
					listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxCurrentTCB->uxPriority ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    212a:	e0 91 97 03 	lds	r30, 0x0397
    212e:	f0 91 98 03 	lds	r31, 0x0398
    2132:	96 89       	ldd	r25, Z+22	; 0x16
    2134:	25 e0       	ldi	r18, 0x05	; 5
    2136:	30 e0       	ldi	r19, 0x00	; 0
    2138:	29 1b       	sub	r18, r25
    213a:	31 09       	sbc	r19, r1
    213c:	3d 87       	std	Y+13, r19	; 0x0d
    213e:	2c 87       	std	Y+12, r18	; 0x0c
					mtCOVERAGE_TEST_MARKER();
				}

				/* If the task being modified is in the ready state it will need
				to be moved into a new list. */
				if( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ pxTCB->uxPriority ] ), &( pxTCB->xStateListItem ) ) != pdFALSE )
    2140:	90 e0       	ldi	r25, 0x00	; 0
    2142:	9c 01       	movw	r18, r24
    2144:	22 0f       	add	r18, r18
    2146:	33 1f       	adc	r19, r19
    2148:	22 0f       	add	r18, r18
    214a:	33 1f       	adc	r19, r19
    214c:	22 0f       	add	r18, r18
    214e:	33 1f       	adc	r19, r19
    2150:	82 0f       	add	r24, r18
    2152:	93 1f       	adc	r25, r19
    2154:	86 55       	subi	r24, 0x56	; 86
    2156:	9c 4f       	sbci	r25, 0xFC	; 252
    2158:	2a 85       	ldd	r18, Y+10	; 0x0a
    215a:	3b 85       	ldd	r19, Y+11	; 0x0b
    215c:	28 17       	cp	r18, r24
    215e:	39 07       	cpc	r19, r25
    2160:	11 f5       	brne	.+68     	; 0x21a6 <vTaskPriorityInherit+0xa6>
				{
					if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    2162:	8e 01       	movw	r16, r28
    2164:	0e 5f       	subi	r16, 0xFE	; 254
    2166:	1f 4f       	sbci	r17, 0xFF	; 255
    2168:	c8 01       	movw	r24, r16
    216a:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
					{
						mtCOVERAGE_TEST_MARKER();
					}

					/* Inherit the priority before being moved into the new list. */
					pxTCB->uxPriority = pxCurrentTCB->uxPriority;
    216e:	e0 91 97 03 	lds	r30, 0x0397
    2172:	f0 91 98 03 	lds	r31, 0x0398
    2176:	86 89       	ldd	r24, Z+22	; 0x16
    2178:	8e 8b       	std	Y+22, r24	; 0x16
					prvAddTaskToReadyList( pxTCB );
    217a:	90 91 a0 03 	lds	r25, 0x03A0
    217e:	98 17       	cp	r25, r24
    2180:	10 f4       	brcc	.+4      	; 0x2186 <vTaskPriorityInherit+0x86>
    2182:	80 93 a0 03 	sts	0x03A0, r24
    2186:	90 e0       	ldi	r25, 0x00	; 0
    2188:	9c 01       	movw	r18, r24
    218a:	22 0f       	add	r18, r18
    218c:	33 1f       	adc	r19, r19
    218e:	22 0f       	add	r18, r18
    2190:	33 1f       	adc	r19, r19
    2192:	22 0f       	add	r18, r18
    2194:	33 1f       	adc	r19, r19
    2196:	82 0f       	add	r24, r18
    2198:	93 1f       	adc	r25, r19
    219a:	86 55       	subi	r24, 0x56	; 86
    219c:	9c 4f       	sbci	r25, 0xFC	; 252
    219e:	b8 01       	movw	r22, r16
    21a0:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
    21a4:	06 c0       	rjmp	.+12     	; 0x21b2 <vTaskPriorityInherit+0xb2>
				}
				else
				{
					/* Just inherit the priority. */
					pxTCB->uxPriority = pxCurrentTCB->uxPriority;
    21a6:	e0 91 97 03 	lds	r30, 0x0397
    21aa:	f0 91 98 03 	lds	r31, 0x0398
    21ae:	86 89       	ldd	r24, Z+22	; 0x16
    21b0:	8e 8b       	std	Y+22, r24	; 0x16
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    21b2:	df 91       	pop	r29
    21b4:	cf 91       	pop	r28
    21b6:	1f 91       	pop	r17
    21b8:	0f 91       	pop	r16
    21ba:	08 95       	ret

000021bc <xTaskPriorityDisinherit>:
/*-----------------------------------------------------------*/

#if ( configUSE_MUTEXES == 1 )

	BaseType_t xTaskPriorityDisinherit( TaskHandle_t const pxMutexHolder )
	{
    21bc:	0f 93       	push	r16
    21be:	1f 93       	push	r17
    21c0:	cf 93       	push	r28
    21c2:	df 93       	push	r29
    21c4:	ec 01       	movw	r28, r24
	TCB_t * const pxTCB = ( TCB_t * ) pxMutexHolder;
	BaseType_t xReturn = pdFALSE;

		if( pxMutexHolder != NULL )
    21c6:	00 97       	sbiw	r24, 0x00	; 0
    21c8:	81 f1       	breq	.+96     	; 0x222a <xTaskPriorityDisinherit+0x6e>
			interrupt, and if a mutex is given by the holding task then it must
			be the running state task. */
			configASSERT( pxTCB == pxCurrentTCB );

			configASSERT( pxTCB->uxMutexesHeld );
			( pxTCB->uxMutexesHeld )--;
    21ca:	8c a1       	lds	r24, 0x4c
    21cc:	81 50       	subi	r24, 0x01	; 1
    21ce:	8c a3       	lds	r24, 0x5c

			/* Has the holder of the mutex inherited the priority of another
			task? */
			if( pxTCB->uxPriority != pxTCB->uxBasePriority )
    21d0:	2e 89       	ldd	r18, Y+22	; 0x16
    21d2:	9b a1       	lds	r25, 0x4b
    21d4:	29 17       	cp	r18, r25
    21d6:	59 f1       	breq	.+86     	; 0x222e <xTaskPriorityDisinherit+0x72>
			{
				/* Only disinherit if no other mutexes are held. */
				if( pxTCB->uxMutexesHeld == ( UBaseType_t ) 0 )
    21d8:	88 23       	and	r24, r24
    21da:	59 f5       	brne	.+86     	; 0x2232 <xTaskPriorityDisinherit+0x76>
					/* A task can only have an inherited priority if it holds
					the mutex.  If the mutex is held by a task then it cannot be
					given from an interrupt, and if a mutex is given by the
					holding	task then it must be the running state task.  Remove
					the	holding task from the ready	list. */
					if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    21dc:	8e 01       	movw	r16, r28
    21de:	0e 5f       	subi	r16, 0xFE	; 254
    21e0:	1f 4f       	sbci	r17, 0xFF	; 255
    21e2:	c8 01       	movw	r24, r16
    21e4:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
					}

					/* Disinherit the priority before adding the task into the
					new	ready list. */
					traceTASK_PRIORITY_DISINHERIT( pxTCB, pxTCB->uxBasePriority );
					pxTCB->uxPriority = pxTCB->uxBasePriority;
    21e8:	4b a1       	lds	r20, 0x4b
    21ea:	4e 8b       	std	Y+22, r20	; 0x16

					/* Reset the event list item value.  It cannot be in use for
					any other purpose if this task is running, and it must be
					running to give back the mutex. */
					listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxTCB->uxPriority ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    21ec:	24 2f       	mov	r18, r20
    21ee:	30 e0       	ldi	r19, 0x00	; 0
    21f0:	85 e0       	ldi	r24, 0x05	; 5
    21f2:	90 e0       	ldi	r25, 0x00	; 0
    21f4:	82 1b       	sub	r24, r18
    21f6:	93 0b       	sbc	r25, r19
    21f8:	9d 87       	std	Y+13, r25	; 0x0d
    21fa:	8c 87       	std	Y+12, r24	; 0x0c
					prvAddTaskToReadyList( pxTCB );
    21fc:	80 91 a0 03 	lds	r24, 0x03A0
    2200:	84 17       	cp	r24, r20
    2202:	10 f4       	brcc	.+4      	; 0x2208 <xTaskPriorityDisinherit+0x4c>
    2204:	40 93 a0 03 	sts	0x03A0, r20
    2208:	c9 01       	movw	r24, r18
    220a:	88 0f       	add	r24, r24
    220c:	99 1f       	adc	r25, r25
    220e:	88 0f       	add	r24, r24
    2210:	99 1f       	adc	r25, r25
    2212:	88 0f       	add	r24, r24
    2214:	99 1f       	adc	r25, r25
    2216:	28 0f       	add	r18, r24
    2218:	39 1f       	adc	r19, r25
    221a:	c9 01       	movw	r24, r18
    221c:	86 55       	subi	r24, 0x56	; 86
    221e:	9c 4f       	sbci	r25, 0xFC	; 252
    2220:	b8 01       	movw	r22, r16
    2222:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
					in an order different to that in which they were taken.
					If a context switch did not occur when the first mutex was
					returned, even if a task was waiting on it, then a context
					switch should occur when the last mutex is returned whether
					a task is waiting on it or not. */
					xReturn = pdTRUE;
    2226:	81 e0       	ldi	r24, 0x01	; 1
    2228:	05 c0       	rjmp	.+10     	; 0x2234 <xTaskPriorityDisinherit+0x78>
#if ( configUSE_MUTEXES == 1 )

	BaseType_t xTaskPriorityDisinherit( TaskHandle_t const pxMutexHolder )
	{
	TCB_t * const pxTCB = ( TCB_t * ) pxMutexHolder;
	BaseType_t xReturn = pdFALSE;
    222a:	80 e0       	ldi	r24, 0x00	; 0
    222c:	03 c0       	rjmp	.+6      	; 0x2234 <xTaskPriorityDisinherit+0x78>
    222e:	80 e0       	ldi	r24, 0x00	; 0
    2230:	01 c0       	rjmp	.+2      	; 0x2234 <xTaskPriorityDisinherit+0x78>
    2232:	80 e0       	ldi	r24, 0x00	; 0
		{
			mtCOVERAGE_TEST_MARKER();
		}

		return xReturn;
	}
    2234:	df 91       	pop	r29
    2236:	cf 91       	pop	r28
    2238:	1f 91       	pop	r17
    223a:	0f 91       	pop	r16
    223c:	08 95       	ret

0000223e <uxTaskResetEventItemValue>:

TickType_t uxTaskResetEventItemValue( void )
{
TickType_t uxReturn;

	uxReturn = listGET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ) );
    223e:	e0 91 97 03 	lds	r30, 0x0397
    2242:	f0 91 98 03 	lds	r31, 0x0398
    2246:	84 85       	ldd	r24, Z+12	; 0x0c
    2248:	95 85       	ldd	r25, Z+13	; 0x0d

	/* Reset the event list item to its normal value - so it can be used with
	queues and semaphores. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), ( ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxCurrentTCB->uxPriority ) ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    224a:	e0 91 97 03 	lds	r30, 0x0397
    224e:	f0 91 98 03 	lds	r31, 0x0398
    2252:	a0 91 97 03 	lds	r26, 0x0397
    2256:	b0 91 98 03 	lds	r27, 0x0398
    225a:	56 96       	adiw	r26, 0x16	; 22
    225c:	4c 91       	ld	r20, X
    225e:	56 97       	sbiw	r26, 0x16	; 22
    2260:	25 e0       	ldi	r18, 0x05	; 5
    2262:	30 e0       	ldi	r19, 0x00	; 0
    2264:	24 1b       	sub	r18, r20
    2266:	31 09       	sbc	r19, r1
    2268:	35 87       	std	Z+13, r19	; 0x0d
    226a:	24 87       	std	Z+12, r18	; 0x0c

	return uxReturn;
}
    226c:	08 95       	ret

0000226e <pvTaskIncrementMutexHeldCount>:

	void *pvTaskIncrementMutexHeldCount( void )
	{
		/* If xSemaphoreCreateMutex() is called before any tasks have been created
		then pxCurrentTCB will be NULL. */
		if( pxCurrentTCB != NULL )
    226e:	80 91 97 03 	lds	r24, 0x0397
    2272:	90 91 98 03 	lds	r25, 0x0398
    2276:	00 97       	sbiw	r24, 0x00	; 0
    2278:	39 f0       	breq	.+14     	; 0x2288 <pvTaskIncrementMutexHeldCount+0x1a>
		{
			( pxCurrentTCB->uxMutexesHeld )++;
    227a:	e0 91 97 03 	lds	r30, 0x0397
    227e:	f0 91 98 03 	lds	r31, 0x0398
    2282:	84 a1       	lds	r24, 0x44
    2284:	8f 5f       	subi	r24, 0xFF	; 255
    2286:	84 a3       	lds	r24, 0x54
		}

		return pxCurrentTCB;
    2288:	80 91 97 03 	lds	r24, 0x0397
    228c:	90 91 98 03 	lds	r25, 0x0398
	}
    2290:	08 95       	ret

00002292 <ulTaskNotifyTake>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	uint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t xTicksToWait )
	{
    2292:	0f 93       	push	r16
    2294:	1f 93       	push	r17
    2296:	cf 93       	push	r28
    2298:	c8 2f       	mov	r28, r24
	uint32_t ulReturn;

		taskENTER_CRITICAL();
    229a:	0f b6       	in	r0, 0x3f	; 63
    229c:	f8 94       	cli
    229e:	0f 92       	push	r0
		{
			/* Only block if the notification count is not already non-zero. */
			if( pxCurrentTCB->ulNotifiedValue == 0UL )
    22a0:	e0 91 97 03 	lds	r30, 0x0397
    22a4:	f0 91 98 03 	lds	r31, 0x0398
    22a8:	85 a1       	lds	r24, 0x45
    22aa:	96 a1       	lds	r25, 0x46
    22ac:	a7 a1       	lds	r26, 0x47
    22ae:	b0 a5       	lds	r27, 0x60
    22b0:	00 97       	sbiw	r24, 0x00	; 0
    22b2:	a1 05       	cpc	r26, r1
    22b4:	b1 05       	cpc	r27, r1
    22b6:	79 f4       	brne	.+30     	; 0x22d6 <ulTaskNotifyTake+0x44>
			{
				/* Mark this task as waiting for a notification. */
				pxCurrentTCB->ucNotifyState = taskWAITING_NOTIFICATION;
    22b8:	e0 91 97 03 	lds	r30, 0x0397
    22bc:	f0 91 98 03 	lds	r31, 0x0398
    22c0:	81 e0       	ldi	r24, 0x01	; 1
    22c2:	81 a7       	lds	r24, 0x71

				if( xTicksToWait > ( TickType_t ) 0 )
    22c4:	61 15       	cp	r22, r1
    22c6:	71 05       	cpc	r23, r1
    22c8:	31 f0       	breq	.+12     	; 0x22d6 <ulTaskNotifyTake+0x44>
				{
					prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    22ca:	cb 01       	movw	r24, r22
    22cc:	61 e0       	ldi	r22, 0x01	; 1
    22ce:	0e 94 c5 09 	call	0x138a	; 0x138a <prvAddCurrentTaskToDelayedList>

					/* All ports are written to allow a yield in a critical
					section (some will yield immediately, others wait until the
					critical section exits) - but it is not something that
					application code should ever do. */
					portYIELD_WITHIN_API();
    22d2:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    22d6:	0f 90       	pop	r0
    22d8:	0f be       	out	0x3f, r0	; 63

		taskENTER_CRITICAL();
    22da:	0f b6       	in	r0, 0x3f	; 63
    22dc:	f8 94       	cli
    22de:	0f 92       	push	r0
		{
			traceTASK_NOTIFY_TAKE();
			ulReturn = pxCurrentTCB->ulNotifiedValue;
    22e0:	e0 91 97 03 	lds	r30, 0x0397
    22e4:	f0 91 98 03 	lds	r31, 0x0398
    22e8:	05 a1       	lds	r16, 0x45
    22ea:	16 a1       	lds	r17, 0x46
    22ec:	27 a1       	lds	r18, 0x47
    22ee:	30 a5       	lds	r19, 0x60

			if( ulReturn != 0UL )
    22f0:	01 15       	cp	r16, r1
    22f2:	11 05       	cpc	r17, r1
    22f4:	21 05       	cpc	r18, r1
    22f6:	31 05       	cpc	r19, r1
    22f8:	c1 f0       	breq	.+48     	; 0x232a <ulTaskNotifyTake+0x98>
			{
				if( xClearCountOnExit != pdFALSE )
    22fa:	cc 23       	and	r28, r28
    22fc:	49 f0       	breq	.+18     	; 0x2310 <ulTaskNotifyTake+0x7e>
				{
					pxCurrentTCB->ulNotifiedValue = 0UL;
    22fe:	e0 91 97 03 	lds	r30, 0x0397
    2302:	f0 91 98 03 	lds	r31, 0x0398
    2306:	15 a2       	lds	r17, 0x95
    2308:	16 a2       	lds	r17, 0x96
    230a:	17 a2       	lds	r17, 0x97
    230c:	10 a6       	lds	r17, 0xb0
    230e:	0d c0       	rjmp	.+26     	; 0x232a <ulTaskNotifyTake+0x98>
				}
				else
				{
					pxCurrentTCB->ulNotifiedValue = ulReturn - 1;
    2310:	e0 91 97 03 	lds	r30, 0x0397
    2314:	f0 91 98 03 	lds	r31, 0x0398
    2318:	d9 01       	movw	r26, r18
    231a:	c8 01       	movw	r24, r16
    231c:	01 97       	sbiw	r24, 0x01	; 1
    231e:	a1 09       	sbc	r26, r1
    2320:	b1 09       	sbc	r27, r1
    2322:	85 a3       	lds	r24, 0x55
    2324:	96 a3       	lds	r25, 0x56
    2326:	a7 a3       	lds	r26, 0x57
    2328:	b0 a7       	lds	r27, 0x70
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			pxCurrentTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    232a:	e0 91 97 03 	lds	r30, 0x0397
    232e:	f0 91 98 03 	lds	r31, 0x0398
    2332:	11 a6       	lds	r17, 0xb1
		}
		taskEXIT_CRITICAL();
    2334:	0f 90       	pop	r0
    2336:	0f be       	out	0x3f, r0	; 63

		return ulReturn;
	}
    2338:	60 2f       	mov	r22, r16
    233a:	71 2f       	mov	r23, r17
    233c:	82 2f       	mov	r24, r18
    233e:	93 2f       	mov	r25, r19
    2340:	cf 91       	pop	r28
    2342:	1f 91       	pop	r17
    2344:	0f 91       	pop	r16
    2346:	08 95       	ret

00002348 <xTaskNotifyWait>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskNotifyWait( uint32_t ulBitsToClearOnEntry, uint32_t ulBitsToClearOnExit, uint32_t *pulNotificationValue, TickType_t xTicksToWait )
	{
    2348:	8f 92       	push	r8
    234a:	9f 92       	push	r9
    234c:	af 92       	push	r10
    234e:	bf 92       	push	r11
    2350:	ef 92       	push	r14
    2352:	ff 92       	push	r15
    2354:	0f 93       	push	r16
    2356:	1f 93       	push	r17
    2358:	dc 01       	movw	r26, r24
    235a:	cb 01       	movw	r24, r22
    235c:	49 01       	movw	r8, r18
    235e:	5a 01       	movw	r10, r20
	BaseType_t xReturn;

		taskENTER_CRITICAL();
    2360:	0f b6       	in	r0, 0x3f	; 63
    2362:	f8 94       	cli
    2364:	0f 92       	push	r0
		{
			/* Only block if a notification is not already pending. */
			if( pxCurrentTCB->ucNotifyState != taskNOTIFICATION_RECEIVED )
    2366:	e0 91 97 03 	lds	r30, 0x0397
    236a:	f0 91 98 03 	lds	r31, 0x0398
    236e:	21 a5       	lds	r18, 0x61
    2370:	22 30       	cpi	r18, 0x02	; 2
    2372:	19 f1       	breq	.+70     	; 0x23ba <xTaskNotifyWait+0x72>
			{
				/* Clear bits in the task's notification value as bits may get
				set	by the notifying task or interrupt.  This can be used to
				clear the value to zero. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnEntry;
    2374:	e0 91 97 03 	lds	r30, 0x0397
    2378:	f0 91 98 03 	lds	r31, 0x0398
    237c:	45 a1       	lds	r20, 0x45
    237e:	56 a1       	lds	r21, 0x46
    2380:	67 a1       	lds	r22, 0x47
    2382:	70 a5       	lds	r23, 0x60
    2384:	80 95       	com	r24
    2386:	90 95       	com	r25
    2388:	a0 95       	com	r26
    238a:	b0 95       	com	r27
    238c:	84 23       	and	r24, r20
    238e:	95 23       	and	r25, r21
    2390:	a6 23       	and	r26, r22
    2392:	b7 23       	and	r27, r23
    2394:	85 a3       	lds	r24, 0x55
    2396:	96 a3       	lds	r25, 0x56
    2398:	a7 a3       	lds	r26, 0x57
    239a:	b0 a7       	lds	r27, 0x70

				/* Mark this task as waiting for a notification. */
				pxCurrentTCB->ucNotifyState = taskWAITING_NOTIFICATION;
    239c:	e0 91 97 03 	lds	r30, 0x0397
    23a0:	f0 91 98 03 	lds	r31, 0x0398
    23a4:	81 e0       	ldi	r24, 0x01	; 1
    23a6:	81 a7       	lds	r24, 0x71

				if( xTicksToWait > ( TickType_t ) 0 )
    23a8:	e1 14       	cp	r14, r1
    23aa:	f1 04       	cpc	r15, r1
    23ac:	31 f0       	breq	.+12     	; 0x23ba <xTaskNotifyWait+0x72>
				{
					prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    23ae:	c7 01       	movw	r24, r14
    23b0:	61 e0       	ldi	r22, 0x01	; 1
    23b2:	0e 94 c5 09 	call	0x138a	; 0x138a <prvAddCurrentTaskToDelayedList>

					/* All ports are written to allow a yield in a critical
					section (some will yield immediately, others wait until the
					critical section exits) - but it is not something that
					application code should ever do. */
					portYIELD_WITHIN_API();
    23b6:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    23ba:	0f 90       	pop	r0
    23bc:	0f be       	out	0x3f, r0	; 63

		taskENTER_CRITICAL();
    23be:	0f b6       	in	r0, 0x3f	; 63
    23c0:	f8 94       	cli
    23c2:	0f 92       	push	r0
		{
			traceTASK_NOTIFY_WAIT();

			if( pulNotificationValue != NULL )
    23c4:	01 15       	cp	r16, r1
    23c6:	11 05       	cpc	r17, r1
    23c8:	69 f0       	breq	.+26     	; 0x23e4 <xTaskNotifyWait+0x9c>
			{
				/* Output the current notification value, which may or may not
				have changed. */
				*pulNotificationValue = pxCurrentTCB->ulNotifiedValue;
    23ca:	e0 91 97 03 	lds	r30, 0x0397
    23ce:	f0 91 98 03 	lds	r31, 0x0398
    23d2:	85 a1       	lds	r24, 0x45
    23d4:	96 a1       	lds	r25, 0x46
    23d6:	a7 a1       	lds	r26, 0x47
    23d8:	b0 a5       	lds	r27, 0x60
    23da:	f8 01       	movw	r30, r16
    23dc:	80 83       	st	Z, r24
    23de:	91 83       	std	Z+1, r25	; 0x01
    23e0:	a2 83       	std	Z+2, r26	; 0x02
    23e2:	b3 83       	std	Z+3, r27	; 0x03

			/* If ucNotifyValue is set then either the task never entered the
			blocked state (because a notification was already pending) or the
			task unblocked because of a notification.  Otherwise the task
			unblocked because of a timeout. */
			if( pxCurrentTCB->ucNotifyState == taskWAITING_NOTIFICATION )
    23e4:	e0 91 97 03 	lds	r30, 0x0397
    23e8:	f0 91 98 03 	lds	r31, 0x0398
    23ec:	81 a5       	lds	r24, 0x61
    23ee:	81 30       	cpi	r24, 0x01	; 1
    23f0:	b1 f0       	breq	.+44     	; 0x241e <xTaskNotifyWait+0xd6>
			}
			else
			{
				/* A notification was already pending or a notification was
				received while the task was waiting. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnExit;
    23f2:	e0 91 97 03 	lds	r30, 0x0397
    23f6:	f0 91 98 03 	lds	r31, 0x0398
    23fa:	85 a1       	lds	r24, 0x45
    23fc:	96 a1       	lds	r25, 0x46
    23fe:	a7 a1       	lds	r26, 0x47
    2400:	b0 a5       	lds	r27, 0x60
    2402:	80 94       	com	r8
    2404:	90 94       	com	r9
    2406:	a0 94       	com	r10
    2408:	b0 94       	com	r11
    240a:	88 22       	and	r8, r24
    240c:	99 22       	and	r9, r25
    240e:	aa 22       	and	r10, r26
    2410:	bb 22       	and	r11, r27
    2412:	85 a2       	lds	r24, 0x95
    2414:	96 a2       	lds	r25, 0x96
    2416:	a7 a2       	lds	r26, 0x97
    2418:	b0 a6       	lds	r27, 0xb0
				xReturn = pdTRUE;
    241a:	81 e0       	ldi	r24, 0x01	; 1
    241c:	01 c0       	rjmp	.+2      	; 0x2420 <xTaskNotifyWait+0xd8>
			task unblocked because of a notification.  Otherwise the task
			unblocked because of a timeout. */
			if( pxCurrentTCB->ucNotifyState == taskWAITING_NOTIFICATION )
			{
				/* A notification was not received. */
				xReturn = pdFALSE;
    241e:	80 e0       	ldi	r24, 0x00	; 0
				received while the task was waiting. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnExit;
				xReturn = pdTRUE;
			}

			pxCurrentTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    2420:	e0 91 97 03 	lds	r30, 0x0397
    2424:	f0 91 98 03 	lds	r31, 0x0398
    2428:	11 a6       	lds	r17, 0xb1
		}
		taskEXIT_CRITICAL();
    242a:	0f 90       	pop	r0
    242c:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    242e:	1f 91       	pop	r17
    2430:	0f 91       	pop	r16
    2432:	ff 90       	pop	r15
    2434:	ef 90       	pop	r14
    2436:	bf 90       	pop	r11
    2438:	af 90       	pop	r10
    243a:	9f 90       	pop	r9
    243c:	8f 90       	pop	r8
    243e:	08 95       	ret

00002440 <xTaskGenericNotify>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskGenericNotify( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue )
	{
    2440:	0f 93       	push	r16
    2442:	1f 93       	push	r17
    2444:	cf 93       	push	r28
    2446:	df 93       	push	r29
    2448:	ec 01       	movw	r28, r24
	uint8_t ucOriginalNotifyState;

		configASSERT( xTaskToNotify );
		pxTCB = ( TCB_t * ) xTaskToNotify;

		taskENTER_CRITICAL();
    244a:	0f b6       	in	r0, 0x3f	; 63
    244c:	f8 94       	cli
    244e:	0f 92       	push	r0
		{
			if( pulPreviousNotificationValue != NULL )
    2450:	01 15       	cp	r16, r1
    2452:	11 05       	cpc	r17, r1
    2454:	49 f0       	breq	.+18     	; 0x2468 <xTaskGenericNotify+0x28>
			{
				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
    2456:	8d a1       	lds	r24, 0x4d
    2458:	9e a1       	lds	r25, 0x4e
    245a:	af a1       	lds	r26, 0x4f
    245c:	b8 a5       	lds	r27, 0x68
    245e:	f8 01       	movw	r30, r16
    2460:	80 83       	st	Z, r24
    2462:	91 83       	std	Z+1, r25	; 0x01
    2464:	a2 83       	std	Z+2, r26	; 0x02
    2466:	b3 83       	std	Z+3, r27	; 0x03
			}

			ucOriginalNotifyState = pxTCB->ucNotifyState;
    2468:	39 a5       	lds	r19, 0x69

			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
    246a:	82 e0       	ldi	r24, 0x02	; 2
    246c:	89 a7       	lds	r24, 0x79

			switch( eAction )
    246e:	22 30       	cpi	r18, 0x02	; 2
    2470:	b9 f0       	breq	.+46     	; 0x24a0 <xTaskGenericNotify+0x60>
    2472:	23 30       	cpi	r18, 0x03	; 3
    2474:	18 f4       	brcc	.+6      	; 0x247c <xTaskGenericNotify+0x3c>
    2476:	21 30       	cpi	r18, 0x01	; 1
    2478:	51 f5       	brne	.+84     	; 0x24ce <xTaskGenericNotify+0x8e>
    247a:	05 c0       	rjmp	.+10     	; 0x2486 <xTaskGenericNotify+0x46>
    247c:	23 30       	cpi	r18, 0x03	; 3
    247e:	e1 f0       	breq	.+56     	; 0x24b8 <xTaskGenericNotify+0x78>
    2480:	24 30       	cpi	r18, 0x04	; 4
    2482:	29 f5       	brne	.+74     	; 0x24ce <xTaskGenericNotify+0x8e>
    2484:	1e c0       	rjmp	.+60     	; 0x24c2 <xTaskGenericNotify+0x82>
			{
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
    2486:	8d a1       	lds	r24, 0x4d
    2488:	9e a1       	lds	r25, 0x4e
    248a:	af a1       	lds	r26, 0x4f
    248c:	b8 a5       	lds	r27, 0x68
    248e:	48 2b       	or	r20, r24
    2490:	59 2b       	or	r21, r25
    2492:	6a 2b       	or	r22, r26
    2494:	7b 2b       	or	r23, r27
    2496:	4d a3       	lds	r20, 0x5d
    2498:	5e a3       	lds	r21, 0x5e
    249a:	6f a3       	lds	r22, 0x5f
    249c:	78 a7       	lds	r23, 0x78
					break;
    249e:	17 c0       	rjmp	.+46     	; 0x24ce <xTaskGenericNotify+0x8e>

				case eIncrement	:
					( pxTCB->ulNotifiedValue )++;
    24a0:	8d a1       	lds	r24, 0x4d
    24a2:	9e a1       	lds	r25, 0x4e
    24a4:	af a1       	lds	r26, 0x4f
    24a6:	b8 a5       	lds	r27, 0x68
    24a8:	01 96       	adiw	r24, 0x01	; 1
    24aa:	a1 1d       	adc	r26, r1
    24ac:	b1 1d       	adc	r27, r1
    24ae:	8d a3       	lds	r24, 0x5d
    24b0:	9e a3       	lds	r25, 0x5e
    24b2:	af a3       	lds	r26, 0x5f
    24b4:	b8 a7       	lds	r27, 0x78
					break;
    24b6:	0b c0       	rjmp	.+22     	; 0x24ce <xTaskGenericNotify+0x8e>

				case eSetValueWithOverwrite	:
					pxTCB->ulNotifiedValue = ulValue;
    24b8:	4d a3       	lds	r20, 0x5d
    24ba:	5e a3       	lds	r21, 0x5e
    24bc:	6f a3       	lds	r22, 0x5f
    24be:	78 a7       	lds	r23, 0x78
					break;
    24c0:	06 c0       	rjmp	.+12     	; 0x24ce <xTaskGenericNotify+0x8e>

				case eSetValueWithoutOverwrite :
					if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )
    24c2:	32 30       	cpi	r19, 0x02	; 2
    24c4:	71 f1       	breq	.+92     	; 0x2522 <xTaskGenericNotify+0xe2>
					{
						pxTCB->ulNotifiedValue = ulValue;
    24c6:	4d a3       	lds	r20, 0x5d
    24c8:	5e a3       	lds	r21, 0x5e
    24ca:	6f a3       	lds	r22, 0x5f
    24cc:	78 a7       	lds	r23, 0x78

			traceTASK_NOTIFY();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    24ce:	31 30       	cpi	r19, 0x01	; 1
    24d0:	51 f5       	brne	.+84     	; 0x2526 <xTaskGenericNotify+0xe6>
			{
				( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    24d2:	8e 01       	movw	r16, r28
    24d4:	0e 5f       	subi	r16, 0xFE	; 254
    24d6:	1f 4f       	sbci	r17, 0xFF	; 255
    24d8:	c8 01       	movw	r24, r16
    24da:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
				prvAddTaskToReadyList( pxTCB );
    24de:	8e 89       	ldd	r24, Y+22	; 0x16
    24e0:	90 91 a0 03 	lds	r25, 0x03A0
    24e4:	98 17       	cp	r25, r24
    24e6:	10 f4       	brcc	.+4      	; 0x24ec <xTaskGenericNotify+0xac>
    24e8:	80 93 a0 03 	sts	0x03A0, r24
    24ec:	90 e0       	ldi	r25, 0x00	; 0
    24ee:	9c 01       	movw	r18, r24
    24f0:	22 0f       	add	r18, r18
    24f2:	33 1f       	adc	r19, r19
    24f4:	22 0f       	add	r18, r18
    24f6:	33 1f       	adc	r19, r19
    24f8:	22 0f       	add	r18, r18
    24fa:	33 1f       	adc	r19, r19
    24fc:	82 0f       	add	r24, r18
    24fe:	93 1f       	adc	r25, r19
    2500:	86 55       	subi	r24, 0x56	; 86
    2502:	9c 4f       	sbci	r25, 0xFC	; 252
    2504:	b8 01       	movw	r22, r16
    2506:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
					earliest possible time. */
					prvResetNextTaskUnblockTime();
				}
				#endif

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    250a:	e0 91 97 03 	lds	r30, 0x0397
    250e:	f0 91 98 03 	lds	r31, 0x0398
    2512:	9e 89       	ldd	r25, Y+22	; 0x16
    2514:	86 89       	ldd	r24, Z+22	; 0x16
    2516:	89 17       	cp	r24, r25
    2518:	40 f4       	brcc	.+16     	; 0x252a <xTaskGenericNotify+0xea>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					taskYIELD_IF_USING_PREEMPTION();
    251a:	0e 94 1c 04 	call	0x838	; 0x838 <vPortYield>
    251e:	81 e0       	ldi	r24, 0x01	; 1
    2520:	05 c0       	rjmp	.+10     	; 0x252c <xTaskGenericNotify+0xec>
						pxTCB->ulNotifiedValue = ulValue;
					}
					else
					{
						/* The value could not be written to the task. */
						xReturn = pdFAIL;
    2522:	80 e0       	ldi	r24, 0x00	; 0
    2524:	03 c0       	rjmp	.+6      	; 0x252c <xTaskGenericNotify+0xec>

			traceTASK_NOTIFY();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    2526:	81 e0       	ldi	r24, 0x01	; 1
    2528:	01 c0       	rjmp	.+2      	; 0x252c <xTaskGenericNotify+0xec>
					earliest possible time. */
					prvResetNextTaskUnblockTime();
				}
				#endif

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    252a:	81 e0       	ldi	r24, 0x01	; 1
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    252c:	0f 90       	pop	r0
    252e:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    2530:	df 91       	pop	r29
    2532:	cf 91       	pop	r28
    2534:	1f 91       	pop	r17
    2536:	0f 91       	pop	r16
    2538:	08 95       	ret

0000253a <xTaskGenericNotifyFromISR>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskGenericNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue, BaseType_t *pxHigherPriorityTaskWoken )
	{
    253a:	ef 92       	push	r14
    253c:	ff 92       	push	r15
    253e:	0f 93       	push	r16
    2540:	1f 93       	push	r17
    2542:	cf 93       	push	r28
    2544:	df 93       	push	r29
    2546:	ec 01       	movw	r28, r24

		pxTCB = ( TCB_t * ) xTaskToNotify;

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			if( pulPreviousNotificationValue != NULL )
    2548:	01 15       	cp	r16, r1
    254a:	11 05       	cpc	r17, r1
    254c:	49 f0       	breq	.+18     	; 0x2560 <xTaskGenericNotifyFromISR+0x26>
			{
				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
    254e:	8d a1       	lds	r24, 0x4d
    2550:	9e a1       	lds	r25, 0x4e
    2552:	af a1       	lds	r26, 0x4f
    2554:	b8 a5       	lds	r27, 0x68
    2556:	f8 01       	movw	r30, r16
    2558:	80 83       	st	Z, r24
    255a:	91 83       	std	Z+1, r25	; 0x01
    255c:	a2 83       	std	Z+2, r26	; 0x02
    255e:	b3 83       	std	Z+3, r27	; 0x03
			}

			ucOriginalNotifyState = pxTCB->ucNotifyState;
    2560:	39 a5       	lds	r19, 0x69
			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
    2562:	82 e0       	ldi	r24, 0x02	; 2
    2564:	89 a7       	lds	r24, 0x79

			switch( eAction )
    2566:	22 30       	cpi	r18, 0x02	; 2
    2568:	b9 f0       	breq	.+46     	; 0x2598 <xTaskGenericNotifyFromISR+0x5e>
    256a:	23 30       	cpi	r18, 0x03	; 3
    256c:	18 f4       	brcc	.+6      	; 0x2574 <xTaskGenericNotifyFromISR+0x3a>
    256e:	21 30       	cpi	r18, 0x01	; 1
    2570:	59 f5       	brne	.+86     	; 0x25c8 <xTaskGenericNotifyFromISR+0x8e>
    2572:	05 c0       	rjmp	.+10     	; 0x257e <xTaskGenericNotifyFromISR+0x44>
    2574:	23 30       	cpi	r18, 0x03	; 3
    2576:	e1 f0       	breq	.+56     	; 0x25b0 <xTaskGenericNotifyFromISR+0x76>
    2578:	24 30       	cpi	r18, 0x04	; 4
    257a:	31 f5       	brne	.+76     	; 0x25c8 <xTaskGenericNotifyFromISR+0x8e>
    257c:	1e c0       	rjmp	.+60     	; 0x25ba <xTaskGenericNotifyFromISR+0x80>
			{
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
    257e:	8d a1       	lds	r24, 0x4d
    2580:	9e a1       	lds	r25, 0x4e
    2582:	af a1       	lds	r26, 0x4f
    2584:	b8 a5       	lds	r27, 0x68
    2586:	84 2b       	or	r24, r20
    2588:	95 2b       	or	r25, r21
    258a:	a6 2b       	or	r26, r22
    258c:	b7 2b       	or	r27, r23
    258e:	8d a3       	lds	r24, 0x5d
    2590:	9e a3       	lds	r25, 0x5e
    2592:	af a3       	lds	r26, 0x5f
    2594:	b8 a7       	lds	r27, 0x78
					break;
    2596:	18 c0       	rjmp	.+48     	; 0x25c8 <xTaskGenericNotifyFromISR+0x8e>

				case eIncrement	:
					( pxTCB->ulNotifiedValue )++;
    2598:	8d a1       	lds	r24, 0x4d
    259a:	9e a1       	lds	r25, 0x4e
    259c:	af a1       	lds	r26, 0x4f
    259e:	b8 a5       	lds	r27, 0x68
    25a0:	01 96       	adiw	r24, 0x01	; 1
    25a2:	a1 1d       	adc	r26, r1
    25a4:	b1 1d       	adc	r27, r1
    25a6:	8d a3       	lds	r24, 0x5d
    25a8:	9e a3       	lds	r25, 0x5e
    25aa:	af a3       	lds	r26, 0x5f
    25ac:	b8 a7       	lds	r27, 0x78
					break;
    25ae:	0c c0       	rjmp	.+24     	; 0x25c8 <xTaskGenericNotifyFromISR+0x8e>

				case eSetValueWithOverwrite	:
					pxTCB->ulNotifiedValue = ulValue;
    25b0:	4d a3       	lds	r20, 0x5d
    25b2:	5e a3       	lds	r21, 0x5e
    25b4:	6f a3       	lds	r22, 0x5f
    25b6:	78 a7       	lds	r23, 0x78
					break;
    25b8:	07 c0       	rjmp	.+14     	; 0x25c8 <xTaskGenericNotifyFromISR+0x8e>

				case eSetValueWithoutOverwrite :
					if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )
    25ba:	32 30       	cpi	r19, 0x02	; 2
    25bc:	09 f4       	brne	.+2      	; 0x25c0 <xTaskGenericNotifyFromISR+0x86>
    25be:	41 c0       	rjmp	.+130    	; 0x2642 <xTaskGenericNotifyFromISR+0x108>
					{
						pxTCB->ulNotifiedValue = ulValue;
    25c0:	4d a3       	lds	r20, 0x5d
    25c2:	5e a3       	lds	r21, 0x5e
    25c4:	6f a3       	lds	r22, 0x5f
    25c6:	78 a7       	lds	r23, 0x78

			traceTASK_NOTIFY_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    25c8:	31 30       	cpi	r19, 0x01	; 1
    25ca:	e9 f5       	brne	.+122    	; 0x2646 <xTaskGenericNotifyFromISR+0x10c>
			{
				/* The task should not have been on an event list. */
				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );

				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    25cc:	80 91 99 03 	lds	r24, 0x0399
    25d0:	88 23       	and	r24, r24
    25d2:	e9 f4       	brne	.+58     	; 0x260e <xTaskGenericNotifyFromISR+0xd4>
				{
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    25d4:	8e 01       	movw	r16, r28
    25d6:	0e 5f       	subi	r16, 0xFE	; 254
    25d8:	1f 4f       	sbci	r17, 0xFF	; 255
    25da:	c8 01       	movw	r24, r16
    25dc:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    25e0:	8e 89       	ldd	r24, Y+22	; 0x16
    25e2:	90 91 a0 03 	lds	r25, 0x03A0
    25e6:	98 17       	cp	r25, r24
    25e8:	10 f4       	brcc	.+4      	; 0x25ee <xTaskGenericNotifyFromISR+0xb4>
    25ea:	80 93 a0 03 	sts	0x03A0, r24
    25ee:	90 e0       	ldi	r25, 0x00	; 0
    25f0:	9c 01       	movw	r18, r24
    25f2:	22 0f       	add	r18, r18
    25f4:	33 1f       	adc	r19, r19
    25f6:	22 0f       	add	r18, r18
    25f8:	33 1f       	adc	r19, r19
    25fa:	22 0f       	add	r18, r18
    25fc:	33 1f       	adc	r19, r19
    25fe:	82 0f       	add	r24, r18
    2600:	93 1f       	adc	r25, r19
    2602:	86 55       	subi	r24, 0x56	; 86
    2604:	9c 4f       	sbci	r25, 0xFC	; 252
    2606:	b8 01       	movw	r22, r16
    2608:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
    260c:	07 c0       	rjmp	.+14     	; 0x261c <xTaskGenericNotifyFromISR+0xe2>
				}
				else
				{
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    260e:	be 01       	movw	r22, r28
    2610:	64 5f       	subi	r22, 0xF4	; 244
    2612:	7f 4f       	sbci	r23, 0xFF	; 255
    2614:	89 ee       	ldi	r24, 0xE9	; 233
    2616:	93 e0       	ldi	r25, 0x03	; 3
    2618:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    261c:	e0 91 97 03 	lds	r30, 0x0397
    2620:	f0 91 98 03 	lds	r31, 0x0398
    2624:	9e 89       	ldd	r25, Y+22	; 0x16
    2626:	86 89       	ldd	r24, Z+22	; 0x16
    2628:	89 17       	cp	r24, r25
    262a:	78 f4       	brcc	.+30     	; 0x264a <xTaskGenericNotifyFromISR+0x110>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					if( pxHigherPriorityTaskWoken != NULL )
    262c:	e1 14       	cp	r14, r1
    262e:	f1 04       	cpc	r15, r1
    2630:	21 f0       	breq	.+8      	; 0x263a <xTaskGenericNotifyFromISR+0x100>
					{
						*pxHigherPriorityTaskWoken = pdTRUE;
    2632:	81 e0       	ldi	r24, 0x01	; 1
    2634:	f7 01       	movw	r30, r14
    2636:	80 83       	st	Z, r24
    2638:	09 c0       	rjmp	.+18     	; 0x264c <xTaskGenericNotifyFromISR+0x112>
					else
					{
						/* Mark that a yield is pending in case the user is not
						using the "xHigherPriorityTaskWoken" parameter to an ISR
						safe FreeRTOS function. */
						xYieldPending = pdTRUE;
    263a:	81 e0       	ldi	r24, 0x01	; 1
    263c:	80 93 9d 03 	sts	0x039D, r24
    2640:	05 c0       	rjmp	.+10     	; 0x264c <xTaskGenericNotifyFromISR+0x112>
						pxTCB->ulNotifiedValue = ulValue;
					}
					else
					{
						/* The value could not be written to the task. */
						xReturn = pdFAIL;
    2642:	80 e0       	ldi	r24, 0x00	; 0
    2644:	03 c0       	rjmp	.+6      	; 0x264c <xTaskGenericNotifyFromISR+0x112>

			traceTASK_NOTIFY_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    2646:	81 e0       	ldi	r24, 0x01	; 1
    2648:	01 c0       	rjmp	.+2      	; 0x264c <xTaskGenericNotifyFromISR+0x112>
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    264a:	81 e0       	ldi	r24, 0x01	; 1
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

		return xReturn;
	}
    264c:	df 91       	pop	r29
    264e:	cf 91       	pop	r28
    2650:	1f 91       	pop	r17
    2652:	0f 91       	pop	r16
    2654:	ff 90       	pop	r15
    2656:	ef 90       	pop	r14
    2658:	08 95       	ret

0000265a <vTaskNotifyGiveFromISR>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	void vTaskNotifyGiveFromISR( TaskHandle_t xTaskToNotify, BaseType_t *pxHigherPriorityTaskWoken )
	{
    265a:	ef 92       	push	r14
    265c:	ff 92       	push	r15
    265e:	0f 93       	push	r16
    2660:	1f 93       	push	r17
    2662:	cf 93       	push	r28
    2664:	df 93       	push	r29
    2666:	ec 01       	movw	r28, r24
    2668:	8b 01       	movw	r16, r22

		pxTCB = ( TCB_t * ) xTaskToNotify;

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			ucOriginalNotifyState = pxTCB->ucNotifyState;
    266a:	29 a5       	lds	r18, 0x69
			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
    266c:	82 e0       	ldi	r24, 0x02	; 2
    266e:	89 a7       	lds	r24, 0x79

			/* 'Giving' is equivalent to incrementing a count in a counting
			semaphore. */
			( pxTCB->ulNotifiedValue )++;
    2670:	8d a1       	lds	r24, 0x4d
    2672:	9e a1       	lds	r25, 0x4e
    2674:	af a1       	lds	r26, 0x4f
    2676:	b8 a5       	lds	r27, 0x68
    2678:	01 96       	adiw	r24, 0x01	; 1
    267a:	a1 1d       	adc	r26, r1
    267c:	b1 1d       	adc	r27, r1
    267e:	8d a3       	lds	r24, 0x5d
    2680:	9e a3       	lds	r25, 0x5e
    2682:	af a3       	lds	r26, 0x5f
    2684:	b8 a7       	lds	r27, 0x78

			traceTASK_NOTIFY_GIVE_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    2686:	21 30       	cpi	r18, 0x01	; 1
    2688:	e9 f5       	brne	.+122    	; 0x2704 <vTaskNotifyGiveFromISR+0xaa>
			{
				/* The task should not have been on an event list. */
				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );

				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    268a:	80 91 99 03 	lds	r24, 0x0399
    268e:	88 23       	and	r24, r24
    2690:	01 f5       	brne	.+64     	; 0x26d2 <vTaskNotifyGiveFromISR+0x78>
				{
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    2692:	ee 24       	eor	r14, r14
    2694:	ff 24       	eor	r15, r15
    2696:	68 94       	set
    2698:	e1 f8       	bld	r14, 1
    269a:	ec 0e       	add	r14, r28
    269c:	fd 1e       	adc	r15, r29
    269e:	c7 01       	movw	r24, r14
    26a0:	0e 94 2e 03 	call	0x65c	; 0x65c <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    26a4:	8e 89       	ldd	r24, Y+22	; 0x16
    26a6:	90 91 a0 03 	lds	r25, 0x03A0
    26aa:	98 17       	cp	r25, r24
    26ac:	10 f4       	brcc	.+4      	; 0x26b2 <vTaskNotifyGiveFromISR+0x58>
    26ae:	80 93 a0 03 	sts	0x03A0, r24
    26b2:	90 e0       	ldi	r25, 0x00	; 0
    26b4:	9c 01       	movw	r18, r24
    26b6:	22 0f       	add	r18, r18
    26b8:	33 1f       	adc	r19, r19
    26ba:	22 0f       	add	r18, r18
    26bc:	33 1f       	adc	r19, r19
    26be:	22 0f       	add	r18, r18
    26c0:	33 1f       	adc	r19, r19
    26c2:	82 0f       	add	r24, r18
    26c4:	93 1f       	adc	r25, r19
    26c6:	86 55       	subi	r24, 0x56	; 86
    26c8:	9c 4f       	sbci	r25, 0xFC	; 252
    26ca:	b7 01       	movw	r22, r14
    26cc:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
    26d0:	07 c0       	rjmp	.+14     	; 0x26e0 <vTaskNotifyGiveFromISR+0x86>
				}
				else
				{
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    26d2:	be 01       	movw	r22, r28
    26d4:	64 5f       	subi	r22, 0xF4	; 244
    26d6:	7f 4f       	sbci	r23, 0xFF	; 255
    26d8:	89 ee       	ldi	r24, 0xE9	; 233
    26da:	93 e0       	ldi	r25, 0x03	; 3
    26dc:	0e 94 dd 02 	call	0x5ba	; 0x5ba <vListInsertEnd>
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    26e0:	e0 91 97 03 	lds	r30, 0x0397
    26e4:	f0 91 98 03 	lds	r31, 0x0398
    26e8:	9e 89       	ldd	r25, Y+22	; 0x16
    26ea:	86 89       	ldd	r24, Z+22	; 0x16
    26ec:	89 17       	cp	r24, r25
    26ee:	50 f4       	brcc	.+20     	; 0x2704 <vTaskNotifyGiveFromISR+0xaa>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					if( pxHigherPriorityTaskWoken != NULL )
    26f0:	01 15       	cp	r16, r1
    26f2:	11 05       	cpc	r17, r1
    26f4:	21 f0       	breq	.+8      	; 0x26fe <vTaskNotifyGiveFromISR+0xa4>
					{
						*pxHigherPriorityTaskWoken = pdTRUE;
    26f6:	81 e0       	ldi	r24, 0x01	; 1
    26f8:	f8 01       	movw	r30, r16
    26fa:	80 83       	st	Z, r24
    26fc:	03 c0       	rjmp	.+6      	; 0x2704 <vTaskNotifyGiveFromISR+0xaa>
					else
					{
						/* Mark that a yield is pending in case the user is not
						using the "xHigherPriorityTaskWoken" parameter in an ISR
						safe FreeRTOS function. */
						xYieldPending = pdTRUE;
    26fe:	81 e0       	ldi	r24, 0x01	; 1
    2700:	80 93 9d 03 	sts	0x039D, r24
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
	}
    2704:	df 91       	pop	r29
    2706:	cf 91       	pop	r28
    2708:	1f 91       	pop	r17
    270a:	0f 91       	pop	r16
    270c:	ff 90       	pop	r15
    270e:	ef 90       	pop	r14
    2710:	08 95       	ret

00002712 <xTaskNotifyStateClear>:
	TCB_t *pxTCB;
	BaseType_t xReturn;

		/* If null is passed in here then it is the calling task that is having
		its notification state cleared. */
		pxTCB = prvGetTCBFromHandle( xTask );
    2712:	00 97       	sbiw	r24, 0x00	; 0
    2714:	29 f4       	brne	.+10     	; 0x2720 <xTaskNotifyStateClear+0xe>
    2716:	e0 91 97 03 	lds	r30, 0x0397
    271a:	f0 91 98 03 	lds	r31, 0x0398
    271e:	01 c0       	rjmp	.+2      	; 0x2722 <xTaskNotifyStateClear+0x10>
    2720:	fc 01       	movw	r30, r24

		taskENTER_CRITICAL();
    2722:	0f b6       	in	r0, 0x3f	; 63
    2724:	f8 94       	cli
    2726:	0f 92       	push	r0
		{
			if( pxTCB->ucNotifyState == taskNOTIFICATION_RECEIVED )
    2728:	81 a5       	lds	r24, 0x61
    272a:	82 30       	cpi	r24, 0x02	; 2
    272c:	19 f4       	brne	.+6      	; 0x2734 <xTaskNotifyStateClear+0x22>
			{
				pxTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    272e:	11 a6       	lds	r17, 0xb1
				xReturn = pdPASS;
    2730:	81 e0       	ldi	r24, 0x01	; 1
    2732:	01 c0       	rjmp	.+2      	; 0x2736 <xTaskNotifyStateClear+0x24>
			}
			else
			{
				xReturn = pdFAIL;
    2734:	80 e0       	ldi	r24, 0x00	; 0
			}
		}
		taskEXIT_CRITICAL();
    2736:	0f 90       	pop	r0
    2738:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    273a:	08 95       	ret

0000273c <memcpy>:
    273c:	fb 01       	movw	r30, r22
    273e:	dc 01       	movw	r26, r24
    2740:	02 c0       	rjmp	.+4      	; 0x2746 <memcpy+0xa>
    2742:	01 90       	ld	r0, Z+
    2744:	0d 92       	st	X+, r0
    2746:	41 50       	subi	r20, 0x01	; 1
    2748:	50 40       	sbci	r21, 0x00	; 0
    274a:	d8 f7       	brcc	.-10     	; 0x2742 <memcpy+0x6>
    274c:	08 95       	ret

0000274e <_exit>:
    274e:	f8 94       	cli

00002750 <__stop_program>:
    2750:	ff cf       	rjmp	.-2      	; 0x2750 <__stop_program>
